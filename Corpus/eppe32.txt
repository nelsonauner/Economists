 [' We consider the problem of estimating and testing for multiple breaks in a single\xe2\x80\x90equation framework with regressors that are endogenous, i.e. correlated with the errors. We show that even in the presence of endogenous regressors it is still preferable, in most cases, to simply estimate the break dates and test for structural change using the usual ordinary least squares (OLS) framework. Except for some knife\xe2\x80\x90edge cases, it delivers estimates of the break dates with higher precision and tests with higher power compared to those obtained using an instrumental variable (IV) method. Also, the OLS method avoids potential weak identification problems caused by weak instruments. To illustrate the relevance of our theoretical results, we consider the stability of the New Keynesian hybrid Phillips curve. IV\xe2\x80\x90based methods only provide weak evidence of instability. On the other hand, OLS\xe2\x80\x90based ones strongly indicate a change in 1991:Q1 and that after this date the model loses all explanatory power. Copyright \xc2\xa9 2013 John Wiley &amp; Sons, Ltd.'] ['We extend the random level shift (RLS) model of Lu and Perron (2010) to the volatility of asset prices, which consists of a short memory process and a random level shift component. Motivated by empirical features, (a) we specify a time-varying probability of shifts as a function of large negative lagged returns; and (b) we incorporate a mean reverting mechanism so that the sign and magnitude of the jump component change according to the deviations of past jumps from their long run mean. This allows the possibility of forecasting the sign and magnitude of the jumps. We estimate the model using twelve different series, and compare its forecasting performance with those of a variety of competing models at various horizons. A striking feature is that the modified RLS model has the smallest mean square forecast errors in 64 of the 72 cases, while it is a close second for the other 8 cases. The improvement in forecast accuracy is often substantial, especially for medium- to long-horizon forecasts. This is strong evidence that our modified RLS model offers important gains in forecasting performance.'] ['We propose a modified local-Whittle estimator of the memory parameter of a long memory time series process which has good properties under an almost complete collection of contamination processes that have been discussed in the literature, mostly separately. These contaminations include processes whose spectral density functions dominate at low frequencies such as random level shifts, deterministic level shifts and deterministic trends. We show that our modified estimator has the usual asymptotic distribution applicable for the standard local Whittle estimator in the absence of such contaminations. We also show how the estimator can be modified to further account for additive noise and that our modification for low frequency contamination reduces the bias due to short-memory dynamics. Through extensive simulations, we show that the proposed estimator provides substantial efficiency gains compared to existing semiparametric estimators in the presence of contaminations, with little loss of efficiency when these are absent.'] ['This note provides a simple proof for the problem of estimating and testing for multiple breaks in a single equation framework with regressors that are endogenous, i.e., correlated with the errors. We show based on standard assumptions about the regressors, instruments and errors that the second stage regression of the instrumental variable (IV) procedure involves regressors and errors that satisfy all the assumptions in Perron and Qu (2006) so that the results about consistency, rate of convergence and limit distributions of the estimates of the break dates, as well as the limit distributions of the tests, are obtained as simple consequences.<p>(This abstract was borrowed from another version of this item.)'] ['We provide a theoretical framework to explain the empirical finding that the estimated betas are sensitive to the sampling interval even when using continuously compounded returns. We suppose that stock prices have both permanent and transitory components. The discrete time representation of the beta depends on the sampling interval and two components labeled \xe2\x80\x9cpermanent and transitory betas\xe2\x80\x9d. We show that if no transitory component is present in stock prices then no sampling interval effect occurs. However, the presence of a transitory component implies that the beta is an increasing (decreasing) function of the sampling interval for more (less) risky assets. In our framework, assets are labeled risky if their \xe2\x80\x9cpermanent beta\xe2\x80\x9d is greater than their \xe2\x80\x9ctransitory beta\xe2\x80\x9d and vice versa for less risky assets. Simulations show that our theoretical results provide good approximations for the estimated betas in small samples. We provide empirical evidence about the presence of negative serial correlation and mean reversion in the returns of the portfolios considered. We discuss why our model is better able to provide an explanation for this sampling interval effect than other models in the literature.'] ['This paper considers the problem of testing for multiple structural changes in the persistence of a univariate time series. We propose sup-Wald tests of the null hypothesis that the process has an autoregressive unit root throughout the sample against the alternative hypothesis that the process alternates between stationary and unit root regimes. We derive the limit distributions of the tests under the null and establish their consistency under the relevant alternatives. We further show that the tests are inconsistent when directed against the incorrect alternative, thereby enabling identification of the nature of persistence in the initial regime. We also propose hybrid testing procedures that allow ruling out of stable stationary processes or ones that are subject to only stationary changes under the null, thereby aiding the researcher in interpreting a rejection as emanating from a switch between a unit root and stationary regime. The computation of the test statistics as well as asymptotic critical values is facilitated by the dynamic programming algorithm proposed in Perron and Qu ( 2006 , Journal of Econometrics 134, 373\xe2\x80\x93399) which allows imposing within- and cross-regime restrictions on the parameters. Finally, we present Monte Carlo evidence to show that the proposed procedures perform well in finite samples relative to those available in the literature.'] ['No abstract is available for this item.'] ['We propose estimators of the memory parameter of a time series that are robust to a wide variety of random level shift processes, deterministic level shifts and deterministic time trends. The estimators are simple trimmed versions of the popular log-periodogram regression estimator that employ certain sample size-dependent and, in some cases, data-dependent trimmings which discard low-frequency components. We also show that a previously developed trimmed local Whittle estimator is robust to the same forms of data contamination. Regardless of whether the underlying long/shortmemory process is contaminated by level shifts or deterministic trends, the estimators are consistent and asymptotically normal with the same limiting variance as their standard untrimmed counterparts. Simulations show that the trimmed estimators perform their intended purpose quite well, substantially decreasing both finite sample bias and root mean-squared error in the presence of these contaminating components. Furthermore, we assess the tradeoffs involved with their use when such components are not present but the underlying process exhibits strong short-memory dynamics or is contaminated by noise. To balance the potential finite sample biases involved in estimating the memory parameter, we recommend a particular adaptive version of the trimmed log-periodogram estimator that performs well in a wide variety of circumstances. We apply the estimators to stock market volatility data to find that various time series typically thought to be long-memory processes actually appear to be short or very weak long-memory processes contaminated by level shifts or deterministic trends.<p>(This abstract was borrowed from another version of this item.)'] [' We study the finite sample properties of tests for structural changes in the trend function of a time series that do not require knowledge of the degree of persistence in the noise component. The tests of interest are the quasi-Feasible Generalized Least Squares (FGLS) procedure by Perron and Yabu (2009b) and the weighted average of the regression t -statistics by Harvey et al . (2009), both of which have the same limit distribution whether the noise component is stationary or has a unit-root. We analyse the finite sample size and power properties of these tests under a variety of Data-Generating Processes (DGPs). The results show that the Perron--Yabu test has greater power overall. With respect to the size, the Harvey--Leybourne--Taylor test exhibits larger size distortions unless a moving-average component is present. Using the Perron and Yabu procedure to test for structural changes in the trend function of long-run real exchange rates with respect to the US dollar indicates that for 17 out of 19 countries, the series have experienced a shift in trend since the late nineteenth century.'] ['This paper considers methods for estimating and testing multiple structural changes occuring at unknown dates in linear models using band spectral regressions. We con- sider changes over time within some frequency bands, permitting the coefficients to be di\xc2\xa4erent across frequency bands. Using standard assumptions, we show that the limit distributions obtained are similar to those in the time domain counterpart. We show that when the coefficients change only within some frequency band we can have increased e\xc2\xa2 ciency of the estimates and power of the tests. We also discuss a very useful application related to contexts in which the data is contaminated by some low frequency process (e.g., level shifts or trends) and that the researcher is interested in whether the original non-contaminated model is stable. We show that all that is needed to obtain estimates of the break dates and tests for structural changes that are not a\xc2\xa4ected by such low frequency contaminations is to truncate a low frequency band that shrinks to zero at rate log(T)=T . Simulations show that the tests have good sizes for a wide range of truncations so that the method is quite robust. We analyze the stability of the relation between hours worked and productivity. When applying the structural change tests in the time domain we document strong evidence of instabil- ities. When excluding a few low frequencies, none of the structural change tests are significant. Hence, the results provide evidence to the e\xc2\xa4ect that the relation between hours worked and productivity is stable over any spectral band that excludes the lowest frequencies, in particular it is stable over the business-cycle band.<p>(This abstract was borrowed from another version of this item.)'] ['Roy, Falk and Fuller (2004) presented a procedure aimed at providing a test for the value of the slope of a trend function that has (nearly) controlled size in autoregressive models whether the noise component is stationary or has a unit root. In this note, we document errors in both their theoretical results and the simulations they reported. Once these are corrected for, their procedure delivers a test that has very liberal size in the case with a unit root so that the stated goal is not achieved. Interestingly, the mistakes in the code used to generate the simulated results (which is the basis for the evidence about the reliability of the method) are such that what they report is essentially equivalent to the size and power of the test proposed by Perron and Yabu (2009), which was shown to have the standard Normal distribution whether the noise is stationary or has a unit root.<p>(This abstract was borrowed from another version of this item.)'] ['This paper studies issues related to the estimation of a structural change in the persistence of a univariate time series. The break is such that the process has a unit root [i.e., is I(1)] in the pre-break regime but reverts to a stationary [i.e., I(0)] process in the post-break regime or vice versa. Chong (2001) develops the limit theory for the estimation of such autoregressive processes and shows that the rate of convergence of the breakpoint estimator in the I(1)\xe2\x80\x93I(0) case is faster than that in the I(0)\xe2\x80\x93I(1) case, which enables the break date to be estimated much more precisely in the former case. In this paper, we show that the faster rate is an artifact of the assumed data generating process that is characterized by a spurious jump at the true breakpoint. Based on a reformulation that avoids this jump, the same rate of convergence prevails in both cases. An important implication of this result is that existing confidence intervals in the I(1)\xe2\x80\x93I(0) case have asymptotically zero coverage rates when the break magnitude is fixed. A small simulation study confirms the relevance of the asymptotic results in finite samples.'] ['We extend the class of M-tests for a unit root analyzed by Perron and Ng (1996) and Ng and Perron (1997) to the case where a change in the trend function is allowed to occur at an unknown time. These tests M(GLS) adopt the GLS detrending approach of Dufour and King (1991) and Elliott, Rothenberg and Stock (1996) (ERS). Following Perron (1989), we consider two models : one allowing for a change in slope and the other for both a change in intercept and slope. We derive the asymptotic distribution of the tests as well as that of the feasible point optimal tests PT(GLS) suggested by ERS. The asymptotic critical values of the tests are tabulated. Also, we compute the non-centrality parameter used for the local GLS detrending that permits the tests to have 50% asymptotic power at that value. We show that the M(GLS) and PT(GLS) tests have an asymptotic power function close to the power envelope. An extensive simulation study analyzes the size and power in finite samples under various methods to select the runcation lag for the autoregressive spectral density estimator. An empirical application is also provided.'] ['It has been argued that estimating the spectral density function of a stationary stochastic process at the zero frequency (or the so-called long-run variance) is an ill-posed problem so that any estimate will have an infinite minimax risk (e.g., P\xc3\xb6tscher 2002). Most often it is a nuisance parameter that is present in the limit distribution of some statistic and one then needs an estimate of it to obtain test statistics that have a pivotal distribution. In this context, we argue that such an impossibility result is irrelevant. We show that, in the presence of the discontinuities that cause the ill-posedness of the estimation problem for the long-run variance, using the true value of the spectral density function at frequency zero leads to tests that have either 0 or 100% size and, hence, lead to confidence intervals that are completely uninformative. On the other hand, tests based on standard estimates of the long-run variance will have well defined limit distributions and, accordingly, be more informative.'] [' Perron and Yabu (2009a) consider the problem of testing for a break occurring at an unknown date in the trend function of a univariate time series when the noise component can be either stationary or integrated. This article extends their work by proposing a sequential test that allows one to test the null hypothesis of, say, l breaks versus the alternative hypothesis of (l + 1) breaks. The test enables consistent estimation of the number of breaks. In both stationary and integrated cases, it is shown that asymptotic critical values can be obtained from the relevant quantiles of the limit distribution of the test for a single break. Monte Carlo simulations suggest that the procedure works well in finite samples. Copyright Copyright 2010 Blackwell Publishing Ltd'] ['We consider the estimation of a random level shift model for which the series of interest is the sum of a short-memory process and a jump or level shift component. For the latter component, we specify the commonly used simple mixture model such that the component is the cumulative sum of a process which is 0 with some probability (1\xc3\x82 -\xc3\x82 [alpha]) and is a random variable with probability [alpha]. Our estimation method transforms such a model into a linear state space with mixture of normal innovations, so that an extension of Kalman filter algorithm can be applied. We apply this random level shift model to the logarithm of daily absolute returns for the S&amp;P; 500, AMEX, Dow Jones and NASDAQ stock market return indices. Our point estimates imply few level shifts for all series. But once these are taken into account, there is little evidence of serial correlation in the remaining noise and, hence, no evidence of long-memory. Once the estimated shifts are introduced to a standard GARCH model applied to the returns series, any evidence of GARCH effects disappears. We also produce rolling out-of-sample forecasts of squared returns. In most cases, our simple random level shift model clearly outperforms a standard GARCH(1,1) model and, in many cases, it also provides better forecasts than a fractionally integrated GARCH model.'] ['This paper considers issues related to testing for multiple structural changes in cointegrated systems. We derive the limiting distribution of the Sup-Wald test under mild conditions on the errors and regressors for a variety of testing problems. We show that even if the coefficients of the integrated regressors are held fixed but the intercept is allowed to change, the limit distributions are not the same as would prevail in a stationary framework. Including stationary regressors whose coefficients are not allowed to change does not affect the limiting distribution of the tests under the null hypothesis. We also propose a procedure that allows one to test the null hypothesis of, say, k changes, versus the alternative hypothesis of k + 1 changes. This sequential procedure is useful in that it permits consistent estimation of the number of breaks present. We show via simulations that our tests maintain the correct size in finite samples and are much more powerful than the commonly used LM tests, which suffer from important problems of non-monotonic power in the presence of serial correlation in the errors.<p>(This abstract was borrowed from another version of this item.)'] ['Recently, there has been an upsurge of interest in the possibility of confusing long memory and structural changes in level. Many studies have shown that when a stationary short memory process is contaminated by level shifts the estimate of the fractional differencing parameter is biased away from zero and the autocovariance function exhibits a slow rate of decay, akin to a long memory process. Partly based on results in Perron and Qu (2007), we analyze the properties of the autocorrelation function, the periodogram and the log periodogram estimate of the memory parameter when the level shift component is specified by a simple mixture model. Our theoretical results explain many findings reported and uncover new features. We confront our theoretical predictions using log-squared returns as a proxy for the volatility of some assets returns, including daily S&amp;P; 500 returns over the period 1928-2002. The autocorrelations and the path of the log periodogram estimates follow patterns that would obtain if the true underlying process was one of short-memory contaminated by level shifts instead of a fractionally integrated process. A simple testing procedure is also proposed, which reinforces this conclusion.<p>(This abstract was borrowed from another version of this item.)'] ['Perron [Perron, P., 1989. The great crash, the oil price shock and the unit root hypothesis. Econometrica 57, 1361-1401] introduced a variety of unit root tests that are valid when a break in the trend function of a time series is present. The motivation was to devise testing procedures that were invariant to the magnitude of the shift in level and/or slope. In particular, if a change is present it is allowed under both the null and alternative hypotheses. This analysis was carried under the assumption of a known break date. The subsequent literature aimed to devise testing procedures valid in the case of an unknown break date. However, in doing so, most of the literature and, in particular the commonly used test of Zivot and Andrews [Zivot, E., Andrews, D.W.K., 1992. Further evidence on the great crash, the oil price shock and the unit root hypothesis. Journal of Business and Economic Statistics 10, 251-270], assumed that if a break occurs, it does so only under the alternative hypothesis of stationarity. This is undesirable since (a) it imposes an asymmetric treatment when allowing for a break, so that the test may reject when the noise is integrated but the trend is changing; (b) if a break is present, this information is not exploited to improve the power of the test. In this paper, we propose a testing procedure that addresses both issues. It allows a break under both the null and alternative hypotheses and, when a break is present, the limit distribution of the test is the same as in the case of a known break date, thereby allowing increased power while maintaining the correct size. Simulation experiments confirm that our procedure offers an improvement over commonly used methods in small samples.'] ['We propose a test for the slope of a trend function when it is a priori unknown whether the series is trend-stationary or contains an autoregressive unit root. The procedure is based on a Feasible Quasi Generalized Least Squares method from an AR(1) specification with parameter [alpha], the sum of the autoregressive coefficients. The estimate of [alpha] is the OLS estimate obtained from an autoregression applied to detrended data and is truncated to take a value 1 whenever the estimate is in a T-[delta] neighborhood of 1. This makes the estimate "super-efficient" when [alpha]=1 and implies that inference on the slope parameter can be performed using the standard Normal distribution whether [alpha]=1 or [alpha]'] ['Perron (1989, Econometrica 57, 1361\xe2\x80\x931401) introduced unit root tests valid when a break at a known date in the trend function of a time series is present. In particular, they allow a break under both the null and alternative hypotheses and are invariant to the magnitude of the shift in level and/or slope. The subsequent literature devised procedures valid in the case of an unknown break date. However, in doing so most research, in particular the commonly used test of Zivot and Andrews (1992, Journal of Business &amp; Economic Statistics 10, 251\xe2\x80\x93270), assumed that if a break occurs it does so only under the alternative hypothesis of stationarity. This is undesirable for several reasons. Kim and Perron (2009, Journal of Econometrics 148, 1\xe2\x80\x9313) developed a methodology that allows a break at an unknown time under both the null and alternative hypotheses. When a break is present, the limit distribution of the test is the same as in the case of a known break date, allowing increased power while maintaining the correct size. We extend their work in several directions: (1) we allow for an arbitrary number of changes in both the level and slope of the trend function; (2) we adopt the quasi\xe2\x80\x93generalized least squares detrending method advocated by Elliott, Rothenberg, and Stock (1996, Econometrica 64, 813\xe2\x80\x93836) that permits tests that have local asymptotic power functions close to the local asymptotic Gaussian power envelope; (3) we consider a variety of tests, in particular the class of M -tests introduced in Stock (1999, Cointegration, Causality, and Forecasting: A Festschrift for Clive W.J. Granger ) and analyzed in Ng and Perron (2001, Econometrica 69, 1519\xe2\x80\x931554).'] ['Trend-cycle decompositions for US real GDP such as the unobserved components models, the Beveridge-Nelson decomposition, the Hodrick-Prescott filter and others yield very different cycles which bear little resemblance to the NBER chronology, ascribes much movements to the trend leaving little to the cycle, and some imply a negative correlation between the noise to the cycle and the trend. We argue that these features are artifacts created by the neglect of a change in the slope of the trend function. Once this is accounted for, all methods yield the same cycle with a trend that is non-stochastic except for a few periods around 1973. The cycle is more important in magnitude than previously reported and it accords well with the NBER chronology. Our results are corroborated using an alternative trend-cycle decomposition based on a generalized unobserved components models with errors having a mixture of normals distribution for both the slope of the trend function and the cyclical component.'] ['This paper considers the problem of testing for structural changes in the trend function of a univariate time series without any prior knowledge as to whether the noise component is stationary or contains an autoregressive unit root. We propose a new approach that builds on the work of Perron and Yabu (2005), based on a Feasible Quasi Generalized Least Squares procedure that uses a superefficient estimate of the sum of autoregressive parameters \xc3\xa1 when \xc3\xa1 = 1. In the case of a known break date, the resulting Wald test has a chi- square limit distribution in both the I(0) and I(1) cases. When the break date is unknown, the Exp function of Andrews and Ploberger (1994) yields a test with identical limit distributions in the two cases so that a testing procedure with nearly the same size in the I(0) and I(1) cases can be obtained. To improve the finite sample properties of the tests, we used the bias corrected version of the OLS estimate of \xc3\xa1 proposed by Roy and Fuller (2001). We show our procedure to be substantially more powerful then currently available alternatives and also to have a power function that is close to that attainable if we knew the true value of \xc3\xa1 in many cases. The extension to the case of multiple breaks is also discussed.<p>(This abstract was borrowed from another version of this item.)'] ["We compare the asymptotic relative efficiency of the Exp, Mean, and Sup functionals of the Wald, LM and LR tests for structural change analyzed by Andrews [Andrews, D.W.K., 1993. Tests for parameter instability and structural change with unknown change point. Econometrica 61, 821-856.] and Andrews and Ploberger [Andrews, D.W.K., Ploberger, W., 1994. Optimal tests when a nuisance parameter is present only under the alternative. Econometrica 62, 1383-1414.]. We derive the approximate Bahadur slopes of these tests using large deviations techniques. These show that tests based on the Mean functional are inferior to those based on the Sup and Exp when using the same base statistic. Also, for a given functional, the Wald-based test dominates the LR-based test, which dominates the LM-based one. We show that the Sup- and Mean-type tests satisfy Wieand's [Wieand, H.S., 1976. A Condition under which the Pitman and Bahadur approaches to efficiency coincide. Annals of Statistics 4, 1003-1011.] condition so that their slopes yield the limiting (as the size tends to zero) asymptotic relative Pitman efficiency (whether this holds for the Exp-type tests still remains a conjecture). Using this measure of efficiency, the Mean-type tests are also inferior to the Sup. We also compare tests based on the Wald and LM statistics modified with a HAC estimator. In this case, the inferiority of the LM-based tests is especially pronounced. The relevance of our theoretical results in finite samples is assessed via simulations. Our results are in contrast to those obtained by the authors-in the second reference cited above-based on a local asymptotic framework, and our analysis thereby reveals its potential weaknesses in the context of structural change problems."] ['We study estimation and inference in cointegrated regression models with multiple structural changes allowing both stationary and integrated regressors. Both pure and partial structural change models are analyzed. We derive the consistency, rate of convergence and the limit distribution of the estimated break fractions. Our technical conditions are considerably less restrictive than those in Bai et\xc3\x82 al.\xc3\x82 [Bai, J., Lumsdaine, R.L., Stock, J.H., 1998. Testing for and dating breaks in multivariate time series. Review of Economic Studies 65, 395-432] who considered the single break case in a multi-equations system, and permit a wide class of practically relevant models. Our analysis is, however, restricted to a single equation framework. We show that if the coefficients of the integrated regressors are allowed to change, the estimated break fractions are asymptotically dependent so that confidence intervals need to be constructed jointly. If, however, only the intercept and/or the coefficients of the stationary regressors are allowed to change, the estimates of the break dates are asymptotically independent as in the stationary case analyzed by Bai and Perron [Bai, J., Perron, P., 1998. Estimating and testing linear models with multiple structural changes. Econometrica 66, 47-78]. We also show that our results remain valid, under very weak conditions, when the potential endogeneity of the non-stationary regressors is accounted for via an increasing sequence of leads and lags of their first-differences as additional regressors. Simulation evidence is presented to assess the adequacy of the asymptotic approximations in finite samples.'] ['We consider the cumulative sum (CUSUM) of squares test in a linear regression model with general mixing assumptions on the regressors and the errors. We derive its limit distribution and show how it depends on the nature of the error process. We suggest a corrected version that has a limit distribution free of nuisance parameters. We also discuss how it provides an improvement over the standard approach to testing for a change in the variance in a univariate times series. Simulation evidence is presented to support this.'] ['Saikkonen (1991, Econometric Theory 7, 1\xe2\x80\x9321) developed an asymptotic optimality theory for the estimation of cointegrated regressions. He proposed the dynamic ordinary least squares (OLS) estimator obtained by augmenting the static cointegrating regression with leads and lags of the first differences of the I(1) regressors. However, the assumptions imposed preclude the use of information criteria such as the Akaike information criterion (AIC) and Bayesian information criterion (BIC) to select the number of leads and lags. We show that his results remain valid under weaker conditions that permit the use of such data dependent rules. Simulations show that, relative to sequential general to specific testing procedures, the use of such information criteria can indeed produce estimates with smaller mean squared errors and confidence intervals with better coverage rates.'] ['We consider the power properties of the CUSUM and CUSUM of squares tests in the presence of a one-time change in the parameters of a linear regression model. A result due to Ploberger and Kr\xc3\xa4mer (1990) is that the CUSUM of squares test has only trivial asymptotic local power in this case, while the CUSUM test has non-trivial local asymptotic power unless the change is orthogonal to the mean regressor. We argue that such conclusions obtained from a local asymptotic framework are not reliable guides to what happens in finite samples. The approach we take is to derive expansions of the test statistics to order Op(T 1/2) that retain terms related to the magnitude of the change under the alternative hypothesis. This enables us to analyze what happens for non-local to zero breaks. Our theoretical results are able to explain how the power function of the tests can be drastically different depending on whether one deals with a static regression with uncorrelated errors, a static regression with correlated errors, a dynamic regression with lagged dependent variables, or whether a correction for non-Normality is applied in the case of the CUSUM of squares. We discuss in which cases the tests are subject to a non-monotonic power function that goes to zero as the magnitude of the change increases, and uncover some curious properties. All theoretical results are verified to yield good guides to the finite sample power through simulation experiments. We finally highlight the practical importance of our results.<p>(This abstract was borrowed from another version of this item.)'] ['The tests introduced by Ng and Perron (2001, Econometrica) have the drawback that for non-local alternatives the power can be very small. The aim of this note is to point out an easy solution to this power reversal problem, which in addition leads to tests having an exact size even closer to nominal size. It involves using OLS instead of GLS detrended data when constructing the modified information criterion.<p>(This abstract was borrowed from another version of this item.)'] ['We consider Johansen\xe2\x80\x99s (1988, 1991) cointegration tests when a Vector AutoRegressive (VAR) process of order k is used to approximate a more general linear process with an infinite VAR representation. In this case, and in particular when a moving average component is present, traditional methods to select the lag order, such as Akaike\xe2\x80\x99s (AIC) or the Bayesian information criteria, lead to too parsimonious a model, with the implication that the cointegration tests suffer from substantial size distortions in finite samples. We extend the analysis of Ng and Perron (2001) to derive a Modified Akaike\xe2\x80\x99s Information Criterion (MAIC) in this multivariate setting. The idea is to use the information specified by the null hypothesis as it relates to restrictions on the parameters of the model to keep an extra term in the penalty function of the AIC. This MAIC takes a very simple form for which this extra term is simply the likelihood ratio test for testing the null hypothesis of r against more than r cointegrating vectors. We provide theoretical analyses of its validity and of the fact that cointegration tests constructed from a VAR whose lag order is selected using the MAIC have the same limit distribution as when the order is finite and known. We also provide theoretical and simulation analyses to show how the MAIC leads to VAR approximations that yield tests with drastically improved size properties with little loss of power.<p>(This abstract was borrowed from another version of this item.)'] [' This paper considers issues related to estimation, inference, and computation with multiple structural changes that occur at unknown dates in a system of equations. Changes can occur in the regression coefficients and/or the covariance matrix of the errors. We also allow arbitrary restrictions on these parameters, which permits the analysis of partial structural change models, common breaks that occur in all equations, breaks that occur in a subset of equations, and so forth. The method of estimation is quasi-maximum likelihood based on Normal errors. The limiting distributions are obtained under more general assumptions than previous studies. For testing, we propose likelihood ratio type statistics to test the null hypothesis of no structural change and to select the number of changes. Structural change tests with restrictions on the parameters can be constructed to achieve higher power when prior information is present. For computation, an algorithm for an efficient procedure is proposed to construct the estimates and test statistics. We also introduce a novel locally ordered breaks model, which allows the breaks in different equations to be related yet not occurring at the same dates. Copyright The Econometric Society 2007.'] [' This paper considers various asymptotic approximations to the finite sample distribution of the estimate of the break date in a simple one-break model for a linear trend function that exhibits a change in slope, with or without a concurrent change in intercept. The noise component is either stationary or has an autoregressive unit root. Our main focus is on comparing the so-called "bounded-trend" and "unbounded-trend" asymptotic frameworks. Not surprisingly, the "bounded-trend" asymptotic framework is of little use when the noise component is integrated. When the noise component is stationary, we obtain the following results. If the intercept does not change and is not allowed to change in the estimation, both frameworks yield the same approximation. However, when the intercept is allowed to change, whether or not it actually changes in the data, the "bounded-trend" asymptotic framework completely misses important features of the finite sample distribution of the estimate of the break date, especially the pronounced bimodality that was uncovered by Perron and Zhu (2005) and shown to be well captured using the "unbounded-trend" asymptotic framework. Simulation experiments confirm our theoretical findings, which expose the drawbacks of using the " bounded-trend" asymptotic framework in the context of structural change models. Copyright Royal Economic Society 2006'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' We consider issues related to the order of an autoregression selected using information criteria. We study the sensitivity of the estimated order to (i) whether the effective number of observations is held fixed when estimating models of different order, (ii) whether the estimate of the variance is adjusted for degrees of freedom, and (iii) how the penalty for overfitting is defined in relation to the total sample size. Simulations show that the lag length selected by both the Akaike and the Schwarz information criteria are sensitive to these parameters in finite samples. The methods that give the most precise estimates are those that hold the effective sample size fixed across models to be compared. Theoretical considerations reveal that this is indeed necessary for valid model comparisons. Guides to robust model selection are provided. Copyright 2005 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] [' Recently, Vogelsang (1999) proposed a method to detect outliers which explicitly imposes the null hypothesis of a unit root. It works in an iterative fashion to select multiple outlier in a given series. We show, via simulations, that, under the null hypothesis of no outliers, it has the right size in finite samples to detect a single outlier but, when applied in an iterative fashion to select multiple outliers, it exhibits severe size distortions towards finding an excessive number of outliers. We show that his iterative method is incorrect and derive the appropriate limiting distribution of the test at each step of the search. Whether corrected or not, we also show that the outliers need to be very large for the method to have any decent power. We propose an alternative method based on first-differenced data that has considerably more power. We also show that our method to identify outliers leads to unit root tests with more accurate finite sample size and robustness to departures from a unit root. The issues are illustrated using two US/Finland real-exchange rate series. Copyright 2003 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] [' to enable proper empirical applications. We provide response surface regressions valid for a wide range of parameters. Copyright Royal Economic Society, 2003'] [' Local to unity GLS detrending routine. Includes the ERS cases (no constant, constant, constant and trend) as well as the Perron and Rodriguez cases (constant and trend with a single break). This just does the detrending, not the actual unit root test(s). Elliott, Rothenberg and Stock(1996), "Efficient Tests for an Autoregressive Unit Root", Econometrica, vol 64, no. 4, pp 813-836. Perron and Rodriguez(2003), "GLS Detrending, Efficient Unit Root Tests and Structural Change", Journal of Econometrics, vol 115, pp 1-27.<p>(This abstract was borrowed from another version of this item.)'] [' In a recent paper, Bai and Perron (1998) considered theoretical issues related to the limiting distribution of estimators and test statistics in the linear model with multiple structural changes. In this companion paper, we consider practical issues for the empirical applications of the procedures. We first address the problem of estimation of the break dates and present an efficient algorithm to obtain global minimizers of the sum of squared residuals. This algorithm is based on the principle of dynamic programming and requires at most least-squares operations of order O(T 2) for any number of breaks. Our method can be applied to both pure and partial structural change models. Second, we consider the problem of forming confidence intervals for the break dates under various hypotheses about the structure of the data and the errors across segments. Third, we address the issue of testing for structural changes under very general conditions on the data and the errors. Fourth, we address the issue of estimating the number of breaks. Finally, a few empirical applications are presented to illustrate the usefulness of the procedures. All methods discussed are implemented in a GAUSS program. Copyright \xc2\xa9 2002 John Wiley &amp; Sons, Ltd.'] ['In a recent paper, Engel, C. (1999) presents monte-carlo evidence to suggest that unit root tests cannot detect a non-stationary component in the real exchange rate even when this component accounts for almost half of its longhorizon forecast error variance. This hidden non-stationary component led to the conclusion that long run purchasing power parity might not hold afterall. In this note, we first point out some conceptual difficulties with the statistic being used to measure the size of the non-stationary component, and then argue that it bears no systematic relationship with rejection rates in unit root tests. The problems stem from near observational equivalence of the simulated model in not one, but two dimensions. We then discuss the steps a practitioner can take to minimize Type I error in cases when the non-stationary component is hard to detect. Real exchange rate data for 19 countries are examined and estimates are obtained for the duration of the real exchange rate shocks.'] ['This paper considers various asymptotic approximations in the near-integrated first-order autoregressive model with a non-zero initial condition. We first extend the work of Knight and Satchell (1993), who considered the random walk case with a zero initial con-dition, to derive the expansion of the relevant joint moment generating function in this more general framework. We also consider, as alternative approximations, the stochastic expansion of Phillips (1987c) and the continuous-time approximation of Perron (1991a). We assess, via a Monte Carlo simulation study, the extent to which these alternative methods provide adequate approximations to the finite sample distribution of the least-squares estimator in a first-order autoregressive model. The results show that, when the initial condition is non-zero, Perron\xc2\xb9s (1991a) continuous-time approximation performs very well while the others only offer improvements when the initial condition is zero.'] [' It is widely known that when there are errors with a moving-average root close to - 1, a high order augmented autoregression is necessary for unit root tests to have good size, but that information criteria such as the "AIC" and the "BIC" tend to select a truncation lag ("k") that is very small. We consider a class of Modified Information Criteria ("MIC") with a penalty factor that is sample dependent. It takes into account the fact that the bias in the sum of the autoregressive coefficients is highly dependent on "k" and adapts to the type of deterministic components present. We use a local asymptotic framework in which the moving-average root is local to - 1 to document how the "MIC" performs better in selecting appropriate values of "k". In Monte-Carlo experiments, the "MIC" is found to yield huge size improvements to the "DF-super-GLS" and the feasible point optimal "P-sub-T" test developed in Elliott, Rothenberg, and Stock (1996). We also extend the "M" tests developed in Perron and Ng (1996) to allow for "GLS" detrending of the data. The "MIC" along with "GLS" detrended data yield a set of tests with desirable size and power properties. Copyright The Econometric Society.'] ['No abstract is available for this item.'] [" This paper considers econometric issues related to time-series data that have been subject to abrupt governmental interventions. The motivating example for this study is the Brazilian monthly inflation rate (1974:1-1993:6) which we use throughout for illustration. This series has been heavily influenced by the effect of so-called shock plans implemented by various governments starting in the mid-1980s. The plans act as 'inliers' in the sense that the series is temporarily brought down to low levels before returning to its previous trend path. We analyse the effects on standard unit root tests and measures of persistence caused by the presence of these 'inliers'. We show a substantial bias in favour of concluding that the series is stationary and that shocks have temporary effects. We then construct appropriately corrected statistics which take into account the presence of the plans. These show, unlike the standard tests, that the stochastic behaviour of the inflation rate was indeed unstable over this period. Simulation results are presented to support the adequacy of our corrected statistics."] ["This paper develops the statistical theory for testing and estimating multiple change points in regression models. The rate of convergence and limiting distribution for the estimated parameters are obtained. Several test statistics are proposed to determine the existence as well as the number of change points. A partial structural change model is considered. The authors study both fixed and shrinking magnitudes of shifts. In addition, the models allow for serially correlated disturbances (mixingales). An estimation strategy for which the location of the breaks need not be simultaneously determined is discussed. Instead, the authors' method successively estimates each break point."] ['Many unit root and cointegration tests require an estimate of the spectral density function at frequency zero at some process. Kernel estimators based on weighted sums of autocovariances constructed using estimated residuals from an AR(1) regression are commonly used. However, it is known that with substantially correlated errors, the OLS estimate of the AR(1) parameter is severely biased. In this paper, we first show that this least squares bias induces a significant increase in the bias and mean-squared error of kernel-based estimators.<p>(This abstract was borrowed from another version of this item.)'] [' The authors consider unit root tests that allow a shift in trend at an unknown time. They focus on the additive outlier approach but also give results for the innovational outlier approach. Various methods of choosing the break date are considered. New limiting distributions are derived, including the case where a shift in trend occurs under the unit root null hypothesis. Limiting distributions are invariant to mean shifts but not to slope shifts. Simulations are used to assess finite sample size and power. The authors focus on the effects of a break under the null and the choice of break date. Copyright 1998 by Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association.'] ['No abstract is available for this item.'] ['This paper considers the problem of estimation in the linear regression model with multiple structural changes. We first survey the class of models analyzed by Bai and Perron (1996) and some of their asymptotic results. We then discuss in greater details a numerical algorithm, based on the principle of dynamic programming, that permits obtaining estimates of the break dates very efficiently even if there is a large number of changes. We also discuss issues related to the estimation of the number of breaks using information criteria. Simulation results are presented to illustrate the merits and drawbacks of such procedures. Finally, some empirical examples highlight the practical importance of our results. Cette \xc3\xa9tude consid\xc3\xa8re le probl\xc3\xa8me de l\xe2\x80\x99estimation de mod\xc3\xa8les de r\xc3\xa9gressions lin\xc3\xa9aires avec changements structurels multiples. Nous passons en revue la classe de mod\xc3\xa8les analys\xc3\xa9e par Bai et Perron (1996) et certains de leurs r\xc3\xa9sultats asymptotiques. Nous discutons plus en d\xc3\xa9tail un algorithme de calcul, bas\xc3\xa9 sur les principes de la programmation dynamique, qui permet d\xe2\x80\x99obtenir des estimations de fa\xc3\xa7on tr\xc3\xa8s efficace m\xc3\xaame si le nombre de points de rupture est \xc3\xa9lev\xc3\xa9. Ensuite, nous discutons du probl\xc3\xa8me d\xe2\x80\x99estimation de ce nombre de changements via certains crit\xc3\xa8res d\xe2\x80\x99information. Des r\xc3\xa9sultats de simulations sont pr\xc3\xa9sent\xc3\xa9s pour illustrer les m\xc3\xa9rites et les d\xc3\xa9fauts de ces proc\xc3\xa9dures. Finalement, certains r\xc3\xa9sultats empiriques mettent en \xc3\xa9vidence l\xe2\x80\x99importance pratique de nos r\xc3\xa9sultats.'] ['No abstract is available for this item.'] [' The authors consider the time-series behavior of the U.S. real interest rate from 1961 to 1986, using the methodology of James D. Hamilton (1989), by allowing three possible regimes affecting both the mean and variance. The results suggest that the ex-post real interest rate is essentially random with means and variances that are different for the periods 1961-73, 1973-80, and 1980-86. The inflation rate series also shows interesting shifts in both mean and variance. Series for the ex-ante real interest rate and expected inflation are constructed. Finally, the authors make clear how their results can explain some recent findings in the literature. Copyright 1996 by MIT Press.'] ['No abstract is available for this item.'] [' Many unit root tests have distorted sizes when the root of the error process is close to the unit circle. This paper analyses the properties of the Phillips-Perron tests and some of their variants in the problematic parameter space. We use local asymptotic analyses to explain why the Phillips-Perron tests suffer from severe size distortions regardless of the choice of the spectral density estimator but that the modified statistics show dramatic improvements in size when used in conjunction with a particular formulation of an autoregressive spectral density estimator. We explain why kernel based spectral density estimators aggravate the size problem in the Phillips-Perron tests and yield no size improvement to the modified statistics. The local asymptotic power of the modified statistics are also evaluated. These modified statistics are recommended as being useful in empirical work since they are free of. the size problems which have plagued many unit root tests, and they retain respectable power. Copyright 1996 by The Review of Economic Studies Limited.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' This note discusses some issues that arise when Johansen\'s (1991) framework is used to analyze cointegrating relationships among variables with deterministic linear time trends. We distinguish "stochastic" and "deterministic" cointegration, arguing that stochastic cointegration is sufficient for the existence of an error correction representation and that it is often the hypothesis of interest in empirical applications. We show that Johansen\'s (1991) method, which includes only a constant term in the estimated regression system, does not allow for stochastic cointegration. We propose to modify Johansen\'s method by including a vector of deterministic linear trends in the estimated model. We present tabulated critical values of the maximal eigen value and trace statistics appropriate for this case. We discuss the circumstances under which our modification may be useful.'] ['This paper is an introduction to unit root econometrics as applied in macroeconomics. The paper first discusses univariate time series analysis, emphasizing the following topics: alternative representations of unit root processes, unit root testing procedures, the power of unit root tests, and the interpretation of unit root econometrics in finite samples. A second part of the paper tackles similar issues in a multivariate context where cointegration is now the central concept. The paper reviews representation, testing, and estimation of multivariate time series models with some unit roots. Two important themes of this paper are first, the importance of correctly specifying deterministic components of the series; and second, the usefulness of unit root tests not as methods to uncover some "true relation" but as practical devices that can be used to impose reasonable restrictions on the data and to suggest what asymptotic distribution theory gives the best approximation to the finite-sample distribution of coefficient estimates and test statistics.'] [' The authors consider testing for a unit root in a time series with a structural change in mean occurring at an unknown date. They derive and tabulate the asymptotic distributions of the minimal t-statistic over all possible break points (and other related statistics) in the appropriate regressions. However, emphasis is given to the tabulation of finite sample critical values with particular attention given to the effect of various procedures to select the order of the estimated autoregressions. They apply the test to analyze the issue of purchasing power parity between the U.S. and the U.K. and Finland whose real exchange rates are characterized by apparent shifts in level when using particular price indices.'] [' This note provides a correction to the treatment of the asymptotic distribution of tests for a unit root for the additive outlier model presented in Perron (1990). It is shown that the tests, as stated for that case, have asymptotic distributions that depend on the correlation structure of the data even if the appropriate order of the autoregression is selected. The authors present a simple modification that yields statistics with the same asymptotic distributions (free of nuisance parameters) as stated earlier.'] ['This study presents an introduction to various concepts and issues related to autoregressive unit roots in the analysis of univariate time series models. The following topics are discussed: representation of the stochastic processes, testing procedures, issues related to the power of the tests, interpretation of the results and the practical usefulness of taking into account the problems caused by these unit roots. The study highlights the following points. First, unit root tests are highly dependent upon the specification of the deterministic component of the series. Secondly, tests for unit roots do not have much usefulness as a means of uncovering some kind of underlying "true process" but should be viewed rather as a device to 1) impose some useful restrictions, and ii) provide a guide to the appropriate asymptotic distribution to be used in subsequent steps. La pr\xc3\xa9sente \xc3\xa9tude fournit une introduction \xc3\xa0 certaines questions et concepts reli\xc3\xa9s aux racines unitaires autor\xc3\xa9gressives dans l\xe2\x80\x99analyse statistique de mod\xc3\xa8les de s\xc3\xa9ries chronologiques \xc3\xa0 une variable. On y aborde les sujets suivants : repr\xc3\xa9sentation des processus stochastiques, proc\xc3\xa9dures de tests, questions reli\xc3\xa9es \xc3\xa0 leur puissance, interpr\xc3\xa9tation des r\xc3\xa9sultats et utilit\xc3\xa9 pratique de prendre en compte des probl\xc3\xa8mes caus\xc3\xa9s par la pr\xc3\xa9sence de racines unitaires. L\xe2\x80\x99\xc3\xa9tude fait ressortir d\xe2\x80\x99une part l\xe2\x80\x99importance de la sp\xc3\xa9cification de la partie d\xc3\xa9terministe de la s\xc3\xa9rie, et d\xe2\x80\x99autre part l\xe2\x80\x99utilit\xc3\xa9 des tests de racines unitaires non pas en tant que moyens de d\xc3\xa9couvrir le \xc2\xab vrai \xc2\xbb processus sous-jacent mais en tant que moyens pratiques pour (i) imposer certaines restrictions utiles et (ii) permettre un guide quant \xc3\xa0 la classe appropri\xc3\xa9e de distributions asymptotiques \xc3\xa0 utiliser.'] ['This paper considers the consistency property of some test statistics based on a time series of data. While the usual consistency criterion is based on keeping the sampling interval fixed, we let the sampling interval take any equispaced path as the sample size increases to infinity. We consider tests of the null hypotheses of the random walk and randomness against positive autocorrelation (stationary or explosive). We show that tests of the unit root hypothesis based on the first-order correlation coefficient of the original data are consistent as long as the span of the data is increasing. Tests of the same hypothesis based on the first-order correlation coefficient of the first-differenced data are consistent against stationary alternatives only if the span is increasing at a rate greater than T \xc2\xbd , where T is the sample size. On the other hand, tests of the randomness hypothesis based on the first-order correlation coefficient applied to the original data are consistent as long as the span is not increasing too fast. We provide Monte Carlo evidence on the power, in finite samples, of the tests Studied allowing various combinations of span and sampling frequencies. It is found that the consistency properties summarize well the behavior of the power in finite samples. The power of tests for a unit root is more influenced by the span than the number of observations while tests of randomness are more powerful when a small sampling frequency is available.'] ['We consider the least-squares estimator in a strictly stationary first-order autoregression without an estimated intercept. We study its continuous time asymptotic distribution based on an asymptotic framework where the sampling interval converges to zero as the sample size increases. We derive a momentgenerating function which permits the calculation of percentage points and moments of this asymptotic distribution and assess the adequacy of the approximation to the finite sample distribution. In general, the approximation is excellent for values of the autoregressive parameter near one. We also consider the behavior of the power function of tests based on the normalized leastsquares estimator. Interesting nonmonotonic properties are uncovered. This analysis extends the study of Perron [15] and helps to provide explanations for the finite sample results established by Nankervis and Savin [13].'] [' We consider a first-order autoregression with i.i.d. errors and a fixed initial condition. The asymptotic distribution of the normalized least-squares estimator as the sampling interval converges to zero is shown to be the same as the exact distribution of the continuous-time estimator in an Ornstein-Uhlenbeck process. This asymptotic distribution permits explicit consideration of the effect of the initial condition. The appropriate moment-generating function is derived and used to tabulate the limiting distribution and probability density functions, the moments and some power functions. The adequacy of this asymptotic approximation is found to be excellent for values of the autoregressive parameter near one and any fixed initial condition. Copyright 1991 by The Econometric Society.'] ['No abstract is available for this item.'] [' The unit root hypothesis is examined allowing a possible one-time change in the level or in the slope of the trend function. When fluctuations are stationary around a breaking trend function, standard tests cannot reject the unit root, even asymptotically. Consistent tests are derived and applied to the Nelson-Plosser data set (allowing a change in level for the 1929 crash) and to the postwar quarterly real GNP series (allowing a change in slope after 1973). The unit root hypothesis is rejected at a high confidence level for most series. Fluctuations are stationary. The only persistent "shocks" are the 1929 crash and the 1973 oil price shock. Copyright 1989 by The Econometric Society.'] ['We tabulate the limiting cumulative distribution and probability density functions of the least-squares estimator in a first-order autoregressive regression when the true model is near-integrated in the sense of Phillips. The results are obtained using an exact numerical method which integrates the appropriate limiting moment generating function. The adequacy of the approximation is examined for various first-order autoregressive processes with a root close to unity.'] ['This Paper Presents a Summary of Recent Work on a New Methodology to Test for the Presence of a Unit Root in Univariate Time Series Models. the Stochastic Framework Is Quite General. While the Dickey-Fuller Approach Accounts for the Autocorrelation of the First-Differences of a Serie in a Paremetric Fashion by Estimating Additional Nuisance Parameters, This New Approach Deals with This Phenomenon in a Nonparametric Way. We Apply These New Tests to Reassess Recent Findings on the Behavior of Common Macroeconomic Time Series, Including the Various Series Studies by Nelson and Plosser (1982).<p>(This abstract was borrowed from another version of this item.)'] ['Stock and Watson (1986) Tests the Hypothesis That Real Per Capita Gnp Has a Unit Root by Using a Test Statistic Due to Phillips (1985) Which Incorporates a Nonparametric Correction for the Serial Correlation Induced by System and Error Dynamics. the Version of This Test That Is Used by Stock and Watson Does Not Accomodate the Presence of a Drift and to Compensate They Detrend the Series by Extracting a 1.5% Annual Trend Growth. We Use a Version of This Class of Nonparametric Tests, Developed by Phillips and Perron (1986), Which Allows for an Estimated Drift and Reassess the Stock and Watson Findings.<p>(This abstract was borrowed from another version of this item.)'] ['Power functions of tests of the random walk hypothesis versus stationary first order autoregressive alternatives are tabulated for samples of fixed span but various frequencies of observation.<p>(This abstract was borrowed from another version of this item.)']