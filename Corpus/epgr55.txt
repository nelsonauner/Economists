 ['This paper shows that a linear process with breaks can mimic autocorrelations and other properties of I(d) processes, where d can be a fraction. Simulation results show that S&amp;P; 500 absolute stock returns are more likely to show the "long memory" property because of the presence of breaks in the series rather than an I(d) process.'] ['No abstract is available for this item.'] [" Phillips' (1958) original curve involves a nonlinear relationship between inflation and unemployment. We consider how his original results change due to updated theoretic and empirical studies, increased computer power, enlarged datasets, increases in data frequency and developed time series econometric models. In the linear models, there was weak causation from unemployment to inflation. Rather than using any of the many nonlinear models that are now available, we adopt a time-varying parameter linear model as their convenient proxy, which empirically supports Phillips' use of nonlinear model form and causation, but the strength of this result is much weaker in recent periods."] ['No abstract is available for this item.'] ['Even though the trend components of economic time series were among the first to be distinguished, even today the trend remains relatively little understood. As Phillips (2005) notes, no one understands trends, but everyone sees them in the data. Economists and econometricians can give plenty of examples of trends, such as straight lines, exponentials or polynomials in time, and also forms of random walks, but these are merely examples. Individuals or groups do have their own personal definitions, but these diverse approaches illustrate the lack of a generally accepted definition of a trend. They also suggest a richness of alternatives to consider, both individually and jointly. Here, we make a variety of observations about trends, and based on these, we offer working definitions of various kinds of trends. We emphasize that these are working definitions, as our purpose here is to invite discussion, not to settle matters once and for all. Our hope is that our discussion here may facilitate development of increasingly better methods for prediction, estimation and hypothesis testing for non-stationary time-series data, and ultimately may enable decision makers to make more informed decisions.'] ['No abstract is available for this item.'] ['This paper describes how the notion of cointegration came about, and discusses some generalizations to indicate where the topic may go next. In particular, some issues in the analysis of possibly cointegrated quantile time series are discussed.'] ['No abstract is available for this item.'] ['Almost all fisher models assume time-invariant parameter values of the underlying biological growth function except for an i.i.d. error term. We examine the economic implications of cyclical growth parameters in both single and multi-species models, which are frequently observed in many real-world fisheries. Neither optimal harvest rates nor optimal escapement (remaining fish stock after fishing) remain constant as current models would predict. The amplitude of the optimal escapement is incrasing in the amplitude of the biological growth function. Moreover, the optimal harvest rate lags the cycle of the biological growth function, i.e., the highest harvest rate is observed after biological conditionos have started to decline and the optimum escapement level has alrady decreased. This is in sharp contrast to current policies which are in phase with biological conditions and hence imply and increasea/decrease in harvest quotas when the biological system is improving/deteriorating. In our model, harvest closures are only optimal during time periods when growth parameters are improving most rapidly. We show that once the periodicity of the biological growth function is incorporated, many of the traditional policy prescriptions reverse.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] [' This is a report on our studies of the systematical use of mixed-frequency datasets. We suggest that the use of high-frequency data in forecasting economic aggregates can increase the accuracy of forecasts. The best way of using this information is to build a single model that relates the data of all frequencies, for example, an ARMA model with missing observations. As an application of linking series generated at different frequencies, we show that the use of a monthly industrial production index improves the predictability of the quarterly GNP. Copyright \xc2\xa9 2008 John Wiley &amp; Sons, Ltd.'] ["Although linear models have been the central focus of econometrics for most of the twentieth century, great developments in non-linear models took place from the latter part of the century. This paper questions the future development of non-linear models in economics and shows (via White's Theorem) that any non-linear model can be approximated by a time-varying parameter linear model. Compared with non-linear models, multi-step forecasts are more easily prepared using time-varying parameter models, while they are also more readily interpretable and theoretical results on aggregation are straightforward to obtain. Nevertheless, there is some evidence that subtle non-linearities may exist in macroeconomic time series."] ['No abstract is available for this item.'] [' Brazil has long ago removed most of the perverse government incentives that stimulated massive deforestation in the Amazon in the 1970s and 1980s, but the highly controversial policy concerning road building still remains. While data is now abundantly available due to the constant satellite surveillance of the Amazon, the analytical methods typically used to analyze the impact of roads on natural vegetation cover are methodologically weak and not very helpful in guiding public policy. This article discusses the respective weaknesses of typical geographic information system (GIS) analysis and typical municipality-level regression analysis, and shows what would be needed to construct an ideal model of deforestation processes. It also presents an alternative approach that is much less demanding in terms of modeling and estimation and is more useful for policymakers. Copyright Springer Japan 2007'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['A definition for a common factor for bivariate time series is suggested by considering the decomposition of the conditional density into the product of the marginals and the copula,\xef\xbf\xbdwith the conditioning variable being a common factor if it does not directly enter the copula.\xef\xbf\xbd The links of this definition with a common factor being a dominant feature in standard linear representations is shown. An application using a business cycle indicator as the common factor in the relationship between U.S. income and consumption found that both series held the factor\xef\xbf\xbd in their marginals but not in the copula.<p>(This abstract was borrowed from another version of this item.)'] [' One method of describing the properties of a fitted autoregressive model of order p is to show the p roots that are implied by the lag operator. Considering autoregressive models fitted to 215 US macro series, with lags chosen by either the Bayesian or Schwarz information criteria or Akaike information criteria, the roots are found to constitute a distinctive pattern. Later analysis suggests that much of this pattern occurs because of overfitting of the models. An extension of the results shows that they have some practical multivariate time-series modelling implications. Copyright 2006 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['This paper introduces a new type of nonlinear model, the min-max model, and analyzes the properties for a pair of series. Stability conditions of this system are given for the nonlinearly integrated bivariate series. Under these stability conditions, the difference of the two series has a threshold-type nonlinearity. One can construct a threshold error correction model from min-max processes. Neglected nonlinearity tests are applied, to the univariate series and to the system, to detect nonlinearity, and it turns out that the tests using the system have better power. We apply the min-max model to U.S. Treasury bill and commercial paper interest rates. The spread of these interest rates shows a threshold-type nonlinearity, and this model outperforms a linear model in terms of its predictability out-of-sample<p>(This abstract was borrowed from another version of this item.)'] [' The modern world has influenced the approach to empirical modeling and consequently the approach to methodology in general. The question of whether to base a model on an economic theory is easier when several models can be constructed, but an empirical evaluation analysis is required. Starting with a widely specified model and using a reduction procedure is currently a popular process; it is unclear if the reduction should be to a single or to a few alternatives. New methodologies are required for conditional predictive distributions, which are the models of the future. (JEL B41, C50) Copyright 2005, Oxford University Press.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' The paper outlines a methodology for analyzing daily stock returns that relinquishes the assumption of global stationarity. Giving up this common working hypothesis reflects our belief that fundamental features of the financial markets are continuously and significantly changing. Our approach approximates the nonstationary data locally by stationary models. The methodology is applied to the S&amp;P; 500 series of returns covering a period of over seventy years of market activity. We find most of the dynamics of this time series to be concentrated in shifts of the unconditional variance. The forecasts based on our nonstationary unconditional modeling were found to be superior to those obtained in a stationary long-memory framework and to those based on a stationary Garch(1, 1) data-generating process. \xc2\xa9 2005 President and Fellows of Harvard College and the Massachusetts Institute of Technology.'] ['No abstract is available for this item.'] ['The efficient market hypothesis gives rise to forecasting tests that mirror those adopted when testing the optimality of a forecast in the context of a given information set. However, there are also important differences arising from the fact that market efficiency tests rely on establishing profitable trading opportunities in \xe2\x80\x98real time\xe2\x80\x99. Forecasters constantly search for predictable patterns and affect prices when they attempt to exploit trading opportunities. Stable forecasting patterns are therefore unlikely to persist for long periods of time and will self-destruct when discovered by a large number of investors. This gives rise to nonstationarities in the time series of financial returns and complicates both formal tests of market efficiency and the search for successful forecasting approaches.<p>(This abstract was borrowed from another version of this item.)'] ['The two prize winners in Economics this year would describe themselves as "Econometricians," so I thought that I should start by explaining that term. One can begin with the ancient subject of Mathematics which is largely concerned with the discovery of relationships between deterministic variables using a rigorous argument. (A deterministic variable is one whose value is known with certainty.) However, by the middle of the last millennium it became clear that some objects were not deterministic, they had to be described with the use of probabilities, so that Mathematics grew a substantial sub-field known as "Statistics." This later became involved with the analysis of data and a number of methods have been developed for data having what may be called "standard properties."<p>(This abstract was borrowed from another version of this item.)'] ["In this paper we compare the relative efficiency of different methods of forecasting the aggregate of spatially correlated variables. Small sample simulations confirm the asymptotic result that improved forecasting performance can be obtained by imposing a priori constraints on the amount of spatial correlation in the system. One way to do so is to aggregate forecasts from a Space-Time Autoregressive model (Cliff et al., 1975), which offers a solution to the 'curse of dimensionality' that arises when forecasting with VARs. We also show that ignoring spatial correlation, even when it is weak, leads to highly inaccurate forecasts. Finally, if the system satisfies a 'poolability' condition, there is a benefit in forecasting the aggregate variable directly.<p>(This abstract was borrowed from another version of this item.)"] [' Stock &amp; Watson (1999) consider the relative quality of different univariate forecasting techniques. This paper extends their study on forecasting practice, comparing the forecasting performance of two popular model selection procedures, the Akaike information criterion (AIC) and the Bayesian information criterion (BIC). This paper considers several topics: how AIC and BIC choose lags in autoregressive models on actual series, how models so selected forecast relative to an AR(4) model, the effect of using a maximum lag on model selection, and the forecasting performance of combining AR(4), AIC, and BIC models with an equal weight.'] ['No abstract is available for this item.'] [' A transformed metric entropy measure of dependence is studied which satisfies many desirable properties, including being a proper measure of distance. It is capable of good performance in identifying dependence even in possibly nonlinear time series, and is applicable for both continuous and discrete variables. A nonparametric kernel density implementation is considered here for many stylized models including linear and nonlinear MA, AR, GARCH, integrated series and chaotic dynamics. A related permutation test of independence is proposed and compared with several alternatives. Copyright 2004 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' The paper asks the question - as time series analysis moves from consideration of conditional mean values and variances to unconditional distributions, do some of the familiar concepts devised for the first two moments continue to be helpful in the more general area? Most seem to generalize fairly easy, such as the concepts of breaks, seasonality, trends and regime switching. Forecasting is more difficult, as forecasts become distributions, as do forecast errors. Persistence can be defined and also common factors by using the idea of a copula. Aggregation is more difficult but causality and controllability can be defined. The study of the time series of quantiles becomes more relevant. Copyright 2003 Blackwell Publishing Ltd.'] [' Building large models, with little dynamics, was long considered to be an alternative to small dimensional time series models involving many lags. The advantages of one modelling methodology are compared to others; such as the size of the model, the use of economic theory, and simultaneity in specification. The question of how to evaluate the possible relative advantages of these alternatives is discussed. The conclusion is that in the future, time series models have to become larger, that is, involve more variables and that some lessons can be learnt from the construction of current large econometric models. Copyright \xc2\xa9 2002 John Wiley &amp; Sons, Ltd.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['Financial market volatility is an important input for investment, option pricing, and financial market regulation. The emphasis of this review article is on forecasting instead of modelling; it compares the volatility forecasting findings in 93 papers published and written in the last two decades. Provided in this paper as well are volatility definitions, insights into problematic issues of forecast evaluation, data frequency, extreme values and the measurement of "actual" volatility. We compare volatility forecasting performance of two main approaches; historical volatility models and volatility implied from options. Forecasting results are compared across different asset classes and geographical regions.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['This paper shows that the properties of nonlinear transformations of a fractionally integrated process depend strongly on whether the initial series is stationary or not. Transforming a stationary Gaussian I(d) process with d &gt; 0 leads to a long-memory process with the same or a smaller long-memory parameter depending on the Hermite rank of the transformation. Any nonlinear transformation of an antipersistent Gaussian I(d) process is I(0). For non-stationary I(d) processes, every integer power transformation is non-stationary and exhibits a deterministic trend in mean and in variance. In particular, the square of a non-stationary Gaussian I(d) process still has long memory with parameter d, whereas the square of a stationary Gaussian I(d) process shows less dependence than the initial process. Simulation results for other transformations are also discussed.<p>(This abstract was borrowed from another version of this item.)'] ['This paper presents evidence, using data from Consensus Forecasts, that there is an "attraction" to conform to the mean forecasts; in other words, views expressed by other forecasters in the previous period influence individuals\' current forecast. The paper then discusses--and provides further evidence on--two important implications of this finding. The first is that the forecasting performance of these groups may be severely affected by the detected imitation behavior and lead to convergence to a value that is not the "right" target. Second, since the forecasts are not independent, the common practice of using the standard deviation from the forecasts\' distribution, as if they were standard errors of the estimated mean, is not warranted. Copyright 2002, International Monetary Fund'] [' Investor risk is a complicated concept in practice and is not well captured by measures of volatility as is well understood by uncertainty theory. Rather than asking statisticians to attempt to measure risk, it may be better to listen to decision theorists, but their suggestions are not very practical. Diversification is clearly helpful in reducing risk but the risk level of one portfolio cannot be measured without knowing the risks of other major portfolios. A meta-analysis can be used to compare alternative volatility measures in terms of their forecasting utility. Copyright \xc2\xa9 2002 John Wiley &amp; Sons, Ltd.'] ['It is pointed out that if the generating mechanism is a fraction integrated process I(d), where d can be less than 1/2, but a simple ARMA model is fitted, a consistent estimation procedure is likely to produce a unit root. Thus the properties of the fitted model will be quite unlike those of the generating mechanism.'] ['No abstract is available for this item.'] [' A spurious regression occurs when a pair of independent series, but with strong temporal properties, are found apparently to be related according to standard inference in an OLS regression. Although this is well known to occur with pairs of independent unit root processes, this paper finds evidence that similar results are found with positively autocorrelated autoregressive series or long moving averages. This occurs regardless of the sample size and for various distributions of the error terms.'] ['No abstract is available for this item.'] [' This paper establishes practical criteria for selecting amongst hypothetical data generating processes in cases where the series has long memory and exponential distribution which implies that the innovations have extremely fat tails.'] ['No abstract is available for this item.'] [" This paper, using daily returns on 30 Dow Jones Industrial stocks for the period 1991-1999, investigates the possibility of portfolio diversification when there are negative large movements in the stock returns (i.e.\xef\xbf\xbdwhen the market is bearish). We estimate the quantiles of stock return distributions using non-parametric and parametric methods that are widely being used in measuring value-at-risk (VaR). We find that the average conditional correlation of 30 stocks is much higher when the large movements are negative than that when the market is 'usual'. Further, we find that, contrary to the results of previous studies, there is no notable difference between the average conditional correlations when the large movements are positive and when the market is 'usual'. Moreover, it is evident from the results of the conditional CAPM that the portfolio's diversifiable and non-diversifiable risks, as measured by the error variance of the CAPM and beta respectively, are highly unstable when the market is bearish than that when it is 'usual' or bullish. The overall results suggest that the possibility of portfolio diversification would be eroded when the stock market is bearish. These findings have implications for portfolio diversification and risk management in particular and for finance in general. The ideas presented in this paper can be utilized for testing contagion in the international financial markets, a much-researched topic in international finance."] ['This paper applies recently developed unit root and cointegration models to determine the appropriate Granger causality relations between stock prices and exchange rates using recent Asian flu data. Coupled with impulse response functions, it is found that data from Japan and Thailand are in agreement with this approach, so that exchange rates leads stock prices with positive correlation. On the other hand, data of Taiwan suggests the result predicted by the portfolio approach: stock prices lead exchange rates with negative correlation. Data from Indonesia, Korea, Malaysia, and the Philippines indicate strong feedback relations while that of Singapore fails to reveal any recognizable pattern<p>(This abstract was borrowed from another version of this item.)'] [' Models that may appear to have different properties may in fact produce residuals that differ only in subtle ways. By analysing the relationships between model residuals the problems in distinguishing between models can perhaps be discovered, as illustrated by the econometric examples considered. Regressing residuals gives the long-memory residual, which is the difference between two models, but this difference is very subtle and deeply hidden, which explains why the traditional standard technique does not find this difference.'] ['This paper shows how a simple univariate stationary nonlinear process has an autocorrelation function suggesting that the underlying process has a long memory, although that is not the case. The conclusion is that just considering linear properties of a process may be misleading.<p>(This abstract was borrowed from another version of this item.)'] ['The cost functions used to form forecasts in practice may be quite different than the squared costs that is often assumed in forecast theory. The impact on evaluation procedures is determined and simple properties for the derivate of the cost function of the errors are found to provide simple tests of optimality. For a very limited class of situations are forecasts based on conditional means optimal, generally, the econometricians needs to provide the whole conditional predicted distribution. Implications for multi-step forecasts and the combination of forecasts are briefly considered.'] ['No abstract is available for this item.'] [' Hoover and Perez?s results show that the general-to-specific approach performs well if the search for a linear and stable model specification is conducted in a local neighborhood around the truth. However, non-linearities, outliers, parameter instability and the absence of even approximate knowledge of the true data generating process means that in practice this approach is unlikely to perform up to the standards reported in the papers.'] [' This paper investigates the interaction between aggregation and nonlinearity through a monte carlo study. Various tests for neglected nonlinearity are used to compare the power of the tests for different nonlinear models to different levels of aggregation. Three types of aggregation, namely, cross-sectional aggregation, temporal aggregation and systematic sampling are considered. Aggregation is inclined to simplify nonlinearity. The degree to which nonlinearity is reduced depends on the importance of common factor and extent of the aggregation. The effect is larger when the size of common factor is smaller and when the extent of the aggregation is larger.'] ['This paper analyzes the effects of individual-specific size factors in a dynamic panel regression model. Theory and simulation show that an individual-specific size factor, with a fat-tailed distribution or a time-varying property, may cause spurious stochastics. If a pair of panel variables depends on size in some way, then they appear to find a strong relationship, if the size variable is not used in the regression, even if the variables are otherwise independent. Moreover, forecasts based on models that have omitted size-factors are affected seriously by the property of the size-factors. A pooling regression with very short time-series appears to fit well in sample, but forecasts poorly out-of-sample if the neglected individual-specific size-factor has a fat-tailed distribution.'] [' This article develops critical values to test the null hypothesis of a unit root against the alternative of stationarity with asymmetric adjustment. Specific attention is paid to threshold and momentum threshold autoregressive processes. The standard Dickey-Fuller tests emerge as a special case. Within a reasonable range of adjustment parameters, the power of the new tests is shown to be greater than that of the corresponding Dickey-Fuller test. The use of the tests is illustrated using the term structure of interest rates. It is shown that the movements toward the long-run equilibrium relationship are best estimated as an asymmetric process.'] ['No abstract is available for this item.'] [' The notion of separation in cointegrated systems helps identifying possible sub-system structures that may reduce the complexity of larger systems by yielding a more parsimonious representation of the time series. In this paper the authors demonstrate that although the subsystem cointegration analysis in such systems can be conducted in case of both completely and partially separated systems, the dual approach, i.e. calculation of the common stochastic trends, may turn out to yield properties of the trends that differ depending upon the type of separation under consideration. In particular, they demonstrate how persistent-transitory (P-T) decompositions and long- and short-memory factorizations of a multivariate time series will interact across systems when considering the presence (or absence) of different types of separation. Generalizations to non-linear error correction models are briefly discussed. Copyright 1997 by Blackwell Publishing Ltd'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['A class of nonlinear processes which have a root that is not constant, but is stochastic, and varying around unity is introduced. Th eprocess can be stationary for some periods, and mildly explosive for others.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['There exist a variety of reasons for the failure to find a unique cointegrating relationship between economic time series where one would normally be expected on economic theory grounds. Among these are the testing procedure (e.g., Engle and Granger (1987) or Johansen (1991), the span of the data set (Hendry (1995), Perron (1989)), the choice of the lag length in generating the test statistic (Banerjee et al. (1993)), the presence of structural breaks (Gregory and Hansen (1996)), and the presence of cointegration only beyond some threshold (Balke and Fomby (1996)). In this paper we propose the concept of regime sensitive cointegration whereby the underlying series need not be cointegrated at all times. We show that cointegration can be switched off when a common stochastic trend is added. Alternatively, cointegration can be switched on or off because series normally believed to contain a unit actually do not. This implies that a linear combination of such variables need not be cointegrated. To illustrate the concept empirically, we test the hypothesis of interest rate parity, and related hypotheses, using daily eurorates for the US and Canada.<p>(This abstract was borrowed from another version of this item.)'] [' A number of topics are discussed concerning how economic forecasts can be improved in quality or at least in presentation. These include the following: using 50% uncertainty intervals rather than 95%; noting that even though forecasters use many different techniques, they are all occasionally incorrect in the same direction; that there is a tendency to underestimate changes; that some expectations and recently available data are used insufficiently; lagged forecasts errors can help compensate for structural breaks; series that are more forecastable could be emphasized and that present methods of evaluating forecasts do not capture the useful properties of some methods compared to alternatives. Copyright 1996 by John Wiley &amp; Sons, Ltd.'] [' The authors investigate whether seasonal adjustment procedures are linear data transformations. This question was addressed by A. H. Young (1968) and is important for the estimation of regression models with seasonally adjustment data. The authors focus on the X-11 program and rely on simulation evidence, involving linear unobserved component autorgressive integrated moving average models. They define and test a set of properties for the adequacy of a linear approximation to a seasonal adjustment filter. Next, the authors study the effect of X-11 on regression statistics assessing the statistical significance between economic variables. Several empirical results involving economic data are also reported.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' The study of cointegration in large systems requires a reduction of their dimensionality. To achieve this, the authors propose to obtain the I(1) common factors in every subsystem and then analyze cointegration among them. A new way of estimating long-memory components is proposed. The identification of these I(1) common factors is achieved by imposing that they be linear combinations of the original variables X[subscript]t, and that the error correction terms do not cause them at low frequencies. Estimation is done from an error correction model, which makes it possible to test hypotheses on the common factors using standard chi-squared tests.'] [' A definition of extended memory is provided, generalizing the ideas of long memory and persistence, based on the properties of forecasts over long horizons. Specification of nonlinear models with variables having extended memory is considered in terms of the balance of an equation and it is suggested that many more types of misspecification can occur than with usual situations and could produce important specification errors. Tests of linearity and standard methods of nonlinear modeling are briefly considered and advice is given on circumstances in which they can be used. Copyright 1995 by The Econometric Society.'] ['The expected absolute return belongs to a class of risk measure derived by Luce (1980) from axioms. The paper considers the time series properties of and also the marginal distribution properties, for various properties of ?. Using a long daily stock index series it is found that the autocorrelations decline slowly for all positive ? but this "long-memory" property is strongest for ? = 1, the absolute return. The moments of absolute returns, after removal of a few outliers, suggest that an exponential distribution is appropriate.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [" Building models of nonlinear relationships are inherently more difficult than linear ones. There are more possibilities, many more parameters, and, thus, more mistakes can be made. It is suggested that a strategy be applied when attempting such modeling involving testing for linearity, considering just a few model types of parsimonious form and then performing postsample evaluation of the resulting models compared to a linear one. The strategy proposed is a 'simple-to-general'one and the application of a heteroskedasticity correction is not recommended. Copyright 1993 by The Economic Society of Australia."] ['No abstract is available for this item.'] [' An attempt is made to link together earlier definitions of the long run found in micro and macro economics with recent developments in econometrics, specifically cointegration. It is suggested that the links are not strong and that most of the previou s work in econometric theory has been unnecessarily overprecise. The possibility of embedding cointegration theory into a very general, nonlinear theory is suggested. An example uses a nonlinear relationship between U.K. short- and long-run interest rates proposed by Frank Paish (1966). Copyright 1993 by Royal Economic Society.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' RegRESET is a regression post-processor which performs Ramsey\'s RESET test. Use this after running a linear regression to test the specification of that regression. Ramsey(1969): "Tests for specification errors in classical Least-Squares Regression Analysis," JRSS-B, vol 32, 350-371. Lee, White and Granger(1992), "Testing for Neglected Non-linearities in Time Series Models," J. of Econometrics, vol 56, 269-290.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' We consider two ways of distinguishing deterministic time-series from stochastic white noise; the Grassberger-Procaccia correlation exponent test and the Brock, Dechert, Scheinkman (or BDS) test. Using simulated data to test the power of these tests, the correlation exponent test can distinguish white noise from chaos. It cannot distinguish white noise from chaos mixed with a small amount of white noise. With i.i.d. as the null, the BDS correctly rejects the null when the data are deterministic chaos. Although the BDS test may also reject the null even when the data are stochastic, it may be useful in distinguishing between linear and nonlinear stochastic processes. Copyright 1992 by John Wiley &amp; Sons, Ltd.'] ['No abstract is available for this item.'] ['This paper examines the evaluation of models claimed to be relevant for policy making purposes. A number of tests are proposed to determine the usefulness of such models in the policy making process. These tests are applied to three empirical examples.<p>(This abstract was borrowed from another version of this item.)'] [" This paper shows that yields to maturity of U.S. Treasury bills are cointegrated and that, during periods when the Federal Reserve specifically targeted short-term interest rates, the spreads between yields of different maturity define the cointegrating vectors. This cointegrating relationship implies that a single nonstationary common factor underlies the time-series behavior of each yield to maturity and that risk premia are stationary. An error-correction model that uses spreads as the error-correction terms is unstable over the Federal Reserve's policy regime changes, but a model using post 1982 data is stable and is shown to be useful for forecasting changes in yields. Copyright 1992 by MIT Press."] [' Various aspects of the analysis of nonlinearities are surveyed in this paper. A possibility of distinguishing between a (low-dimensional) deterministic chaotic process and a white noise stochastic process using estimates of the correlation dimension is discussed. It is concluded that there is no evidence of chaos--as opposed to nonlinearity--in the economic data. The modes of testing for nonlinearity are briefly surveyed, with particular attention paid to a new test based on a neural network specification. It is found that aggregation can reduce nonlinearity and a definition of long memory is proposed that suggests a nonlinear generalization of cointegration. Copyright 1991 by The editors of the Scandinavian Journal of Economics.'] ['No abstract is available for this item.'] [' Performs the calculations from Granger and Uhlig(1990), "Reasonable Extreme Bounds Analysis", J. of Econometrics, vol. 44, 159-170.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['This paper estimates models of electricity and gas consumption for individual households using the Miracle 4 to 6 data sets collected by San Diego Gas and Electricity Company. Two types of model were constructed: the first involves typical end-use models with consumption explained by appliance ownership, household demographic characteristics, house dimensions and household income; the second class uses these variables plus consumption data for the previous year. The latter models consistently fitted better, while the end-use variables afforded little explanatory power. The results thus suggest that simple end-use models are of little value, at least for short-run forecasting. Their use for long-run forecasting has yet to be evaluated.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['Many observed macrovariables are simple aggregates over a large number of microunits. It is pointed out that the generating process of the macrovariables is largely determined by the common factors in the generating mechanisms of the microvariables, even though these factors may be very unimportant at the microlevel. It follows that macrorelationships are simpler than the complete microrelationships, but that empirical investigations of microrelationships may not catch those components, containing common factors, which will determine the macrorelationship. It is also shown that an aggregate expectation or forecast is simply the common factor component of the individual agents expectations.'] ['Forecasts based on two information sets, one of which includes the other plus additional causal variables are considered. Given a general cost function of forecast errors, it is shown that the expected cost is smaller for the information set that includes the causal variables.'] [' The relationship between cointegration and error correction models, first suggested by Granger, is here extended and used to develop estimation procedures, tests, and empirical examples. A vector of time series is said to be cointegrated with cointegrating vector a if each element is stationary only after differencing while linear combinations a8xt are themselves stationary. A representation theorem connects the moving average , autoregressive, and error correction representations for cointegrated systems. A simple but asymptotically efficient two-step estimator is proposed and applied. Tests for cointegration are suggested and examined by Monte Carlo simulation. A series of examples are presented. Copyright 1987 by The Econometric Society.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['Because utilities bill their residential and commercial customers by cycle on each working day of the month, the calculation of weather variables to associate with monthly sales data is complicated. We examined three different methods of calculating weather variables. 1.(1) For a utility that bills monthly, the most appropriate method is to calculate daily weather measures, then take a weighted sum of these daily measures over the current and previous month, with the weights for each day being proportional to the number of customers whose consumption on that day is billed in the current month. When weather variables are calculated in this way, accurate econometric models of electricity sales can be estimated.2.(2) If data on the number of customers in each cycle are unavailable, the first procedure can be applied under an assumption concerning the number of customers consuming on each day. For the three utilities in the study, using these approximate weights reduced the model accuracy noticeably but not substantially, implying: if data on the number of customers in each cycle can be retrieved, the effort expended in doing so will be rewarded with more accurate models; however, if such data are impossible to obtain, fairly accurate models can still be estimated.3.(3) The easiest method for calculating weather variables is to ignore the billing cycle phenomenon and take an unweighted sum of daily weather measures over days in the previous or current, or both, months. Our estimation results indicate that these simple measures decrease the accuracy of the models substantially, implying that the additional effort required to calculate weather variables that reflect the billing cycle phenomenon is clearly worthwhile in terms of increased model accuracy.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['A generalized definition of invertibility is proposed and applied to linear, non-linear and bilinear models. It is shown that some recently studied non-linear models are not invertible, but conditions for invertibility can be achieved for the other models.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.']