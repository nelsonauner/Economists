 ['It has been known since Phillips and Hansen (1990) that cointegrated systems can be consistently estimated using stochastic trend instruments that are independent of the system variables. A similar phenomenon occurs with deterministically trending instruments. The present work shows that such \xe2\x80\x9cirrelevant\xe2\x80\x9d deterministic trend instruments may be systematically used to produce asymptotically efficient estimates of a cointegrated system. The approach is convenient in practice, involves only linear instrumental variables estimation, and is a straightforward one step procedure with no loss of degrees of freedom in estimation. Simulations reveal that the procedure works well in practice both in terms of point and interval estimation, having little finite sample bias and less finite sample dispersion than other popular cointegrating regression procedures such as reduced rank VAR regression, fully modified least squares, and dynamic OLS. The procedure is a form of maximum likelihood estimation where the likelihood is constructed for data projected onto the trending instruments. This \xe2\x80\x9ctrend likelihood\xe2\x80\x9d is related to the notion of the local Whittle likelihood but avoids frequency domain issues.'] ['No abstract is available for this item.'] ['This paper introduces a new estimation method for dynamic panel models with fixed effects and AR(p) idiosyncratic errors. The proposed estimator uses a novel form of systematic differencing, called X-differencing, that eliminates fixed effects and retains information and signal strength in cases where there is a root at or near unity. The resulting "panel fully aggregated" estimator (PFAE) is obtained by pooled least squares on the system of X-differenced equations. The method is simple to implement, free from bias for all parameter values, including unit root cases, and has strong asymptotic and finite sample performance characteristics that dominate other procedures, such as bias corrected least squares, GMM and system GMM methods. The asymptotic theory holds as long as the cross section (n) or time series (T) sample size is large, regardless of the n/T ratio, which makes the approach appealing for practical work. In the time series AR(1) case (n = 1), the FAE estimator has a limit distribution with smaller bias and variance than the maximum likelihood estimator (MLE) when the autoregressive coefficient is at or near unity and the same limit distribution as the MLE in the stationary case, so the advantages of the approach continue to hold for fixed and even small n. For panel data modeling purposes, a general-to-specific selection rule is suggested for choosing the lag parameter p and the procedure works in a standard manner, aiding practical implementation. The PFAE estimation method is also applicable to dynamic panel models with exogenous regressors. Some simulation results are reported giving comparisons with other dynamic panel estimation methods.<p>(This abstract was borrowed from another version of this item.)'] ['The paper proposes a novel inference procedure for long-horizon predictive regression with persistent regressors, allowing the autoregressive roots to lie in a wide vicinity of unity. The invalidity of conventional tests when regressors are persistent has led to a large literature dealing with inference in predictive regressions with local to unity regressors. Magdalinos and Phillips (2009b) recently developed a new framework of extended IV procedures (IVX) that enables robust chi-square testing for a wider class of persistent regressors. We extend this robust procedure to an even wider parameter space in the vicinity of unity and apply the methods to long-horizon predictive regression. Existing methods in this model, which rely on simulated critical values by inverting tests under local to unity conditions, cannot be easily extended beyond the scalar regressor case or to wider autoregressive parametrizations. In contrast, the methods developed here lead to standard chi-square tests, allow for multivariate regressors, and include predictive processes whose roots may lie in a wide vicinity of unity. As such they have many potential applications in predictive regression. In addition to asymptotics under the null hypothesis of no predictability, the paper investigates validity under the alternative, showing how balance in the regression may be achieved through the use of localizing coefficients and developing local asymptotic power properties under such alternatives. These results help to explain some of the empirical difficulties that have been encountered in establishing predictability of stock returns.'] ['First difference maximum likelihood (FDML) seems an attractive estimation methodology in dynamic panel data modeling because differencing eliminates fixed effects and, in the case of a unit root, differencing transforms the data to stationarity, thereby addressing both incidental parameter problems and the possible effects of nonstationarity. This paper draws attention to certain pathologies that arise in the use of FDML that have gone unnoticed in the literature and that affect both finite sample performance and asymptotics. FDML uses the Gaussian likelihood function for first differenced data and parameter estimation is based on the whole domain over which the log-likelihood is defined. However, extending the domain of the likelihood beyond the stationary region has certain consequences that have a major effect on finite sample and asymptotic performance. First, the extended likelihood is not the true likelihood even in the Gaussian case and it has a finite upper bound of definition. Second, it is often bimodal, and one of its peaks can be so peculiar that numerical maximization of the extended likelihood frequently fails to locate the global maximum. As a result of these pathologies, the FDML estimator is a restricted estimator, numerical implementation is not straightforward and asymptotics are hard to derive in cases where the peculiarity occurs with non-negligible probabilities. The peculiarities in the likelihood are found to be particularly marked in time series with a unit root. In this case, the asymptotic distribution of the FDMLE has bounded support and its density is infinite at the upper bound when the time series sample size T\xe2\x86\x92\xe2\x88\x9e. As the panel width n\xe2\x86\x92\xe2\x88\x9e the pathology is removed and the limit theory is normal. This result applies even for T fixed and we present an expression for the asymptotic distribution which does not depend on the time dimension. We also show how this limit theory depends on the form of the extended likelihood.'] ['Nielsen (Working paper, University of Oxford, 2009) shows that vector autoregression is inconsistent when there are common explosive roots with geometric multiplicity greater than unity. This paper discusses that result, provides a coexplosive system extension and an illustrative example that helps to explain the finding, gives a consistent instrumental variable procedure, and reports some simulations. Some exact limit distribution theory is derived and a useful new reverse martingale central limit theorem is proved.'] ['A system of multivariate semiparametric nonlinear time series models is studied with possible dependence structures and nonstationarities in the parametric and nonparametric components. The parametric regressors may be endogenous while the nonparametric regressors are assumed to be strictly exogenous. The parametric regressors may be stationary or nonstationary and the nonparametric regressors are nonstationary integrated time series. Semiparametric least squares (SLS) estimation is considered and its asymptotic properties are derived. Due to endogeneity in the parametric regressors, SLS is not consistent for the parametric component and a semiparametric instrumental variable (SIV) method is proposed instead. Under certain regularity conditions, the SIV estimator of the parametric component is shown to have a limiting normal distribution. The rate of convergence in the parametric component depends on the properties of the regressors. The conventional n rate may apply even when nonstationarity is involved in both sets of regressors.'] ['We analyze the applicability of standard normal asymptotic theory for linear process models near the boundary of stationarity. Limit results are given for estimation of the mean, autocovariance and autocorrelation functions within the broad region of stationarity that includes near boundary cases which vary with the sample size. The rate of consistency and the validity of the normal asymptotic approximation for the corresponding estimators is determined both by the sample size n and a parameter measuring the proximity of the model to the unit root boundary.'] ['An asymptotic theory is developed for a weakly identified cointegrating regression model in which the regressor is a nonlinear transformation of an integrated process. Weak identification arises from the presence of a loading coefficient for the nonlinear function that may be close to zero. In that case, standard nonlinear cointegrating limit theory does not provide good approximations to the finite-sample distributions of nonlinear least squares estimators, resulting in potentially misleading inference. A new local limit theory is developed that approximates the finite-sample distributions of the estimators uniformly well irrespective of the strength of the identification. An important technical component of this theory involves new results showing the uniform weak convergence of sample covariances involving nonlinear functions to mixed normal and stochastic integral limits. Based on these asymptotics, we construct confidence intervals for the loading coefficient and the nonlinear transformation parameter and show that these confidence intervals have correct asymptotic size. As in other cases of nonlinear estimation with integrated processes and unlike stationary process asymptotics, the properties of the nonlinear transformations affect the asymptotics and, in particular, give rise to parameter dependent rates of convergence and differences between the limit results for integrable and asymptotically homogeneous functions.'] ['Reduced rank regression (RRR) models with time varying heterogeneity are considered. Standard information criteria for selecting cointegrating rank are shown to be weakly consistent in semiparametric RRR models in which the errors have general nonparametric short memory components and shifting volatility provided the penalty coefficient Cn\xe2\x86\x92\xe2\x88\x9e and Cn/n\xe2\x86\x920 as n\xe2\x86\x92\xe2\x88\x9e. The AIC criterion is inconsistent and its limit distribution is given. The results extend those in Cheng and Phillips (2009a) and are useful in empirical work where structural breaks or time evolution in the error variances is present. An empirical application to exchange rate data is provided.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['We analyze optimality properties of maximum likelihood (ML) and other estimators when the problem does not necessarily fall within the locally asymptotically normal (LAN) class, therefore covering cases that are excluded from conventional LAN theory such as unit root nonstationary time series. The classical H\xc3\xa1jek\xe2\x80\x93Le Cam optimality theory is adapted to cover this situation. We show that the expectation of certain monotone \xe2\x80\x9cbowl-shaped\xe2\x80\x9d functions of the squared estimation error are minimized by the ML estimator in locally asymptotically quadratic situations, which often occur in nonstationary time series analysis when the LAN property fails. Moreover, we demonstrate a direct connection between the (Bayesian property of) asymptotic normality of the posterior and the classical optimality properties of ML estimators.'] ["This paper proposes a nonparametric test for common trends in semiparametric panel data models with fixed effects based on a measure of nonparametric goodness-of-fit (R^2). We first estimate the model under the null hypothesis of common trends by the method of profile least squares, and obtain the augmented residual which consistently estimates the sum of the fixed effect and the disturbance under the null. Then we run a local linear regression of the augmented residuals on a time trend and calculate the nonparametric R^2 for each cross section unit. The proposed test statistic is obtained by averaging all cross sectional nonparametric R^2's, which is close to zero under the null and deviates from zero under the alternative. We show that after appropriate standardization the test statistic is asymptotically normally distributed under both the null hypothesis and a sequence of Pitman local alternatives. We prove test consistency and propose a bootstrap procedure to obtain p-values. Monte Carlo simulations indicate that the test performs well in finite samples. Empirical applications are conducted exploring the commonality of spatial trends in UK climate change data and idiosyncratic trends in OECD real GDP growth data. Both applications reveal the fragility of the widely adopted common trends assumption.<p>(This abstract was borrowed from another version of this item.)"] ['Linear cointegration is known to have the important property of invariance under temporal translation. The same property is shown not to apply for nonlinear cointegration. The limit properties of the Nadaraya\xe2\x80\x93Watson (NW) estimator for cointegrating regression under misspecified lag structure are derived, showing the NW estimator to be inconsistent, in general, with a \xe2\x80\x9cpseudo-true function\xe2\x80\x9d limit that is a local average of the true regression function. In this respect nonlinear cointegrating regression differs importantly from conventional linear cointegration which is invariant to time translation. When centred on the pseudo-true function and appropriately scaled, the NW estimator still has a mixed Gaussian limit distribution. The convergence rates are the same as those obtained under correct specification (hn, h is a bandwidth term) but the variance of the limit distribution is larger. The practical import of the results for index models, functional regression models, temporal aggregation and specification testing are discussed. Two nonparametric linearity tests are considered. The proposed tests are robust to dynamic misspecification. Under the null hypothesis (linearity), the first test has a \xcf\x872 limit distribution while the second test has limit distribution determined by the maximum of independently distributed \xcf\x872 variates. Under the alternative hypothesis, the test statistics attain a hn divergence rate.'] ['While differencing transformations can eliminate nonstationarity, they typically reduce signal strength and correspondingly reduce rates of convergence in unit root autoregressions. The present paper shows that aggregating moment conditions that are formulated in differences provides an orderly mechanism for preserving information and signal strength in autoregressions with some very desirable properties. In first order autoregression, a partially aggregated estimator based on moment conditions in differences is shown to have a limiting normal distribution that holds uniformly in the autoregressive coefficient \xcf\x81 , including stationary and unit root cases. The rate of convergence is null when null and the limit distribution is the same as the Gaussian maximum likelihood estimator (MLE), but when \xcf\x81 = 1 the rate of convergence to the normal distribution is within a slowly varying factor of n . A fully aggregated estimator (FAE) is shown to have the same limit behavior in the stationary case and to have nonstandard limit distributions in unit root and near integrated cases, which reduce both the bias and the variance of the MLE. This result shows that it is possible to improve on the asymptotic behavior of the MLE without using an artificial shrinkage technique or otherwise accelerating convergence at unity at the cost of performance in the neighborhood of unity. Confidence intervals constructed from the FAE using local asymptotic theory around unity also lead to improvements over the MLE.'] ["Multivariate continuous time models are now widely used in economics and finance. Empirical applications typically rely on some process of discretization so that the system may be estimated with discrete data. This paper introduces a framework for discretizing linear multivariate continuous time systems that includes the commonly used Euler and trapezoidal approximations as special cases and leads to a general class of estimators for the mean reversion matrix. Asymptotic distributions and bias formulae are obtained for estimates of the mean reversion parameter. Explicit expressions are given for the discretization bias and its relationship to estimation bias in both multivariate and in univariate settings. In the univariate context, we compare the performance of the two approximation methods relative to exact maximum likelihood (ML) in terms of bias and variance for the Vasicek process. The bias and the variance of the Euler method are found to be smaller than the trapezoidal method, which are in turn smaller than those of exact ML. Simulations suggest that when the mean reversion is slow, the approximation methods work better than ML, the bias formulae are accurate, and for scalar models the estimates obtained from the two approximate methods have smaller bias and variance than exact ML. For the square root process, the Euler method outperforms the Nowman method in terms of both bias and variance. Simulation evidence indicates that the Euler method has smaller bias and variance than exact ML, Nowman's method and the Milstein method."] ['A new recursive regression methodology is introduced to analyze the bubble characteristics of various financial time series during the subprime crisis. The methods modify a technique proposed in Phillips, Wu and Yu (2010) and provide a technology for identifying bubble behavior and consistent dating of their origination and collapse. The tests also serve as an early warning diagnostic of bubble activity. Seven relevant financial series are investigated, including three financial assets (the Nasdaq index, home price index and asset-backed commercial paper), two commodities (the crude oil price and platinum price), one bond rate (Baa), and one exchange rate (Pound/USD). Statistically significant bubble characteristics are found in all of these series. The empirical estimates of the origination and collapse dates suggest an interesting migration mechanism among the financial variables: a bubble first emerged in the equity market during mid-1995 lasting to the end of 2000, followed by a bubble in the real estate market between January 2001 and July 2007 and in the mortgage market between November 2005 and August 2007. After the subprime crisis erupted, the phenomenon migrated selectively into the commodity market and the foreign exchange market, creating bubbles which subsequently burst at the end of 2008, just as the effects on the real economy and economic growth became manifest. Our empirical estimates of the origination and collapse dates match well with the general datetimes of this crisis put forward in a recent study by Caballero, Farhi and Gourinchas (2008).<p>(This abstract was borrowed from another version of this item.)'] ['Using the power kernels of Phillips, Sun, and Jin (2006, 2007), we examine the large sample asymptotic properties of the t -test for different choices of power parameter ( \xcf\x81 ). We show that the nonstandard fixed- \xcf\x81 limit distributions of the t -statistic provide more accurate approximations to the finite sample distributions than the conventional large- \xcf\x81 limit distribution. We prove that the second-order corrected critical value based on an asymptotic expansion of the nonstandard limit distribution is also second-order correct under the large- \xcf\x81 asymptotics. As a further contribution, we propose a new practical procedure for selecting the test-optimal power parameter that addresses the central concern of hypothesis testing: The selected power parameter is test-optimal in the sense that it minimizes the type II error while controlling for the type I error. A plug-in procedure for implementing the test-optimal power parameter is suggested. Simulations indicate that the new test is as accurate in size as the nonstandard test of Kiefer and Vogelsang (2002a, 2002b), and yet it does not incur the power loss that often hurts the performance of the latter test. The results complement recent work by Sun, Phillips, and Jin (2008) on conventional and b T HAC testing.'] ['No abstract is available for this item.'] ['A recursive test procedure is suggested that provides a mechanism for testing explosive behavior, date-stamping the origination and collapse of economic exuberance, and providing valid con?dence intervals for explosive growth rates. The method involves the recursive im- plementation of a right-side unit root test and a sup test, both of which are easy to use in practical applications, and some new limit theory for mildly explosive processes. The test procedure is shown to have discriminatory power in detecting periodically collapsing bubbles, thereby overcoming a weakness in earlier applications of unit root tests for economic bubbles. An empirical application to Nasdaq stock price index in the 1990s provides con?rmation of ex- plosiveness and date-stamps the origination of ?nancial exuberance to mid -1995, prior to the famous remark in December 1996 by Alan Greenspan about irrational exuberance in ?nancial market, thereby giving the remark empirical content.<p>(This abstract was borrowed from another version of this item.)'] ['Statistics are developed to test for the presence of an asymptotic discontinuity (or infinite density or peakedness) in a probability density at the median. The approach makes use of work by Knight (1998) on L1 estimation asymptotics in conjunction with non-parametric kernel density estimation methods. The size and power of the tests are assessed, and conditions under which the tests have good performance are explored in simulations. The new methods are applied to stock returns of leading companies across major U.S. industry groups. The results confirm the presence of infinite density at the median as a new significant empirical evidence for stock return distributions.<p>(This abstract was borrowed from another version of this item.)'] ['A local limit theorem is given for the sample mean of a zero energy function of a nonstationary time series involving twin numerical sequences that pass to infinity. The result is applicable in certain nonparametric kernel density estimation and regression problems where the relevant quantities are functions of both sample size and bandwidth. An interesting outcome of the theory in nonparametric regression is that the linear term is eliminated from the asymptotic bias. In consequence and in contrast to the stationary case, the Nadaraya\xe2\x80\x93Watson estimator has the same limit distribution (to the second order including bias) as the local linear nonparametric estimator.'] ['No abstract is available for this item.'] ['A functional law is given for an I(1) sample data version of the continuous-path block bootstrap of Paparoditis and Politis (2001a). The results provide an alternative demonstration that continuous-path block bootstrap unit root tests are consistent under the null.'] ['Least absolute deviations (LAD) estimation of linear time series models is considered under conditional heteroskedasticity and serial correlation. The limit theory of the LAD estimator is obtained without assuming the finite density condition for the errors that is required in standard LAD asymptotics. The results are particularly useful in application of LAD estimation to financial time series data.'] ['This paper develops a linearity test that can be applied to cointegrating relations. We consider the widely used RESET specification test and show that when this test is applied to nonstationary time series its asymptotic distribution involves a mixture of noncentral chi^2 distributions, which leads to severe size distortions in conventional testing based on the central chi^2. Nonstationarity is shown to introduce two bias terms in the limit distribution, which are the source of the size distortion in testing. Appropriate corrections for this asymptotic bias leads to a modified version of the RESET test which has a central chi^2 limit distribution under linearity. The modified test has power not only against nonlinear cointegration but also against the absence of cointegration. Simulation results reveal that the modified test has good size infinite samples and reasonable power against many nonlinear models as well as models with no cointegration, confirming the analytic results. In an empirical illustration, the linear purchasing power parity (PPP) specification is tested using US, Japan, and Canada monthly data after Bretton Woods. While commonly used ADF and PP cointegration tests give mixed results on the presence of linear cointegration in the series, the modified test rejects the null of linear PPP cointegration.<p>(This abstract was borrowed from another version of this item.)'] [' This paper studies the distribution of the classical\xe2\x80\x82t-ratio with data generated from distributions with no finite moments and shows how classical testing is affected by bimodality. A key condition in generating bimodality is independence of the observations in the underlying data-generating process (DGP). The paper highlights the strikingly different implications of lack of correlation versus statistical independence in DGPs with infinite moments and shows how standard inference can be invalidated in such cases, thereby pointing to the need for adapting estimation and inference procedures to the special problems induced by thick-tailed (TT) distributions. The paper presents theoretical results for the Cauchy case and develops a new distribution termed the "double-Pareto", which allows the thickness of the tails and the existence of moments to be determined parametrically. It also investigates the relative importance of tail thickness in case of finite moments by using TT distributions truncated on a compact support, showing that bimodality can persist even in such cases. Simulation results highlight the dangers of relying on naive testing in the face of TT distributions. Novel density estimation kernel methods are employed, given that our theoretical results yield cases that exhibit density discontinuities. Copyright The Author(s). Journal compilation Royal Economic Society 2010.'] ['This paper develops new estimation and inference procedures for dynamic panel data models with fixed effects and incidental trends. A simple consistent GMM estimation method is proposed that avoids the weak moment condition problem that is known to affect conventional GMM estimation when the autoregressive coefficient ( \xcf\x81 ) is near unity. In both panel and time series cases, the estimator has standard Gaussian asymptotics for all values of \xcf\x81 null (\xe2\x88\x921, 1] irrespective of how the composite cross-section and time series sample sizes pass to infinity. Simulations reveal that the estimator has little bias even in very small samples. The approach is applied to panel unit root testing.'] ['Maximum likelihood (ML) estimation of the autoregressive parameter of a dynamic panel data model with fixed effects is inconsistent under fixed time series sample size and large cross section sample size asymptotics. This paper proposes a general, computationally inexpensive method of bias reduction that is based on indirect inference, shows unbiasedness and analyzes efficiency. Monte Carlo studies show that our procedure achieves substantial bias reductions with only mild increases in variance, thereby substantially reducing root mean square errors. The method is compared with certain consistent estimators and is shown to have superior finite sample properties to the generalized method of moment (GMM) and the bias-corrected ML estimator.'] [' Two distinguished New Zealanders pioneered some of the foundations of modern econometrics. Alec Aitken, one of the most famous and well-documented mental arithmeticians of all time, contributed the matrix formulation and projection geometry of linear regression, generalized least squares (GLS) estimation, algorithms for Hodrick Prescott (HP) style data smoothing (six decades before their use in economics), and statistical estimation theory leading to the Cramer Rao bound. Rex Bergstrom constructed and estimated by limited information maximum likelihood (LIML) the largest empirical structural model in the early 1950s, opened up the field of exact distribution theory, developed cyclical growth models in economic theory, and spent nearly 40 years of his life developing the theory of continuous time econometric modeling and its empirical application. We provide an overview of their lives, discuss some of their accomplishments, and develop some new econometric theory that connects with their foundational work.'] ['A limit theory is established for autoregressive time series that smooths the transition between local and moderate deviations from unity and provides a transitional form that links conventional unit root distributions and the standard normal. Edgeworth expansions of the limit theory are given. These expansions show that the limit theory that holds for values of the autoregressive coefficient that are closer to stationarity than local (i.e. deviations of the form , where n is the sample size and c'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['An asymptotic theory is developed for multivariate regression in cointegrated systems whose variables are moderately integrated or moderately explosive in the sense that they have autoregressive roots of the form \xcf\x81 = 1 + c /n , involving moderate deviations from unity when \xce\xb1 null (0, 1) and c null null are constant parameters. When the data are moderately integrated in the stationary direction (with c '] ['Some exact distribution theory is developed for structural equation models with and without identities. The theory includes LIML, IV, and OLS. We relate the new results to earlier studies in the literature, including the pioneering work of Bergstrom (1962). General IV exact distribution formulas for a structural equation model without an identity are shown to apply also to models with an identity by specializing along a certain asymptotic parameter sequence. Some of the new exact results are obtained by means of a uniform asymptotic expansion. An interesting consequence of the new theory is that the uniform asymptotic approximation provides the exact distribution of the OLS estimator in the model considered by Bergstrom (1962). This example appears to be the first instance in the statistical literature of a uniform approximation delivering an exact expression for a probability density.'] [' Some extensions of neoclassical growth models are discussed that allow for cross-section heterogeneity among economies and evolution in rates of technological progress over time. The models offer a spectrum of transitional behavior among economies that includes convergence to a common steady-state path as well as various forms of transitional divergence and convergence. Mechanisms for modeling such transitions, measuring them econometrically, assessing group behavior and selecting subgroups are developed in the paper. Some econometric issues with the commonly used augmented Solow regressions are pointed out, including problems of endogeneity and omitted variable bias which arise under conditions of transitional heterogeneity. Alternative regression methods for analyzing economic transition are given which lead to a new test of the convergence hypothesis and a new procedure for detecting club convergence clusters. Transition curves for individual economies and subgroups of economies are estimated in a series of empirical applications of the methods to regional US data, OECD data and Penn World Table data. Copyright \xc2\xa9 2009 John Wiley &amp; Sons, Ltd.'] ['Asymptotic theory is developed for local time density estimation for a general class of functionals of integrated and fractionally integrated time series. The main result provides a convenient basis for developing a limit theory for nonparametric cointegrating regression and nonstationary autoregression. The treatment directly involves local time estimation and the density function of the processes under consideration, providing an alternative approach to the Markov chain and Fourier integral methods that have been used in other recent work on these problems.'] ['A local limit theorem is proved for sample covariances of nonstationary time series and integrable functions of such time series that involve a bandwidth sequence. The resulting theory enables an asymptotic development of nonparametric regression with integrated or fractionally integrated processes that includes the important practical case of spurious regressions. Some local regression diagnostics are suggested for forensic analysis of such regresssions, including a local R 2 and a local Durbin\xe2\x80\x93Watson ( DW ) ratio, and their asymptotic behavior is investigated. The most immediate findings extend the earlier work on linear spurious regression (Phillips, 1986, Journal of Econometrics 33, 311\xe2\x80\x93340) showing that the key behavioral characteristics of statistical significance, low DW ratios and moderate to high R 2 continue to apply locally in nonparametric spurious regression. Some further applications of the limit theory to models of nonlinear functional relations and cointegrating regressions are given. The methods are also shown to be applicable in partial linear semiparametric nonstationary regression.'] ['This paper motivates and introduces a two-stage method of estimating diffusion processes based on discretely sampled observations. In the first stage we make use of the feasible central limit theory for realized volatility, as developed in [Jacod, J., 1994. Limit of random measures associated with the increments of a Brownian semiartingal. Working paper, Laboratoire de Probabilities, Universite Pierre et Marie Curie, Paris] and [Barndorff-Nielsen, O., Shephard, N., 2002. Econometric analysis of realized volatility and its use in estimating stochastic volatility models. Journal of the Royal Statistical Society. Series B, 64, 253-280], to provide a regression model for estimating the parameters in the diffusion function. In the second stage, the in-fill likelihood function is derived by means of the Girsanov theorem and then used to estimate the parameters in the drift function. Consistency and asymptotic distribution theory for these estimates are established in various contexts. The finite sample performance of the proposed method is compared with that of the approximate maximum likelihood method of [A\xc3\xaft-Sahalia, Y., 2002. Maximum likelihood estimation of discretely sampled diffusion: A closed-form approximation approach. Econometrica. 70, 223-262].'] ['It is well known that unit root limit distributions are sensitive to initial conditions in the distant past. If the distant past initialization is extended to the infinite past, the initial condition dominates the limit theory, producing a faster rate of convergence, a limiting Cauchy distribution for the least squares coefficient, and a limit normal distribution for the t -ratio. This amounts to the tail of the unit root process wagging the dog of the unit root limit theory. These simple results apply in the case of a univariate autoregression with no intercept. The limit theory for vector unit root regression and cointegrating regression is affected but is no longer dominated by infinite past initializations. The latter contribute to the limiting distribution of the least squares estimator and produce a singularity in the limit theory, but do not change the principal rate of convergence. Usual cointegrating regression theory and inference continue to hold in spite of the degeneracy in the limit theory and are therefore robust to initial conditions that extend to the infinite past.'] [' A new methodology is proposed to estimate theoretical prices of financial contingent claims whose values are dependent on some other underlying financial assets. In the literature, the preferred choice of estimator is usually maximum likelihood (ML). ML has strong asymptotic justification but is not necessarily the best method in finite samples. This paper proposes a simulation-based method. When it is used in connection with ML, it can improve the finite-sample performance of the ML estimator while maintaining its good asymptotic properties. The method is implemented and evaluated here in the Black-Scholes option pricing model and in the Vasicek bond and bond option pricing model. It is especially favored when the bias in ML is large due to strong persistence in the data or strong nonlinearity in pricing functions. Monte Carlo studies show that the proposed procedures achieve bias reductions over ML estimation in pricing contingent claims when ML is biased. The bias reductions are sometimes accompanied by reductions in variance. Empirical applications to U.S. Treasury bills highlight the differences between the bond prices implied by the simulation-based approach and those delivered by ML. Some consequences for the statistical testing of contingent-claim pricing models are discussed. The Author 2009. Published by Oxford University Press on behalf of The Society for Financial Studies. All rights reserved. For Permissions, please e-mail: journals.permissions@oxfordjournals.org., Oxford University Press.'] [' . The limit distribution of the AIC criterion, which is inconsistent, is also obtained. The analysis provides a general limit theory for semiparametric reduced rank regression under weakly dependent errors. The method does not require the specification of a full model, is convenient for practical implementation in empirical work, and is sympathetic with semiparametric estimation approaches to co-integration analysis. Some simulation results on the finite sample performance of the criteria are reported. Copyright (C) The Author(s). Journal compilation (C) Royal Economic Society 2009'] [' Nonparametric estimation of a structural cointegrating regression model is studied. As in the standard linear cointegrating regression model, the regressor and the dependent variable are jointly dependent and contemporaneously correlated. In nonparametric estimation problems, joint dependence is known to be a major complication that affects identification, induces bias in conventional kernel estimates, and frequently leads to ill-posed inverse problems. In functional cointegrating regressions where the regressor is an integrated or near-integrated time series, it is shown here that inverse and ill-posed inverse problems do not arise. Instead, simple nonparametric kernel estimation of a structural nonparametric cointegrating regression is consistent and the limit distribution theory is mixed normal, giving straightforward asymptotics that are useable in practical work. It is further shown that use of augmented regression, as is common in linear cointegration modeling to address endogeneity, does not lead to bias reduction in nonparametric regression, but there is an asymptotic gain in variance reduction. The results provide a convenient basis for inference in structural nonparametric regression with nonstationary time series when there is a single integrated or near-integrated regressor. The methods may be applied to a range of empirical models where functional estimation of cointegrating relations is required. Copyright 2009 The Econometric Society.'] ['A commonly used defining property of long memory time series is the power law decay of the autocovariance function. Some alternative methods of deriving this property are considered, working from the alternate definition in terms of a fractional pole in the spectrum at the origin. The methods considered involve the use of (i) Fourier transforms of generalized functions, (ii) asymptotic expansions of Fourier integrals with singularities, (iii) direct evaluation using hypergeometric function algebra, and (iv) conversion to a simple gamma integral. The paper is largely pedagogical but some novel methods and results involving complete asymptotic series representations are presented. The formulae are useful in many ways, including the calculation of long run variation matrices for multivariate time series with long memory and the econometric estimation of such models.'] ['This paper introduces a simple first-difference-based approach to estimation and inference for the AR(1) model. The estimates have virtually no finite-sample bias and are not sensitive to initial conditions, and the approach has the unusual advantage that a Gaussian central limit theory applies and is continuous as the autoregressive coefficient passes through unity with a uniform null rate of convergence. En route, a useful central limit theorem (CLT) for sample covariances of linear processes is given, following Phillips and Solo (1992, Annals of Statistics , 20, 971\xe2\x80\x931001). The approach also has useful extensions to dynamic panels.'] ["An infinite-order asymptotic expansion is given for the autocovariance function of a general stationary long-memory process with memory parameter d[set membership, variant](-1/2,1/2). The class of spectral densities considered includes as a special case the stationary and invertible ARFIMA(p,d,q) model. The leading term of the expansion is of the order O(1/k1-2d), where k is the autocovariance order, consistent with the well known power law decay for such processes, and is shown to be accurate to an error of O(1/k3-2d). The derivation uses Erd\xc3\xa9lyi's [Erd\xc3\xa9lyi, A., 1956. Asymptotic Expansions. Dover Publications, Inc, New York] expansion for Fourier-type integrals when there are critical points at the boundaries of the range of integration - here the frequencies {0,2[pi]}. Numerical evaluations show that the expansion is accurate even for small k in cases where the autocovariance sequence decays monotonically, and in other cases for moderate to large k. The approximations are easy to compute across a variety of parameter values and models."] ['A limit theory is developed for multivariate regression in an explosive cointegrated system. The asymptotic behavior of the least squares estimator of the cointegrating coefficients is found to depend upon the precise relationship between the explosive regressors. When the eigenvalues of the autoregressive matrix \xce\x98 are distinct, the centered least squares estimator has an exponential \xce\x98 null rate of convergence and a mixed normal limit distribution. No central limit theory is applicable here, and Gaussian innovations are assumed. On the other hand, when some regressors exhibit common explosive behavior, a different mixed normal limiting distribution is derived with rate of convergence reduced to null . In the latter case, mixed normality applies without any distributional assumptions on the innovation errors by virtue of a Lindeberg type central limit theorem. Conventional statistical inference procedures are valid in this case, the stationary convergence rate dominating the behavior of the least squares estimator.'] ['Weak convergence of partial sums and multilinear forms in independent random variables and linear processes and their nonlinear analogues to stochastic integrals now plays a major role in nonstationary time series and has been central to the development of unit root econometrics. The present paper develops a new and conceptually simple method for obtaining such forms of convergence. The method relies on the fact that the econometric quantities of interest involve discrete time martingales or semimartingales and shows how in the limit these quantities become continuous martingales and semimartingales. The limit theory itself uses very general convergence results for semimartingales that were obtained in the work of Jacod and Shiryaev (2003, Limit Theorems for Stochastic Processes ). The theory that is developed here is applicable in a wide range of econometric models, and many examples are given. %One notable outcome of the new approach is that it provides a unified treatment of the asymptotics for stationary, explosive, unit root, and local to unity autoregression, and also some general nonlinear time series regressions. All of these cases are subsumed within the martingale convergence approach, and different rates of convergence are accommodated in a natural way. Moreover, the results on multivariate extensions developed in the paper deliver a unification of the asymptotics for, among many others, models with cointegration and also for regressions with regressors that are nonlinear transforms of integrated time series driven by shocks correlated with the equation errors. Because this is the first time the methods have been used in econometrics, the exposition is presented in some detail with illustrations of new derivations of some well-known existing results, in addition to the provision of new results and the unification of the limit theory for autoregression.'] [' There is an emerging consensus in empirical finance that realized volatility series typically display long range dependence with a memory parameter (d) around 0.4 (Andersen et al., 2001; Martens et al., 2004). The present article provides some illustrative analysis of how long memory may arise from the accumulative process underlying realized volatility. The article also uses results in Lieberman and Phillips (2004, 2005) to refine statistical inference about d by higher order theory. Standard asymptotic theory has an O(n-1/2) error rate for error rejection probabilities, and the theory used here refines the approximation to an error rate of o(n-1/2). The new formula is independent of unknown parameters, is simple to calculate and user-friendly. The method is applied to test whether the reported long memory parameter estimates of Andersen et al. (2001) and Martens et al. (2004) differ significantly from the lower boundary (d\xef\xbf\xbd=\xef\xbf\xbd0.5) of nonstationary long memory, and generally confirms earlier findings.'] [' This paper considers studentized tests in time series regressions with nonparametrically autocorrelated errors. The studentization is based on robust standard errors with truncation lag M=bT for some constant b is an element of (0, 1] and sample size T. It is shown that the nonstandard fixed-b limit distributions of such nonparametrically studentized tests provide more accurate approximations to the finite sample distributions than the standard small-b limit distribution. We further show that, for typical economic time series, the optimal bandwidth that minimizes a weighted average of type I and type II errors is larger by an order of magnitude than the bandwidth that minimizes the asymptotic mean squared error of the corresponding long-run variance estimator. A plug-in procedure for implementing this optimal bandwidth is suggested and simulations (not reported here) confirm that the new plug-in procedure works well in finite samples. Copyright The Econometric Society 2008.'] ['Stable autoregressive models of known finite order are considered with martingale differences errors scaled by an unknown nonparametric time-varying function generating heterogeneity. An important special case involves structural change in the error variance, but in most practical cases the pattern of variance change over time is unknown and may involve shifts at unknown discrete points in time, continuous evolution or combinations of the two. This paper develops kernel-based estimators of the residual variances and associated adaptive least squares (ALS) estimators of the autoregressive coefficients. These are shown to be asymptotically efficient, having the same limit distribution as the infeasible generalized least squares (GLS). Comparisons of the efficient procedure and ordinary least squares (OLS) reveal that least squares can be extremely inefficient in some cases while nearly optimal in others. Simulations show that, when least squares work well, the adaptive estimators perform comparably well, whereas when least squares work poorly, major efficiency gains are achieved by the new estimators.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['An asymptotic expansion is given for the autocovariance matrix of a vector of stationary long-memory processes with memory parameters d satisfying 0 <p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['Log periodogram (LP) regression is shown to be consistent and to have a mixed normal limit distribution when the memory parameter d = 1. Gaussian errors are not required. Tests of d = 1 based on LP regression are consistent against d <p>(This abstract was borrowed from another version of this item.)'] ['The asymptotic local powers of various panel unit root tests are investigated. The power envelope is obtained under homogeneous and heterogeneous alternatives. It is compared with asymptotic power functions of the pooled t-test, the Ploberger-Phillips (2002) test, and a point optimal test in neighborhoods of unity that are of order n^{-1/4}T^{-1} and n^{-1/2}T^{-1}, depending on whether or not incidental trends are extracted from the panel data. In the latter case, when the alternative hypothesis is homogeneous across individuals, it is shown that the point optimal test and Ploberger-Phillips test both achieve the power envelope and are uniformly most powerful, in contrast to point optimal unit root tests for time series. Some simulations examining the finite sample performance of the tests are reported.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['Explicit asymptotic bias formulae are given for dynamic panel regression estimators as the cross section sample size N\\rightarrow\\infty. The results extend earlier work by Nickell (1981) in several directions that are relevant for practical work, including models with unit roots, deterministic trends, predetermined and exogenous regressors, and errors that may be cross sectionally dependent. The asymptotic bias is found to be so large when incidental linear trends are fitted and the time series sample size is small that it changes the sign of the autoregressive coefficient. Another finding of interest is that, when there is cross section error dependence, the probability limit of the dynamic panel regression estimator is a random variable rather than a constant, which helps to explain the substantial variability observed in dynamic panel estimates when there is cross section dependence even in situations where N is very large.<p>(This abstract was borrowed from another version of this item.)'] ['A simple and robust approach is proposed for the parametric estimation of scalar homogeneous stochastic differential equations. We specify a parametric class of diffusions and estimate the parameters of interest by minimizing criteria based on the integrated squared difference between kernel estimates of the drift and diffusion functions and their parametric counterparts. The procedure does not require simulations or approximations to the true transition density and has the simplicity of standard nonlinear least-squares methods in discrete-time. A complete asymptotic theory for the parametric estimates is developed. The limit theory relies on infill and long span asymptotics and is robust to deviations from stationarity, requiring only recurrence.<p>(This abstract was borrowed from another version of this item.)'] ['An asymptotic theory is given for autoregressive time series with a root of the form rho_{n} = 1+c/n^{alpha}, which represents moderate deviations from unity when alpha in (0,1). The limit theory is obtained using a combination of a functional law to a diffusion on D[0,infinity) and a central limit law to a scalar normal variate. For c <p>(This abstract was borrowed from another version of this item.)'] ['We correct the limit theory presented in an earlier paper by Hu and Phillips (Journal of Econometrics, 2004) for nonstationary time series discrete choice models with multiple choices and thresholds. The new limit theory shows that, in contrast to the binary choice model with nonstationary regressors and a zero threshold where there are dual rates of convergence (n^{1/4} and n^{3/4}), all parameters including the thresholds converge at the rate n^{3/4}. The presence of non-zero thresholds therefore materially affects rates of convergence. Dual rates of convergence reappear when stationary variables are present in the system. Some simulation evidence is provided, showing how the magnitude of the thresholds affects finite sample performance. A new finding is that predicted probabilities and marginal effect estimates have finite sample distributions that manifest a pile-up, or increasing density, towards the limits of the domain of definition.<p>(This abstract was borrowed from another version of this item.)'] [' A new panel data model is proposed to represent the behavior of economies in transition, allowing for a wide range of possible time paths and individual heterogeneity. The model has both common and individual specific components, and is formulated as a nonlinear time varying factor model. When applied to a micro panel, the decomposition provides flexibility in idiosyncratic behavior over time and across section, while retaining some commonality across the panel by means of an unknown common growth component. This commonality means that when the heterogeneous time varying idiosyncratic components converge over time to a constant, a form of panel convergence holds, analogous to the concept of conditional sigma convergence. The paper provides a framework of asymptotic representations for the factor components that enables the development of econometric procedures of estimation and testing. In particular, a simple regression based convergence test is developed, whose asymptotic properties are analyzed under both null and local alternatives, and a new method of clustering panels into club convergence groups is constructed. These econometric methods are applied to analyze convergence in cost of living indices among 19 U.S. metropolitan cities. Copyright The Econometric Society 2007.'] ['No abstract is available for this item.'] [' First order autoregression is shown to satisfy a limit theory which is uniform over stationary values of the autoregressive coefficient rho = rho_n is an element of [0, 1) provided (1 - rho_n)n goes to infinity. This extends existing Gaussian limit theory by allowing for values of stationary rho that include neighbourhoods of unity provided they are wider than O(n-super- - 1), even by a slowly varying factor. Rates of convergence depend on rho and are at least but less than n. Only second moments are assumed, as in the case of stationary autoregression with fixed rho. Copyright 2006 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['In a simple model composed of a structural equation and identity, the finite sample distribution of the IV/LIML estimator is always bimodal and this is most apparent when the concentration parameter is small. Weak instrumentation is the energy that feeds the secondary mode and the coefficient in the structural identity provides a point of compression in the density that gives rise to it. The IV limit distribution can be normal, bimodal, or inverse normal depending on the behavior of the concentration parameter and the weakness of the instruments. The limit distribution of the OLS estimator is normal in all cases and has a much faster rate of convergence under very weak instrumentation. The IV estimator is therefore more resistant to the attractive effect of the identity than OLS. Some of these limit results differ from conventional weak instrument asymptotics, including convergence to a constant in very weak instrument cases and limit distributions that are inverse normal.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['A new approach to robust testing in cointegrated systems is proposed using nonparametric HAC estimators without truncation. While such HAC estimates are inconsistent, they still produce asymptotically pivotal tests and, as in conventional regression settings, can improve testing and inference. The present contribution makes use of steep origin kernels which are obtained by exponentiating traditional quadratic kernels. Simulations indicate that tests based on these methods have improved size properties relative to conventional tests and better power properties than other tests that use Bartlett or other traditional kernels with no truncation.<p>(This abstract was borrowed from another version of this item.)'] [' This paper provides a first order asymptotic theory for generalized method of moments (GMM) estimators when the number of moment conditions is allowed to increase with the sample size and the moment conditions may be weak. Examples in which these asymptotics are relevant include instrumental variable (IV) estimation with many (possibly weak or uninformed) instruments and some panel data models that cover moderate time spans and have correspondingly large numbers of instruments. Under certain regularity conditions, the GMM estimators are shown to converge in probability but not necessarily to the true parameter, and conditions for consistent GMM estimation are given. A general framework for the GMM limit distribution theory is developed based on epiconvergence methods. Some illustrations are provided, including consistent GMM estimation of a panel model with time varying individual effects, consistent limited information maximum likelihood estimation as a continuously updated GMM estimator, and consistent IV structural estimation using large numbers of weak or irrelevant instruments. Some simulations are reported. Copyright The Econometric Society 2006.'] ['No abstract is available for this item.'] [' A scalar pth-order autoregression (AR(p)) is considered with heteroskedasticity of the unknown form delivered by a transition function of time. A limit theory is developed and three heteroskedasticity-robust test statistics are proposed for inference, one of which is based on the nonparametric estimation of the variance function. The performance of the resulting testing procedures in finite samples is compared in simulations and some suggestions for practical application are given. Copyright 2005 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] [' A new class of kernels for long-run variance and spectral density estimation is developed by exponentiating traditional quadratic kernels. Depending on whether the exponent parameter is allowed to grow with the sample size, we establish different asymptotic approximations to the sampling distribution of the proposed estimators. When the exponent is passed to infinity with the sample size, the new estimator is consistent and shown to be asymptotically normal. When the exponent is fixed, the new estimator is inconsistent and has a nonstandard limiting distribution. It is shown via Monte Carlo experiments that, when the chosen exponent is small in practical applications, the nonstandard limit theory provides better approximations to the finite sample distributions of the spectral density estimator and the associated test statistic in regression settings. Copyright 2006 by the Economics Department Of The University Of Pennsylvania And Osaka University Institute Of Social And Economic Research Association.'] ['Our subject is the notion of automated discovery in econometrics. Advances in computer power, electronic communication, and data collection processes have all changed the way econometrics is conducted. These advances have helped to elevate the status of empirical research within the economics profession in recent years and they now open up new possibilities for empirical econometric practice. Of particular significance is the ability to build econometric models in an automated way according to an algorithm of decision rules that allow for (what we call here) heteroskedastic and autocorrelation robust (HAR) inference. Computerized search algorithms may be implemented to seek out suitable models, thousands of regressions and model evaluations may be performed in seconds, statistical inference may be automated according to the properties of the data, and policy decisions can be made and adjusted in real time with the arrival of new data. We discuss some aspects and implications of these exciting, emergent trends in econometrics.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [" Fisher's equation for the determination of the real rate of interest is studied from a fresh econometric perspective. Some new methods of data description for nonstationary time series are introduced. The methods provide a nonparametric mechanism for modelling the spatial densities of a time series that displays random wandering characteristics, like interest rates and inflation. Hazard rate functionals are also constructed, an asymptotic theory is given, and the techniques are illustrated in some empirical applications to real interest rates for the United States. The paper ends by calculating semiparametric estimates of long-range dependence in U.S. real interest rates, using a new estimation procedure called modified log periodogram regression and new asymptotics that covers the nonstationary case. The empirical results indicate that the real rate of interest in the United States is (fractionally) nonstationary over 1934-1997 and over the more recent subperiods 1961-1985 and 1961-1997. Unit root nonstationarity and short memory stationarity are both strongly rejected for all these periods. Copyright 2005 American Journal of Economics and Sociology, Inc.."] [' . Copyright 2005 Royal Economic Society'] ['We discuss some challenges presented by trending data in time series econometrics. To the empirical economist there is little guidance from theory about the source of trend behavior and even less guidance about practical formulations. Moreover, recent proximity theorems [W. Ploberger, P.C.B. Phillips, Empirical limits for time series econometric models, Econometrica 71 (2003) 627\xe2\x80\x93673] reveal that trends are more elusive to model empirically than stationary processes, with the upshot that optimal forecasts are also harder to estimate when the data involve trends. These limitations are implicitly acknowledged in much practical modeling and forecasting work, where adaptive methods are often used to help keep models on track as trends evolve. The paper discusses these broader issues and limitations of econometrics and offers some thoughts on new practical possibilities for data analysis in the absence of good theory models for trends. In particular, a new concept of coordinate cointegration is introduced and some new econometric methodology is suggested for analyzing trends and co-movement and for producing forecasts in a general way that is agnostic about the specific nature of the trend process. Some simulation exercises are conducted and some long historical series on prices and yields on long securities are used to illustrate the methods.'] ['A simple regression approach to HAC and LRV estimation is suggested. The method exploits the fact that the quantities of interest relate to only one point of the spectrum (the origin). The new estimator is simply the explained sum of squares in a linear regression whose regressors are a set of trend basis functions. Positive definiteness in the estimate is therefore automatically enforced and the technique can be implemented with standard regression packages. No kernel choice is needed in practical implementation but basis functions need to be chosen and a smoothing parameter corresponding to the number of basis functions needs to be selected. An automated approach to making this selection based on optimizing the asymptotic mean squared error is derived. The limit theory of the new estimator shows that its properties, including the convergence rate, are comparable to those of conventional HAC estimates constructed from quadratic kernels.<p>(This abstract was borrowed from another version of this item.)'] [" Prices of interest rate derivative securities depend crucially on the mean reversion parameters of the underlying diffusions. These parameters are subject to estimation bias when standard methods are used. The estimation bias can be substantial even in very large samples and much more serious than the discretization bias, and it translates into a bias in pricing bond options and other derivative securities that is important in practical work. This article proposes a very general and computationally inexpensive method of bias reduction that is based on Quenouille's (1956; Biometrika, 43, 353--360) jackknife. We show how the method can be applied directly to the options price itself as well as the coefficients in the models. We investigate its performance in a Monte Carlo study. Empirical applications to U.S. dollar swap rates highlight the differences between bond and option prices implied by the jackknife procedure and those implied by the standard approach. These differences are large and suggest that bias reduction in pricing options is important in practical applications. Copyright 2005, Oxford University Press."] [' Heteroskedasticity and autocorrelation consistent (HAC) estimation commonly involves the use of prewhitening filters based on simple autoregressive models. In such applications, small sample bias in the estimation of autoregressive coefficients is transmitted to the recolouring filter, leading to HAC variance estimates that can be badly biased. The present paper provides an analysis of these issues using asymptotic expansions and simulations. The approach we recommend involves the use of recursive demeaning procedures that mitigate the effects of small-sample autoregressive bias. Moreover, a commonly used restriction rule on the prewhitening estimates (that first-order autoregressive coefficient estimates, or largest eigenvalues, &gt;0.97 be replaced by 0.97) adversely interferes with the power of unit-root and [Kwiatkowski, Phillips, Schmidt and Shin (1992) "Journal of Econometrics", Vol. 54, pp. 159-178] (KPSS) tests. We provide a new boundary condition rule that improves the size and power properties of these tests. Some illustrations of the effects of these adjustments on the size and power of KPSS testing are given. Using prewhitened HAC estimates and the new boundary condition rule, the KPSS test is consistent, in contrast to KPSS testing that uses conventional prewhitened HAC estimates [Lee, J. S. (1996) "Economics Letters", Vol. 51, pp. 131-137]. Copyright 2005 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] ['This paper develops an asymptotic theory for time series discrete choice models with explanatory variables generated as integrated processes and with multiple choices and threshold parameters determining the choices. The theory extends recent work by Park and Phillips (2000) on binary choice models. As in this earlier work, the maximum likelihood (ML) estimator is consistent and has a limit theory with multiple rates of convergence (n^{3/4} and n^{1/4}) and mixture normal distributions where the mixing variates depend on Brownian local time as well as Brownian motion. An extended arc sine limit law is given for the sample proportions of the various choices. The new limit law exhibits a wider range of potential behavior that depends on the values taken by the threshold parameters.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' This paper investigates a generalized method of moments (GMM) approach to the estimation of autoregressive roots near unity with panel data and incidental deterministic trends. Such models arise in empirical econometric studies of firm size and in dynamic panel data modeling with weak instruments. The two moment conditions in the GMM approach are obtained by constructing bias corrections to the score functions under OLS and GLS detrending, respectively. It is shown that the moment condition under GLS detrending corresponds to taking the projected score on the Bhattacharya basis, linking the approach to recent work on projected score methods for models with infinite numbers of nuisance parameters (Waterman and Lindsay (1998)). Assuming that the localizing parameter takes a nonpositive value, we establish consistency of the GMM estimator and find its limiting distribution. A notable new finding is that the GMM estimator has convergence rate    $n^{1/6}$     n  1 / 6     , slower than    $\\sqrt{n}$     n    , when the true localizing parameter is zero (i.e., when there is a panel unit root) and the deterministic trends in the panel are linear. These results, which rely on boundary point asymptotics, point to the continued difficulty of distinguishing unit roots from local alternatives, even when there is an infinity of additional data. Copyright The Econometric Society 2004.'] [' This paper establishes error orders for integral limit approximations to traces of powers (to the pth order) of products of Toeplitz matrices. Such products arise frequently in the analysis of stationary time series and in the development of asymptotic expansions. The elements of the matrices are Fourier transforms of functions which we allow to be bounded, unbounded, or even to vanish on [ - \xcf\x80, \xcf\x80], thereby including important cases such as the spectral functions of fractional processes. Error rates are also given in the case in which the matrix product involves inverse matrices. The rates are sharp up to an arbitrarily small &amp;epsiv; &gt; 0. The results improve on the o(1) rates obtained in earlier work for analogous products. For the p = 1 case, an explicit second-order asymptotic expansion is found for a quadratic functional of the autocovariance sequences of stationary long-memory time series. The order of magnitude of the second term in this expansion is shown to depend on the long-memory parameters. It is demonstrated that the pole in the first-order approximation is removed by the second-order term, which provides a substantially improved approximation to the original functional. Copyright 2004 Blackwell Publishing Ltd.'] ['Instrumental variable (IV) estimation methods that allow for certain nonlinear functions of the data as instruments are studied. The context of the discussion is the simple unit root model where certain advantages to the use of nonlinear instruments are revealed. In particular, certain classes of IV estimators and associated t-tests are shown to have simpler (standard) limit theory in contrast to the least squares estimator, providing an opportunity for the study of optimal estimation in certain IV classes and furnishing tests and confidence intervals that allow for unit root and stationary alternatives. The Cauchy estimator studied in recent work by So and Shin (1999) is shown to have such an optimality property in the class of certain IV procedures with bounded instruments.<p>(This abstract was borrowed from another version of this item.)'] [' We discuss general weaknesses and limitations of the econometric approach. A template from sociology is used to formulate six laws that characterise mainstream activities of econometrics and their scientific limits. We discuss proximity theorems that quantify by explicit bounds how close we can get to the generating mechanism of the data and the optimal forecasts of next period observations using a finite number of observations. The magnitude of the bound depends on the characteristics of the model and trajectory of the data. We look at one possible future of econometrics using advanced econometric methods interactively with a web browser. Copyright Royal Economic Society 2003'] [' This paper deals with cross section dependence, homogeneity restrictions and small sample bias issues in dynamic panel regressions. To address the bias problem we develop a panel approach to median unbiased estimation that takes account of cross section dependence. The estimators given here considerably reduce the effects of bias and gain precision from estimating cross section error correlation. This paper also develops an asymptotic theory for tests of coefficient homogeneity under cross section dependence, and proposes a modified Hausman test to test for the presence of homogeneous unit roots. An orthogonalization procedure, based on iterated method of moments estimation, is developed to remove cross section dependence and permit the use of conventional and meta unit root tests with panel data. Some simulations investigating the finite sample performance of the estimation and test procedures are reported. Copyright Royal Economic Society, 2003'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' Ploberger and Phillips ("Econometrica", Vol. 71, pp. 627-673, 2003) proved a result that provides a bound on how close a fitted empirical model can get to the true model when the model is represented by a parameterized probability measure on a finite dimensional parameter space. The present note extends that result to cases where the parameter space is infinite dimensional. The results have implications for model choice in infinite dimensional problems and highlight some of the difficulties, including technical difficulties, presented by models of infinite dimension. Some implications for forecasting are considered and some applications are given, including the empirically relevant case of vector autoregression (VAR) models of infinite order. Copyright 2003 Blackwell Publishing Ltd.'] ['This paper studies fractional processes that may be perturbed by weakly dependent time series. The model for a perturbed fractional process has a components framework in which there may be components of both long and short memory. All commonly used estimates of the long memory parameter (such as log periodogram (LP) regression) may be used in a components model where the data are affected by weakly dependent perturbations, but these estimates can suffer from serious downward bias. To circumvent this problem, the present paper proposes a new procedure that allows for the possible presence of additive perturbations in the data. The new estimator resembles the LP regression estimator but involves an additional (nonlinear) term in the regression that takes account of possible perturbation effects in the data. Under some smoothness assumptions at the origin, the bias of the new estimator is shown to disappear at a faster rate than that of the LP estimator, while its asymptotic variance is inflated only by a multiplicative constant. In consequence, the optimal rate of convergence to zero of the asymptotic MSE of the new estimator is faster than that of the LP estimator. Some simulation results demonstrate the viability and the bias-reducing feature of the new estimator relative to the LP estimator in finite samples. A test for the presence of perturbations in the data is given.<p>(This abstract was borrowed from another version of this item.)'] [' This paper characterizes empirically achievable limits for time series econometric modeling and forecasting. The approach involves the concept of minimal information loss in time series regression and the paper shows how to derive bounds that delimit the proximity of empirical measures to the true probability measure (the DGP) in models that are of econometric interest. The approach utilizes joint probability measures over the combined space of parameters and observables and the results apply for models with stationary, integrated, and cointegrated data. A theorem due to Rissanen is extended so that it applies directly to probabilities about the relative likelihood (rather than averages), a new way of proving results of the Rissanen type is demonstrated, and the Rissanen theory is extended to nonstationary time series with unit roots, near unit roots, and cointegration of unknown order. The corresponding bound for the minimal information loss in empirical work is shown not to be a constant, in general, but to be proportional to the logarithm of the determinant of the (possibility stochastic) Fisher--information matrix. In fact, the bound that determines proximity to the DGP is generally path dependent, and it depends specifically on the type as well as the number of regressors. For practical purposes, the proximity bound has the asymptotic form ("K"&amp;sol;2)log "n", where "K" is a new dimensionality factor that depends on the nature of the data as well as the number of parameters in the model. When \'good\' model selection principles are employed in modeling time series data, we are able to show that our proximity bound quantifies empirical limits even in situations where the models may be incorrectly specified.One of the main implications of the new result is that time trends are more costly than stochastic trends, which are more costly in turn than stationary regressors in achieving proximity to the true density. Thus, in a very real sense and quantifiable manner, the DGP is more elusive when there is nonstationarity in the data. The implications for prediction are explored and a second proximity theorem is given, which provides a bound that measures how close feasible predictors can come to the optimal predictor. Again, the bound has the asymptotic form ("K"&amp;sol;2)log "n", showing that forecasting trends is fundamentally more difficult than forecasting stationary time series, even when the correct form of the model for the trends is known. Copyright The Econometric Society 2003.'] ["Denis Sargan's intellectual influence in econometrics is discussed and some of his visions for the future of econometrics are considered in this memorial article. One of Sargan's favorite topics in econometric theory was finite sample theory, including both exact theory and various types of asymptotic expansions. We provide some summary discussion of asymptotic expansions of the type that Sargan developed in this field and give explicit representations of Sargan's formula for the Edgeworth expansion in the case of an econometric estimator that can be written as a smooth function of sample moments whose distributions themselves have Edgeworth expansions.<p>(This abstract was borrowed from another version of this item.)"] [' ARCH and GARCH models directly address the dependency of conditional second moments, and have proved particularly valuable in modelling processes where a relatively large degree of fluctuation is present. These include financial time series, which can be particularly heavy tailed. However, little is known about properties of ARCH or GARCH models in the heavy--tailed setting, and no methods are available for approximating the distributions of parameter estimators there. In this paper we show that, for heavy--tailed errors, the asymptotic distributions of quasi--maximum likelihood parameter estimators in ARCH and GARCH models are nonnormal, and are particularly difficult to estimate directly using standard parametric methods. Standard bootstrap methods also fail to produce consistent estimators. To overcome these problems we develop percentile--"t", subsample bootstrap approximations to estimator distributions. Studentizing is employed to approximate scale, and the subsample bootstrap is used to estimate shape. The good performance of this approach is demonstrated both theoretically and numerically. Copyright The Econometric Society 2003.'] ['No abstract is available for this item.'] [' We propose a functional estimation procedure for homogeneous stochastic differential equations based on a discrete sample of observations and with minimal requirements on the data generating process. We show how to identify the drift and diffusion function in situations where one or the other function is considered a nuisance parameter. The asymptotic behavior of the estimators is examined as the observation frequency increases and as the time span lengthens. We prove almost sure consistency and weak convergence to mixtures of normal laws, where the mixing variates depend on the chronological local time of the underlying diffusion process, that is the random time spent by the process in the vicinity of a generic spatial point. The estimation method and asymptotic results apply to both stationary and nonstationary recurrent processes. Copyright The Econometric Society 2003.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['We show that the conventional CUSUM test for structural change can be applied to cointegrating regression residuals leading to a consistent residual based test for the null hypothesis of cointegration. The proposed tests are semiparametric and utilize fully modified residuals to correct for endogeneity and serial correlation and to scale out nuisance parameters. The limit distribution of the test is derived under both the null and the alternative hypothesis. The tests are easy to use and are found to perform quite well in a Monte Carlo experiment.<p>(This abstract was borrowed from another version of this item.)'] [' Band spectral regression with both deterministic and stochastic trends is considered. It is shown that trend removal by regression in the time domain prior to band spectral regression can lead to biased and inconsistent estimates in models with frequency dependent coefficients. Both semiparametric and nonparametric regression formulations are considered, the latter including general systems of two-sided distributed lags such as those arising in lead and lag regressions. The bias problem arises through omitted variables and is avoided by careful specification of the regression equation. Trend removal in the frequency domain is shown to be a convenient option in practice. An asymptotic theory is developed and the two cases of stationary data and cointegrated nonstationary data are compared. In the latter case, a levels and differences regression formulation is shown to be useful in estimating the frequency response function at nonzero as well as zero frequencies. Copyright The Econometric Society 2002.'] ['This paper analyzes the behavior of posterior distributions under the Jeffreys prior in a simultaneous equations model. The case under study is that of a general limited information setup with n + 1 endogenous variables. The Jeffreys prior is shown to give rise to a marginal posterior density which has Cauchy-like tails similar to that exhibited by the exact finite sample distribution of the corresponding LIML estimator. A stronger correspondence is established in the special case of a just-identified orthonormal canonical model, where the posterior density under the Jeffreys prior is shown to have the same functional form as the density of the finite sample distribution of the LIML estimator. The work here generalizes that of Chao and Phillips (1997), which gives analogous results for the special case of two endogenous variables.<p>(This abstract was borrowed from another version of this item.)'] ['It is shown that the KPSS test for stationarity may be applied without change to regressions with seasonal dummies. In particular, the limit distribution of the KPSS statistic is the same under both the null and alternative hypotheses whether or not seasonal dummies are used.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['Recent work by the author (1998) has shown that stochastic trends can be validly represented in empirical regressions in terms of deterministic functions of time. These representations offer an alternative mechanism for modelling stochastic trends. It is shown here that the alternate representations affect the asymptotics of all commonly used unit root tests in the presence of trends. In particular, the critical values of unit root tests diverge when the number of deterministic regressors K approaches infinity as the sample size n approaches infinity. In such circumstances, use of conventional critical values based on fixed K will lead to rejection of the null of a unit root in favour of trend stationarity with probability one when the null is true. The results can be interpreted as saying that serious attempts to model trends by deterministic functions will always be successful and that these functions can validly represent stochastically trending data even when lagged variables are present in the regressor set, thereby undermining conventional unit root tests.<p>(This abstract was borrowed from another version of this item.)'] ['A new model of near integration is formulated in which the local to unity parameter is identifiable and consistently estimable with time series data. The properties of the model are investigated, new functional laws for near integrated time series are obtained, and consistent estimators of the localizing parameter are constructed. The model provides a more complete interface between I(0) and I(1) models than the traditional local to unity model and leads to autoregressive coefficient estimates with rates of convergence that vary continuously between the O(/n) rate of stationary autoregression, the O(n) rate of unit root regression and the power rate of explosive autoregression. Models with deterministic trends are also considered, least squares trend regression is shown to be efficient, and consistent estimates of the localising parameter are obtained for this case as well. Conventional unit root tests are shown to be consistent against local alternatives in the new class.<p>(This abstract was borrowed from another version of this item.)'] ['This paper proposes a Gaussian estimator for nonlinear continuous time models of the short-term interest rate. The approach is based on a stopping time argument that produces a normalizing transformation facilitating the use of a Gaussian likelihood. A Monte Carlo study shows that the finite-sample performance of the proposed procedure offers an improvement over the discrete approximation method proposed by Nowman (1997). An em-pirical application to US and British interest rates is given.'] [' An asymptotic theory is developed for nonlinear regression with integrated processes. The models allow for nonlinear effects from unit root time series and therefore deal with the case of parametric nonlinear cointegration. The theory covers integrable and asymptotically homogeneous functions. Sufficient conditions for weak consistency are given and a limit distribution theory is provided. The rates of convergence depend on the properties of the nonlinear regression function, and are shown to be as slow as n[superscript 1/4] for integrable functions, and to be generally polynomial in n[superscript 1/2] for homogeneous functions. For regressions with integrable functions, the limiting distribution theory is mixed normal with mixing variates that depend on the sojourn time of the limiting Brownian motion of the integrated process.'] ['No abstract is available for this item.'] [" This paper explores tests of the hypothesis that the tail thickness of a distribution is constant over time. Using Hill's conditional maximum likelihood estimator for the tail index of a distribution, tests of tail shape constancy are constructed that allow for an unknown breakpoint. The recursive test is shown to be inconsistent in one direction, and only a one-sided test is recommended. Specifically, the test can be used when the alternative hypothesis is that the tail index decreases over time. A rolling and sequential version of the test is consistent in both directions. The methods are illustrated on recent stock price data for Thailand, Malaysia and Indonesia. The period covers the recent Asian financial crisis and enables us to assess whether breakpoints in domestic asset return distributions are related to known changes in institutional arrangements in the foreign currency markets of these countries. Copyright 2001 by The Review of Economic Studies Limited"] [" Using both semiparametric and parametric estimation methods, this paper corroborates earlier findings of fractionally integrated behaviour in the forward premium. Two new explanations are also proposed to help reconcile earlier conflicting empirical evidence on the time series properties of the forward premium. Traditional regression approaches used to test the forward rate unbiasedness hypothesis are then evaluated, including regression in levels, in returns (Fama's, 1984, regression), and in error-correction format. Interesting statistical and|or interpretive implications are found in all three cases. For example, the predictions of the appropriate nonstandard limit theory are consistent with many of the standard empirical results reported from Fama's regression, including the commonly occurring, yet puzzling negative correlations between spot returns and the forward premium. It is suggested that the principal failure of unbiasedness, may be due instead to the difference in persistence between these two series. Copyright \xc2\xa9 2001 John Wiley &amp; Sons, Ltd."] [' Recent work by the author on methods of spatial density analysis for time series data with stochastic trends is reviewed. The methods are extended to include processes with deterministic trends, formulae for the mean spatial density are given, and the limits of sample moments of non-stationary data are shown to take the form of moments with respect to the underlying spatial density, analogous to population moments of a stationary process. The methods are illustrated in some empirical applications and simulations. The empirical applications include macroeconomic data on inflation, financial data on exchange rates and political opinion poll data. It is shown how the methods can be used to measure empirical hazard rates for inflation and deflation. Empirical estimates based on historical US data over the last 60 years indicate that the predominant inflation risks are at low levels (2-6%) and low two-digit levels (10-12%), and that there is also a significant risk of deflation around the \xe2\x88\x921% level. Copyright \xc3\x82\xc2\xa9 2001 John Wiley &amp; Sons, Ltd.'] ['This paper develops an asymptotic theory for a general class of nonlinear non-stationary regressions, extending earlier work by Phillips and Hansen (1990) on linear coin-tegrating regressions.The model considered accommodates a linear time trend and stationary regressors, as well as multiple I(1) regressors. We establish consistency and derive the limit distribution of the nonlinear least squares estimator. The estimator is consistent under fairly general conditions but the convergence rate and the limiting distribution are critically dependent upon the type of the regression function. For integrable regression functions, the parameter estimates converge at a reduced n 1 4 rate and have mixed normal limit distributions. On the other hand, if the regression functions are homogeneous at infinity, the convergence rates are determined by the degree of the asymptotic homogeneity and the limit distributions are non-Gaussian. It is shown that nonlinear least squares generally yields inefficient estimators and invalid tests, just as in linear nonstationary regressions. The paper proposes a methodol-ogy to overcome such difficulties. The approach is simple to implement, produces efficient estimates and leads to tests that are asymptotically chi-square. It is implemented in empirical applications in much the same way as the fully modified estimator of Phillips and Hansen.'] ['Some challenges for econometric research on trending time are discussed in relation to some perceived needs of macroeconomics and macroeconomic policy making.<p>(This abstract was borrowed from another version of this item.)'] ['Time series data are often well modelled by using the device of an autoregressive root that is local to unity. Unfortunately, the localizing parameter (c) is not consistently estimable using existing time series econometric techniques and the lack of a consistent estimator complicates inference. This paper develops procedures for the estimation of a common localizing parameter using panel data. Pooling information across individuals in a panel aids the identification and estimation of the localising parameter and leads to consistent estimation in simple panel models. However, in the important case of models with concomitant deterministic trends, it is shown that pooled panel estimators of the localising parameter are asymptotically biased. Some techniques are developed to overcome this difficulty and consistent estimators of c in the region c <p>(This abstract was borrowed from another version of this item.)'] [' This paper overviews some recent developments in panel data asymptotics, concentrating on the nonstationary panel case and gives a new result for models with individual effects. Underlying recent theory are asymptotics for multi-indexed processes in which both indexes may pass to infinity. We review some of the new limit theory that has been developed, show how it can be applied and give a new interpretation of individual effects in nonstationary panel data. Fundamental to the interpretation of much of the asymptotics is the concept of a panel regression coefficient which measures the long run average relation across a section of the panel. This concept is analogous to the statistical interpretation of the coefficient in a classical regression relation. A variety of nonstationary panel data models are discussed and the paper reviews the asymptotic properties of estimators in these various models. Some recent developments in panel unit root tests and stationary dynamic panel regression models are also reviewed.'] ['No abstract is available for this item.'] [" Recent time series methods are applied to the problem of forecasting New Zealand's real GDP. Model selection is conducted within autoregressive (AR) and vector autoregressive (VAR) classes, allowing for evolution in the form of the models over time. The selections are performed using the Schwarz (1978) BIC and the Phillips-Ploberger (1996) PIC criteria. The forecasts generated by the data-determined AR models and an international VAR model are found to be competitive with forecasts from fixed format models and forecasts produced by the NZIER. Two illustrations of the methodology in conditional forecasting settings are performed with the VAR models. The first provides conditional predictions of New Zealand's real GDP when there is a future recession in the United States. The second gives conditional predictions of New Zealand's real GDP under a variety of profiles that allow for tightening in monetary conditions by the Reserve Bank."] ['This paper develops an asymptotic theory for time series binary choice models with nonstationary explanatory variables generated as integrated processes. Both logit and probit models are covered. The maximum likelihood (ML) estimator is consistent but a new phenomenon arises in its limit distribution theory. The estimator consists of a mixture of two components, one of which is parallel to and the other orthogonal to the direction of the true parameter vector, with the latter being the principal component. The ML estimator is shown to converge at a rate of n^(3/4) along its principal component but has the slower rate of n^(1/4) convergence in all other directions. This is the first instance known to the authors of multiple convergence rates in models where the regressors have the same (full rank) stochastic order and where the parameters appear in linear forms of these regressors. It is a consequence of the fact that the estimating equations involve nonlinear integrable transformations of linear forms of integrated processes as well as polynomials in these processes, and the asymptotic behavior of these elements are quite different. The limit distribution of the ML estimator is derived and is shown to be a mixture of two mixed normal distributions with mixing variates that are dependent upon Brownian local time as well as Brownian motion. It is further shown that the sample proportion of binary choices follows an are sine law and therefore spends most of its time in the neighbourhood of zero or unity. The result has implications for policy decision making that involves binary choices and where the decisions depend on economic fundamentals that involve stochastic trends. Our limit theory shows that, in such conditions, policy is likely to manifest streams of little intervention or intensive intervention.<p>(This abstract was borrowed from another version of this item.)'] ['The current practice for determining the number of cointegrating vectors, or the cointegrating rank, in a vector autoregression (VAR) requires the investigator to perform a sequence of cointegration tests. However, as was shown in Johansen (1992), this type of sequential procedure does not lead to consistent estimation of the cointegrating rank. Moreover, these methods take as given the correct specification of the lag order of the VAR, though in actual applications the true lag length is rarely known, Simulation studies by Toda and Phillips (1994) and Chao (1993), on the other hand, have shown that test performance of these procedures can be adversely affected by lag misspecification. This paper addresses these issues by extending the analysis of Phillips and Ploberger (1996) on the Posterior Information Criterion (PIC) to a partially nonstationary vector autoregressive process with reduced rank structure. This extension allows lag length and cointegrating rank to be jointly selected by the criterion, and it leads to the consistent estimation of both. In addition, we also evaluate the finite sample performance of PIC relative to existing model selection procedures, BIC and AIC, through a Monte Carlo study. Results here show PIC to perform at least as well and sometimes better than the other two methods in all the cases examined.<p>(This abstract was borrowed from another version of this item.)'] [' It is shown that the maximum likelihood estimator of a local to unity parameter can be consistently estimated with panel data when the cross-section observations are independent. Consistency applies when there are no deterministic trends or when there is a homogeneous deterministic trend in the panel model. When there are heterogeneous deterministic trends the panel MLE of the local to unity parameter is inconsistent. This outcome provides a new instance of inconsistent ML estimation in dynamic panels, and, unlike earlier results of this type, applies when both T approaches infinity and N approaches infinity. Copyright 1999 by Blackwell Publishing Ltd'] ['An asymptotic theory for stochastic processes generated from nonlinear transformations of nonstationary integrated time series is developed. Various nonlinear functions of integrated series such as ARIMA time series are studied, and the asymptotic distributions of sample moments of such functions are obtained and analyzed. The transformations considered in the paper include a variety of functions that are used in practical nonlinear statistical analysis. It is shown that their asymptotic theory is quite different from that of integrated processes and stationary time series. When the transformation function is exponentially explosive, for instance, the convergence rate of sample functions is path-dependent. In particular, the convergence rate depends not only on the size of the sample, but also on the realized sample path. Some brief applications of these asymptotics are given to illustrate the effects of nonlinearly transformed integrated processes on regression. The methods developed in the paper are useful in a project of greater scope concerned with the development of a general theory of nonlinear regression for nonstationary time series.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' This paper develops a regression limit theory for nonstationary panel data with large numbers of cross section and time series observations. The limit theory allows for both sequential limits and joins limits, and the relationship between these multidimensional limits is explored. The panel structures considered allow for no time series cointegration, heterogeneous cointegration, homogeneous cointegration, and near-homogeneous cointegration. The paper explores the existence of long-run average relations between integrated panel vectors. In the case of homogeneous and near homogeneous cointegrating panels, a panel fully modified regression estimator is developed and studied.'] ['No abstract is available for this item.'] [' The immense literature and diversity of unit root tests can at times be confusing even to the specialist and presents a truly daunting prospect to the uninitiated. In consequence, much empirical work still makes use of the simplest testing procedures because it is unclear from the literature and from recent reviews which tests if any are superior. This paper presents a survey of unit root theory with an emphasis on testing principles and recent developments. The general framework adopted makes it possible to consider tests of stochastic trends against trend stationarity and trend breaks of a general type. The main tests are listed, and asymptotic distributions are given in a simple form that emphasizes commonalities in the theory. Some simulation results are reported, and an extensive list of references and all annotated bibliography are provided. Copyright 1998 by Blackwell Publishers Ltd'] ['Some new tools for analyzing spurious regressions are presented. The theory utilizes the general representation of a stochastic process in terms of an orthonormal system and provides an extension of the Weierstrass theorem to include the approximation of continuous functions and stochastic processes by Wiener processes. The theory is applied to two classic examples of spurious regressions: regressions of stochastic trends on time polynomials and regressions among independent random walks. It is shown that such regressions reproduce in part and in whole the underlying orthonormal representations.'] [' This paper proposes an Augmented Dickey-Fuller (ADF) coefficient test for detecting the presence of a unit root in autoregressive moving average (ARMA) models of unknown order. Although the limit distribution of the coefficient estimate depends on nui-sance parameters, a simple transformation can be applied to eliminate the nuisance parameter asymptotically, providing an ADF coefficient test for this case. When the time series has an unknown deterministic trend, we propose a modified version of the ADF coefficient test based on quasi-differencing in the construction of the detrending regression as in Elliott et al. (1996). The limit distributions of these test statistics are derived. Empirical applications of these tests for common macroeconomic time series in the US economy are reported and compared with the usual ADF t -test.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ["Impulse response and forecast error variance matrix asymptotics are developed for VAR models with some roots at or near unity and some cointegration. For such models, it is shown that impulse responses that are estimated from an unrestricted VAR are inconsistent at long horizons and tend to random variables rather than the true impulse responses in the limit. The asymmetric distribution of the limit variates helps to explain the asymmetry of the finite sample distributions of the estimated impulse responses that is often found in simulations. VAR regressions also give inconsistent estimates of the forecast error variance of the optimal predictor at long horizons, and have a tendency to understate this variance. Moreover, predictions from an unrestricted nonstationary VAR are not optimal in the sense that they do not converge to the optimal predictors, at least for long horizons. In these respects, the asymptotic theory of prediction and policy analysis for nonstationary VAR's is very different from that which applies in stationary VAR's. By contrast, in a reduced rank regression the impulse response and forecast error variance matrix estimates are consistent and predictions from the fitted RRR model are asymptotically optimal, all provided the cointegrating rank is correctly specified or consistently estimated. Some simulations are reported which show these findings to be relevant in finite samples, and which assess the sensitivity of forecasting performance and policy analysis to certain design features of models in the VAR class.<p>(This abstract was borrowed from another version of this item.)"] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ["This paper develops a general theory of instrumental variables (IV) estimation that allows for both I(1) and I(0) regressors and instruments. The estimation techniques involve an extension of the fully modified (FM) regression procedure that was introduced in earlier work by Phillips-Hansen (1990). FM versions of the generalized instrumental variable estimation (GIVE) method and the generalized method of moments (GMM) estimator are developed. In models with both stationary and nonstationary components, the FM-GIVE and FM-GMM techniques provide efficiency gains over FM-IV in the estimation of the stationary components of a model that has both stationary and nonstationary regressors. The paper exploits a result of Phillips (1991a) that we can apply FM techniques in models with cointegrated regressors and even in stationary regression models without losing the method's good asymptotic properties. The present paper shows how to take advantage jointly of the good asymptotic properties of FM estimators with respect to the nonstationary elements of a model and the good asymptotic properties of the GIVE and GMM estimators with respect to the stationary components. The theory applies even when there is no prior knowledge of the number of unit roots in the system or the dimension or the location of the cointegration space. An FM extension of the Sargan (1958) test for the validity of the instruments is proposed.<p>(This abstract was borrowed from another version of this item.)"] ['No abstract is available for this item.'] ['This paper implements a new statistical approach to robust regression with nonstationary time series. The methods are presently under theoretical development in other work, and are briefly exposited here. They allow us to perform regressions in levels with nonstationary time series data, they accommodate data distributions with heavy tails and they permit serial dependence and temporal heterogeneity of unknown form in the equation errors. With these features the methods are well suited to applications with frequently sampled exchange rate data, which generally display all of these empirical characteristics. Our application is to daily data on spot and forward exchange rates between the Australian and US dollars over the period 1984-1991 following the deregulation of the Australian foreign exchange market. We find big differences between the robust and the non-robust regression outcomes and in the associated statistical tests of the hypothesis that the forward rate is an unbiased predictor of the future spot rate. The robust regression tests reject the unbiasedness hypothesis but still give the forward rate an important role as a predictor of the future spot rate.<p>(This abstract was borrowed from another version of this item.)'] [" This paper is concerned with model determination methods and their use in the prediction of economic time series. The methods are Bayesian but they can be justified by classical arguments as well. The paper continues some recent work on Bayesian asymptotic, develops embedding techniques for vector martingales, and implements the modeling ideas in a multivariate regression framework that includes Bayesian vector autoregression (BVAR's) and reduced rank regressions (RRR's). It is shown how the theory in the paper can be used; (i) to construct optimized BVAR's; (ii) to compare models such as BVAR's, optimized BVAR's and RRR's; (iii) to perform joint order selection of cointegrating rank, lag length and trend degree in a VAR; and (iv) to discard data that may be irrelevant and reset the initial conditions of a model. Copyright 1996 by The Econometric Society."] [' A limiting representation of the Bayesian data density is obtained and shown to be the same general exponential form for a wide class of likelihoods and prior distributions. An embedding theorem is given which shows how to embed the exponential density in a continuous time process. From the embedding, the authors obtain a large sample approximation to the model of the data that corresponds to the exponential density. This has the form of discrete observations drawn from a nonlinear stochastic differential equation driven by Brownian motion. No assumptions concerning stationarity or rates of convergence are required in the asymptotics. Some implications for statistical testing are explored. Copyright 1996 by The Econometric Society.'] ["This paper provides a robust statistical approach to testing the unbiasedness hypothesis in forward exchange market efficiency studies. The methods we use allow us to work explicitly with levels rather than differenced data. They are statistically robust to data distributions with heavy tails, and they can be applied to data sets where the frequency of observation and the futures maturity do not coincide. In addition, our methods allow for stochastic trend nonstationarity and general forms of serial dependence. The methods are applied to daily data of spot exchange rates and forward exchange rates during the 1920's, which marked the first episode of a broadly general floating exchange rate system. The tail behavior of the data is analyzed using an adaptive data-based method for estimating the tail slope of the density. The results confirm the need for the use of robust regression methods. We find cointegration between the forward rate and spot rate for the four currencies we consider (the Belgian and French francs, the Italian lira and the US dollar, all measured against the British pound), we find support for a stationary risk premium in the case of the Belgian franc, the Italian lira and the US dollar, and we find support for the simple market efficiency hypothesis (where the forward rate is an unbiased predictor of the future spot rate and there is a zero mean risk premium) in the case of the US dollar.<p>(This abstract was borrowed from another version of this item.)"] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['The paper develops a statistical theory for regressions with integrated regressors of unknown order and unknown cointegrating dimension. In practice, we are often unsure whether unit roots or cointegration is present in time series data, and we are also uncertain about the order of integration in some cases. This paper addresses issues of estimation and inference in cases of such uncertainty. Phillips (1995, Econometrica 63, 1023\xe2\x80\x931078) developed a theory for time series regressions with an unknown mixture of 1(0) and 1(1) variables and established that the method of fully modified ordinary least squares (FM-OLS) is applicable to models (including vector autoregressions) with some unit roots and unknown cointegrating rank. This paper extends these results to models that contain some I(0), I(1), and I(2) regressors. The theory and methods here are applicable to cointegrating regressions that include unknown numbers of I(0), I(1), and I(2) variables and an unknown degree of cointegration. Such models require a somewhat different approach than that of Phillips (1995). The paper proposes a residual-based fully modified ordinary least-squares (RBFMOLS) procedure, which employs residuals from a first-order autoregression of the first differences of the entire regressor set in the construction of the FMOLS estimator. The asymptotic theory for the RBFM-OLS estimator is developed and is shown to be normal for all the stationary coefficients and mixed normal for all the nonstationary coefficients. Under Gaussian assumptions, estimation of the cointegration space by RBFM-OLS is optimal even though the dimension of the space is unknown.'] ['One of the more obvious empirical characteristics of macroeconomic time series is their tendency to grow, or trend, over time. Dealing with this trendnonstationarity in models of multiple time series has been a major agenda of econometric research for much of the last decade and has produced an enormous literature. Equally, the goal of developing a general asymptotic theory of inference for stochastic processes has been a long-standing concern of probabilists and statisticians. Finally, understanding and modeling trend processes and cyclical activity lie at the nerve center of much of modern macroeconomics. As a consequence, research on nonstationary time series has brought statisticians, econometricians, and macroeconomists close together in productive ways that simply could not have been anticipated 10 years ago.'] ['No abstract is available for this item.'] ['This paper provides a robust statistical approach to nonstationary time series regression and inference. Fully modified extensions of traditional robust statistical procedures are developed that allow for endogeneities in the nonstationary regressors and serial dependence in the shocks that drive the regressors and the errors that appear in the equation being estimated. The suggested estimators involve semiparametric corrections to accommodate these possibilities, and they belong to the same family as the fully modified least-squares (FM-OLS) estimator of Phillips and Hansen (1990, Review of Economic Studies 57,99\xe2\x80\x93125). Specific attention is given to fully modified least absolute deviation (FM-LAD) estimation and fully modified M (FM-M) estimation. The criterion function for LAD and some M -estimators is not always smooth, and this paper develops generalized function methods to cope with this difficulty in the asymptotics. The results given here include a strong law of large numbers and some weak convergence theory for partial sums of generalized functions of random variables. The limit distribution theory for FM-LAD and FM-M estimators that is developed includes the case of finite variance errors and the case of heavytailed (infinite variance) errors. Some simulations and a brief empirical illustration are reported.'] ['A limit theory for instrumental variables (IV) estimation that allows for possibly nonstationary processes was developed in Kitamura and Phillips (1992, Fully Modified IV, GIVE, and GMM Estimation with Possibly Non-stationary Regressors and Instruments, mimeo, Yale University). This theory covers a case that is important for practitioners, where the nonstationarity of the regressors may not be of full rank, and shows that the fully modified (FM) regression procedure of Phillips and Hansen (1990) is still applicable. FM. versions of the generalized method of moments (GMM) estimator and the generalized instrumental variables estimator (GIVE) were also developed, and these estimators (FM-GMM and FM-GIVE) were designed specifically to take advantage of potential stationarity in the regressors (or unknown linear combinations of them). These estimators were shown to deliver efficiency gains over FM-IV in the estimation of the stationary components of a model.'] [' This paper provides a general framework which makes it possible to study the asymptotic behavior of FM regression in models with I(1) and I(0) regressors, models with unit roots, and models with only stationary regressors. This framework enables us to consider the use of FM regression in the context of vector autoregressions with some unit roots and some cointegrating relations. The resulting FM-VAR regressions are shown to produce optimal estimates of the cointegration space without prior knowledge of the number of unit roots in the system, without pretesting to determine the dimension of the cointegration space and without the use of restricted regression techniques like reduced rank regression. The paper also develops an asymptotic theory for inference. It is shown that conventional chi-squared critical values can be used to construct valid (but conservative) asymptotic tests in quite general FM time series regression. Copyright 1995 by The Econometric Society.'] ['No abstract is available for this item.'] ['This paper builds on some recent work by the author and Werner Ploberger (1991, 1994) on the development of "Bayes models" for time series and on the authors\' model selection criterion "PIC." The PIC criterion is used in this paper to determine the lag order, the trend degree, and the presence or absence of a unit root in an autoregression with deterministic trend. A new forecast encompassing test for Bayes models is developed which allows one Bayes model to be compared with another on the basis of their respective forecasting performance. The paper reports an extended empirical application of the methodology to the Nelson-Plosser (1982)/Schotman-van Dijk (1991) data. It is shown that parsimonious, evolving-format Bayes models forecast-encompass fixed Bayes models of the "AR(3) + linear trend" variety for most of these series. In some cases, the forecast performance of the parsimonious Bayes models is substantially superior. The results cast some doubts on the value of working with fixed format time series models in empirical research and demonstrate the practical advantages of evolving-format models. The paper makes a new suggestion for modelling interest rates in terms of reciprocals of levels rather than levels (which display more volatility) and shows that the best data-determined model for this transformed series is a martingale. Keywords: Bayes model, Bayes measure, BIC, forecast, forecast-encompass, model selection, PIC, unit root<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] [' The author derives some exact finite sample disbibutions and characterizes the tail behavior of maximum likelihood estimators of the cointegrating coefficients in error correction models. The reduced rank regression estimator has a distribution with Cauchy-like tails and no finite moments of integer order. The maximum likelihood estimator of the coefficients in a particular triangular system representation has matrix t-distribution tails with finite integer moments to order T - n + r, where T is the sample size, n is the total number of variables, and r is the dimension of cointegration space. This helps explain some recent simulation studies where extreme outliers occur more frequently for the reduced rank regression estimator than for alternative asymptotically efficient procedures based on triangular representation. Copyright 1994 by The Econometric Society.'] ['No abstract is available for this item.'] ['The Kalman filter is used to derive updating equations for the Bayesian data density in discrete time linear regression models with stochastic regressors. The implied \xe2\x80\x9cBayes model\xe2\x80\x9d has time varying parameters and conditionally heterogeneous error variances. A \xcf\x83-finite Bayes model measure is given and used to produce a new-model-selection criterion (PIC) and objective posterior odds tests for sharp null hypotheses like the presence of a unit root. This extends earlier work by Phillips and Ploberger [18]. Autoregressive-moving average (ARMA) models are considered, and a general test of trend-stationarity versus difference stationarity is developed in ARMA models that allow for automatic order selection of the stochastic regressors and the degree of the deterministic trend. The tests are completely consistent in that both type I and type II errors tend to zero as the sample size tends to infinity. Simulation results and an empirical application are reported. The simulations show that the PIC works very well and is generally superior to the Schwarz BIC criterion, even in stationary systems. Empirical application of our methods to the Nelson-Plosser [11] series show that three series (unemployment, industrial production, and the money stock) are level- or trend-stationary. The other eleven series are found to be stochastically nonstationary.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['This paper reexamines the permanent income hypothesis (PIH) in the frequency domain. Using a simple model, we demonstrate that the PIH implies the marginal propensity to consume (MPC) out of zero frequency income is unity. The PIH also implies that the MPC out of transitory (or high frequency) income is smaller than the long-run MPC. The paper employs a systems spectral regression procedure to test the PIH that accommodates stochastic trends in the consumption and income series as well as the joint dependence in these series. Monte Carlo simulations suggest that single equation techniques can produce inefficient tests of the PIH and that systems spectral regression methods provide substantially better tests. New empirical estimates of the consumption function and tests of the PIH based on systems spectral regression methods are reported for U.S. aggregate consumption and income data over the period 1948-1990. The empirical results provide partial support for the theoretical implications of the PIH in the frequency domain.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] [' This paper proposes an approach to testing for coefficient stability in cointegrating regressions in time series models. The test statistic considered is the one-sided version of the Lagrange Multiplier (LM) test. Its limit distribution is non-standard but is nuisance parameter free and can be represented in terms of a stochastic bridge process which is tied down like a Brownian bridge but relies on a random rather than a deterministic fraction do so. The approach provides a test of the null hypothesis of cointegration against specific directions of departure from the null; subset coefficient stability tests are also available. A small simulation studies the size and power properties of these tests and an empirical illustration to Australian data on consumption, disposable income, inflation and money is provided.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [" A limit theory for Wald tests of Granger causality in levels vector autoregressions (VAR's) and error correction models (ECM's) is developed, which allows for stochastic trends and cointegration. Earlier work is extended to the general case, thereby characterizing when these Wald tests are asymptotically valid as 'x'(superscript 2) criteria. Our results for inference from unrestricted levels VAR are not encouraging: the limit theory often involves nuisance parameters and nonstandard distributions, a situation offering no satisfactory statistical basis for these tests. Granger causality tests in ECM's also suffer from nuisance parameter dependencies asymptotically and in some cases nonstandard limit theory. Both these results are somewhat surprising in light of earlier research. Copyright 1993 by The Econometric Society."] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['The standard conclusion that is drawn from this empirical evidence is that many or most aggregate economic time series contain a unit root. However, it is important to note that in this empirical work the unit root is set up as the null hypothesis testing is carried out ensures that the null hypothesis is accepted unless there is strong evidence against it. Therefore, an alternative explanation for the common failure to reject a unit root is simply that most economic time series are not very informative about whether or not there is a unit root; or, equivalently, that standard unit root tests are not very powerful against relevant alternatives.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ["General formula for the finite sample and asymptotic distributions of the instrumental variable estimators and the Wald statistics in a simultaneous equation model are derived. It is assumed that the coefficient vectors of both endogenous and exogenous variables are only partially identified, even though the order condition for identification is satisfied. This work extends previous results in Phillips (1989) where the coefficient vector of the exogenous variables is partially identified and that of the endogenous variables is totally unidentified. The effect of partial identification on the finite sample and asymptotic distributions of the estimators and the Wald statistics is analyzed by isolating identifiable parts of the coefficient vectors using a rotation of the coordinate system developed in Phillips (1989). The pdf's of the estimators and the Wald statistics are illustrated using simulation and compared with their respective asymptotic distributions.<p>(This abstract was borrowed from another version of this item.)"] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' This paper provides detailed responses to the following eight discussants of the author\'s paper "To criticize the critics: an objective Bayesian analysis of stochastic trends": Gary Koop and Mark Steel; Edward Leamer; In-Moo Kim and G. S. Maddala; Dale J. Poirier; Peter C. Schotman and Herman K. van Dijk; James H. Stock; David DeJong and Charles H. Whiteman; and Christopher Sims. This reply puts new emphasis on the call made in the earlier paper for objective Bayesian analysis in time-series; it underlines the need of a new approach, especially with regard to posterior odds testing; and it draws attention to a new methodology of Bayesian analysis developed in a recent paper by Phillips and Ploberger (1991a). Some new simulations that shed light on certain comments of the discussants are provided, new empirical evidence is reported with the extended Nelson-Plosser data supplied by Schotman and van Dijk; and the new Phillips-Ploberger posterior odds test is given a brief empirical illustration. Copyright 1991 by John Wiley &amp; Sons, Ltd.'] ['Using generalized functions of random variables and generalized Taylor series expansions, we provide quick demonstrations of the asymptotic theory for the LAD estimator in a regression model setting. The approach is justified by the smoothing that is delivered in the limit by the asymptotics, whereby the generalized functions are forced to appear as linear functionals wherein they become real valued. Models with fixed and random regressors, and autoregressions with infinite variance errors are studied. Some new analytic results are obtained including an asymptotic expansion of the distribution of the LAD estimator.'] [" The authors' subject is estimation and inference concerning long-run economic equilibria in models with stochastic trends. An asymptotic theory is provided to analyze a menu of currently existing estimators of cointegrated systems. The authors study, in detail, the single-equation error-correction model (SEECM) approach of David Hendry. Their theoretical results lead to prescriptions for empirical work, such as specifying SEECM's nonlinearly and including lagged equilibrium relationships rather than lagged differences of the dependent variable as covariates. Simulations support these prescriptions and point to problems of overfitting not encountered in the semiparametric approach of P. B. C. Phillips and B. E. Hansen (1990). Copyright 1991 by The Review of Economic Studies Limited."] ['This paper studies the properties of the von Neumann ratio for time series with infinite variance. The asymptotic theory is developed using recent results on the weak convergence of partial sums of time series with infinite variance to stable processes and of sample serial correlations to functions of stable variables. Our asymptotics cover the null of iid variates and general moving average (MA) alternatives. Regression residuals are also considered. In the static regression model the Durbin-Watson statistic has the same limit distribution as the von Neumann ratio under general conditions. However, the dynamic models, the results are more complex and more interesting. When the regressors have thicker tail probabilities than the errors we find that the Durbin-Watson and von Neumann ration asymptotics are the same.<p>(This abstract was borrowed from another version of this item.)'] ['In two recent articles, Sims (1988) and Sims and Uhlig (1988) question the value of much of the ongoing literature on unit roots and stochastic trends. They characterize the seeds of this literature as "sterile ideas," the application of nonstationary limit theory as "wrongheaded and unenlightening" and the use of classical methods of inference as "unreasonable" and "logically unsound." They advocate in place of classical methods an explicit Bayesian approach to inference that utilizes a flat prior on the autoregressive coefficient. DeJong and Whiteman adopt a related Bayesian approach in a group of papers (1989a,b,c) that seek to reevaluate the empirical evidence from historical economic time series. Their results appear to be conclusive in turning around the earlier, influential conclusions of Nelson and Plosser (1982) that most aggregate economic time series have stochastic trends. So far, these criticisms of unit root econometrics have gone unanswered; the assertions about the impropriety of classical methods and the superiority of flat prior Bayesian methods have been unchallenged; and the empirical reevaluation of evidence in support of stochastic trends has been left without comment. This paper breaks that silence and offers a new perspective. We challenge the methods, the assertions and the conclusions of these articles on the Bayesian analysis of unit roots. Our approach is also Bayesian but we employ objective ignorance priors not flat priors in our analysis. Ignorance priors represent a state of ignorance about the value of a parameter and in many models are very different from flat priors. We demonstrate that in time series models flat priors do not represent ignorance but are actually informative (sic) precisely because they neglect generically available information about how autoregressive coefficients influence observed time series characteristics. Contrary to their apparent intent, flat priors unwittingly bias <p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] [" This paper deals with error correction models (ECM's) and cointegrated systems that are formulated in continuous time. Long-run equilibrium coefficients in the continuous system are always identified in the discrete time reduced form, so that there is no aliasing problem for these parameters. The long- run relationships are also preserved under quite general data filtering. Frequency domain procedures are outlined for estimation and inference. These methods are asymptotically optimal under Gaussian assumptions and they have the advantages of simplicity of computation and generality of specification, thereby avoiding some methodological problems of dynamic specification. In addition, they facilitate the treatment of data irregularities such as mixed stock and flow data and temporally aggregate partial equilibrium formulations. Models with restricted cointegrating matrices are also considered. Copyright 1991 by The Econometric Society."] [" Properties of maximum likelihood estimates of cointegrated systems are studied. Alternative formulations are considered, including a new triangular system error correction mechanism. We demonstrate that full system maximum likelihood brings the problem of inference within the family covered by the locally asymptotically mixed normal asymptotic theory, provided all unit roots have been eliminated by specification and data transformation. Methodological issues provide a major focus of the paper. Our results favor use of full system estimation in error correction mechanisms or subsystem methods that are asymptotically equivalent. They also point to disadvantages in the use of unrestricted VAR's formulated in levels and of certain single equation approaches to estimation of error correction mechanisms. Copyright 1991 by The Econometric Society."] ['In [4] Chan and Tran give the limit theory for the least-squares coefficient in a random walk with i.i.d. (identically and independently distributed) errors that are in the domain of attraction of a stable law. This paper discusses their results and provides generalizations to the case of I (1) processes with weakly dependent errors whose distributions are in the domain of attraction of a stable law. General unit root tests are also studied. It is shown that the semiparametric corrections suggested by the author in other work [22] for the finite-variance case continue to work when the errors have infinite variance. Surprisingly, no modifications to the formulas given in [22] are required. The limit laws are expressed in terms of ratios of quadratic functional of a stable process rather than Brownian motion. The correction terms that eliminate nuisance parameter dependencies are random in the limit and involve multiple stochastic integrals that may be written in terms of the quadratic variation of the limiting stable process. Some extensions of these results to models with drifts and time trends are also indicated.'] ['No abstract is available for this item.'] [' This paper develops an asymptotic theory for residual based tests for cointegration. Attention is given to the augmented Dickey-Fuller (ADF) test and the Z(subscript "alpha") and Z(subscript "t") unit root tests. Two new tests are also introduced. The tests are shown to be asymptotically similar, and simple representations of their limiting distributions are given and asymptotic critical values are tabulated. The ADF and Z(subscript "t") tests are asymptotically equivalent. Power properties of the test are also studied. The tests are consistent if suitably constructed, but the ADF and Z(subscript "t") tests have slower rates of divergence under cointegration than the other tests. Copyright 1990 by The Econometric Society.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' Estimates a cointegrating relation among the listed variables using fully modified least squares. Phillips and Hansen(1990), "Statistical Inference in Instrumental Variables Regression with I(1) Processes", Review of Economic Studies, vol 57, 99-125. Hansen, Bruce (1992), "Efficient Estimation and Testing of Cointegrating Vectors in the Presence of Deterministic Trends", Journal of Econometrics, vol 53, 87-121.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['This paper continues the theoretical investigation of Park and Phillips. We develop an asymptotic theory of regression for multivariate linear models that accommodates integrated processes of different orders, nonzero means, drifts, time trends, and cointegrated regressors. The framework of analysis is general but has a common architecture that helps to simplify and codify what would otherwise be a myriad of isolated results. A good deal of earlier research by the authors and by others comes within the new framework. Special models of some importance are considered in detail, such as VAR systems with multiple lags and cointegrated variates.'] ['It is shown that matrix quotients of submatrices of a spherical matrix are distributed as matrix Cauchy. This generalizes known results for scalar ratios of independent normal variates. The derivations are simple and make use of the theory of invariant measures on manifolds.'] ['No abstract is available for this item.'] ['This paper studies a class of models where full identification is not necessarily assumed. We term such models partially identified. It is argued that partially identified systems are of practical importance since empirical investigators frequently proceed under conditions that are best described as apparent identification. One objective of the paper is to explore the properties of conventional statistical procedures in the context of identification failure. Our analysis concentrates on two major types of partially identified model: the classic simultaneous equations model under rank condition failures; and time series spurious regressions. Both types serve to illustrate the extensions that are needed to conventional asymptotic theory if the theory is to accommodate partially identified systems. In many of the cases studied, the limit distributions fall within the class of compound normal distributions. They are simply represented as covariance matrix or scalar mixtures of normals. This includes time series spurious regressions, where representations in terms of functionals of vector Brownian motion are more conventional in recent research following earlier work by the author.'] ['No abstract is available for this item.'] ['This paper studies the effects of spurious detrending in regression. The asymptotic behavior of traditional least squares estimators and tests are examined in the context of models where the generating mechanism is systematically misspecified by the presence of deterministic time trends. Most previous work on the subject has relied upon Monte Carlo studies to understand the issues involved in detrending data that is generated by integrated processes and our analytical results help to shed light on many of the simulation findings. Standard F tests and Hausman tests are shown to inadequately discriminate between the competing hypotheses. Durbin-Watson statistics, on the other hand, are shown to be valuable measures of series stationarity. The asymptotic properties of regressions and excess volatility tests with detrended integrated time series are also explored.<p>(This abstract was borrowed from another version of this item.)'] [' The concept of a near-integrated vector random process is introduce d, helping the author work towards a general asymptotic theory of regression fo r multiple time series in which some series may be integrated processe s of the ARIMA type, others may be stable ARMA processes with near unit roots, and yet others may be mildly explosive. A limit theory for th e sample moments of such time series is developed using weak convergence. The theory is applied to the study of vector autoregress ions and cointegrating regressions of the type advanced by R. F. Engle and C. W. Granger (1987). A noncentral limiting distribution theory is derived for some recently-proposed multivariate unit root tests. Models with drift and near-integration are also studied. Copyright 1988 by The Econometric Society.'] ['This paper develops a multivariate regression theory for integrated processes which simplifies and extends much earlier work. Our framework allows for both stochastic and certain deterministic regressors, vector autoregressions, and regressors with drift. The main focus of the paper is statistical inference. The presence of nuisance parameters in the asymptotic distributions of regression F tests is explored and new transformations are introduced to deal with these dependencies. Some specializations of our theory are considered in detail. In models with strictly exogenous regressors, we demonstrate the validity of conventional asymptotic theory for appropriately constructed Wald tests. These tests provide a simple and convenient basis for specification robust inferences in this context. Single equation regression tests are also studied in detail. Here it is shown that the asymptotic distribution of the Wald test is a mixture of the chi square of conventional regression theory and the standard unit-root theory. The new result accommodates both extremes and intermediate cases.'] ["The asymptotic theory of regression with integrated processes of the ARIMA type frequently involves weak convergence to stochastic integrals of the form [integral operator]01 W dW, where W(r) is standard Brownian motion. In multiple regressions and vector autoregressions with vector ARIMA processes, the theory involves weak convergence to matrix stochastic integrals of the form [integral operator]01 B dB', where B(r) is vector Brownian motion with a non-scalar covariance matrix. This paper studies the weak convergence of sample covariance matrices to [integral operator]01 B dB' under quite general conditions. The theory is applied to vector autoregressions with integrated processes."] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['Nine leading journals that publish statistical theory are used to provide a data base of institutional and individual research activity in statistics over the period 1980\xe2\x80\x931986. From this data base, we construct both institutional and individual research rankings according to standardized page counts of articles published in these journals over the stated period. The study is worldwide and we provide breakdowns of publication by country and by journal. Separate rankings are also provided for both institutions and individuals according to publication track records in the Annals of Statistics alone.'] ['No abstract is available for this item.'] ['General issues about the methodology of empirical econometric research are discussed. It is argued that the most successful paradigms for applied work are the ones that have a capacity to survive and to evolve into more useful forms as these are needed. Paradigms that embrace progressive modeling principles, such as those espoused by David Hendry, seem most amenable to this criterion. It is also argued that econometric theory has a large role to play in helping us to understand the strengths and the weaknesses of a methodology and to codify what its prescriptions entail. The time series methodology of David Hendry is considered in some detail. It is shown that the Hendry methodology comes remarkable close to achieving an optimal inference procedure for long run structural relationships even though it is conducted on a single equation basis. The findings indicate that the methodology may be improved further to achieve results that are equivalent to optimal estimation.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['Conditional independence almost everywhere in the space of the conditioning variates does not imply unconditional independence, although it may well imply unconditional independence of certain functions of the variables. An example that is important in linear regression theory is discussed in detail. This involves orthogonal projections on random linear manifolds, which are conditionally independent but not unconditionally independent under normality. Necessary and sufficient conditions are obtained under which conditional independence does imply unconditional independence.<p>(This abstract was borrowed from another version of this item.)'] [' This paper utilizes asymptotic expansions of the Edgeworth type to investigate alternative forms of the Wald test of nonlinear restricti ons. Some formulae for the asymptotic expansion of the distribution of the Wald statistic are provided for a general case that should include most econometric applications. When specialized to the simple cases that have been studied recently in the literature, these formulae are found to explain rather well the discrepancies in sampling behavior that have been observed by other authors. It is further shown how the corrections delivered by Edgeworth expansions m ay be used to find transformations of the restrictions that accelerate covergence to the asymptotic distribution. Copyright 1988 by The Econometric Society.'] ['Under general conditions the sample covariance matrix of a vector martingale and its differences converges weakly to the matrix stochastic integral \xe2\x88\xab 01 BdB\xe2\x80\xb2 , where B is vector Brownian motion. For strictly stationary and ergodic sequences, rather than martingale differences, a similar result obtains. In this case, the limit is \xe2\x88\xab 01 BdB\xe2\x80\xb2 + \xce\x9b and involves a constant matrix \xce\x9b of bias terms whose magnitude depends on the serial correlation properties of the sequence. This note gives a simple proof of the result using martingale approximations.'] ['No abstract is available for this item.'] [' This paper studies the random walk in a general time series setting that allows for weakly dependent and heterogeneously distributed innovations. It is shown that simple least squares regression consistently estimates a unit root under very general conditions in spite of the presence of autocorrelated errors. The limiting distribution of the standardized estimator and the associated regression t statistic are found using functional central limit theory. New tests of the random walk hypothesis are developed which permit a wide class of dependent and heterogeneous innovation sequences. A new limiting distribution theory is constructed based on the concept of continuous data recording. This theory, together with an asymptotic expansion that is developed in the paper for the unit root case, explain many of the interesting experimental results recently reported in Evans and Savin (1981, 1984). Copyright 1987 by The Econometric Society.'] ['Stock and Watson (1986) Tests the Hypothesis That Real Per Capita Gnp Has a Unit Root by Using a Test Statistic Due to Phillips (1985) Which Incorporates a Nonparametric Correction for the Serial Correlation Induced by System and Error Dynamics. the Version of This Test That Is Used by Stock and Watson Does Not Accomodate the Presence of a Drift and to Compensate They Detrend the Series by Extracting a 1.5% Annual Trend Growth. We Use a Version of This Class of Nonparametric Tests, Developed by Phillips and Perron (1986), Which Allows for an Estimated Drift and Reassess the Stock and Watson Findings.<p>(This abstract was borrowed from another version of this item.)'] ["This paper studies the statistical properties of vector autoregressions (VAR's) for quite general multiple time series which are integrated processes of order one. Functional central limit theorems are given for multivariate partial sums of weakly dependent innovations and these are applied to yield first-order asymptotics in nonstationary VAR's. Characteristic and cumulant functionals for generalized random processes are introduced as a means of developing a refinement of central limit theory on function spaces. The theory is used to find asymptotic expansions of the regression coefficients in nonstationary VAR's under very general conditions. The results are specialized to the scalar case and are related to other recent work by the author [21]."] ["A new series representation of the exact distribution of Hotelling's generalized T02 statistic is obtained. Unlike earlier work, the series representation given here is everywhere convergent. Explicit formulae are given for both the null and the non-central distributions. Earlier results by [1], 215-225), which are convergent on the interval [0, 1), are also derived quite simply from our formulae. The paper therefore provides a solution to the long standing problem of the exact distribution of the T02 statistic in the general case."] ['No abstract is available for this item.'] ['This paper develops a general asymptotic theory of regression for processes which are integrated of order one. The theory includes vector autoregressions and multivariate regressions amongst integrated processes that are driven by innovation sequences which allow for a wide class of weak dependence and heterogeneity. The models studied cover cointegrated systems and quite general linear simultaneous equations systems with contemporaneous regressor-error correlation and serially correlated errors. Problems of statistical testing in vector autoregressions and multivariate regressions with integrated processes are also studied. It is shown that the asymptotic theory for conventional tests involves major departures from classical theory and raises new and important issues of the presence of nuisance parameters in the limiting distribution theory.<p>(This abstract was borrowed from another version of this item.)'] ['In a recent article (1984a) Phillips showed that the distribution of the limited information maximum likelihood (LIML) estimator of the coefficients of the endogenous variables in a single structural equation is multivariate Cauchy in the leading (totally unidentified) case. The purpose of the present note is to show that the same result holds for the full information maximum likelihood (FIML) estimator. Our proof relies on the theory of invariant measures on a Stiefel manifold. This approach provides a major simplification of the derivation of the LIML result given in the earlier article and extends to the FIML case without difficulty. We start by illustrating its use for LIML.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['This paper provides an analytical study of spurious regressions involving the levels of economic time series. As asymptotic theory is developed for regressions that relate independent random walks. It is shown that the usual t ratio significance tests do not possess limiting distributions but actually diverge as the sample size T approaches infinity. The Durbin-Watson statistic, on the other hand, converges in probability to zero. An alternative asymptotic theory is also analyzed. An alternative asymptotic theory is developed based on the concept of continuous data recording. This theory together with the large sample asymptotics that we present go a long way towards explaining the experimental results of Granger and Newbold (1974, 1977).<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ["This paper derives the exact distribution of the Wald statistic for testing general linear restrictions on the coefficients in the multivariate linear model. This generalizes all previously known results including those for the standard F statistic in linear regression, for Hotelling's T^{2} test and for Hotelling's generalized T_{0}^{2} test. Conventional classical assumptions of normally distributed errors and nonrandom exogenous variables are employed.<p>(This abstract was borrowed from another version of this item.)"] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ["Cram\xc3\xa9r's inversion formula for the distribution of a quotient is generalized to matrix variates and applied to give an alternative derivation of the matrix t-distribution."] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['It is shown that the exact finite sample distribution of the limited information maximum likelihood (LIML) estimator in a general and leading single equation case is multivariate Cauchy. When the LIML estimator utilizes a known error covariance matrix (LIMLK) it is proved that the same Cauchy distribution still applies. The corresponding result for the instrumental variable (IV) estimator is a form of multivariate t density where the degrees of freedom depend on the number of instruments.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['This paper derives the exact probability density function of the instrumental variable (IV) estimator of the exogenous variable coefficient vector in a structural equation containing n+1 endogenous variables and N degrees of overidentification. A leading case of the general distribution that is more amenable to analysis and computation is also presented. Conventional classical assumptions or normally distributed errors and nonrandom exogenous variables are employed.<p>(This abstract was borrowed from another version of this item.)'] ["This article proposes a new approach to small sample theory that achieves a meaningful integration of earlier directions of research in this field. The approach centers on the constructive technique of approximating distributions developed recently by the author in [10]. This technique utilizes extended rational approximants (ERA's) which methods (such as those based on asymptotic expansions) and which simultaneously blend information from diverse analytic, numerical and experimental sources. The first part of the article explores the general theory of approximation of continuous probability distributions by means of ERA's. Existence, characterization, error bound and uniqueness for the convergence result obtained earlier in [10]. Some further aspects of finding ERA's by modifications to multiple-point Pade approximants are presented and the new approach is applied to the non-circular serial correlation coefficient. The results of this application demonstrate how ERA's provide systematic improvements over Edgeworth and saddlepoint techniques. These results, taken with those of the earlier article [10], suggest that the approach offers considerable potential for empirical application in terms of its reliability, convenience and generality.<p>(This abstract was borrowed from another version of this item.)"] ['Examples are given which show that:(i) normality is not Necessary for the consistency of the quasi maximum likelihood estimator in the nonlinear simultaneous equations model (nonlinear FIML) even when there are major departures from linearity; and (ii) the lemma which is used extensively by Amemiya [2] in the theoretical development of the properties of nonlinear FIML under the assumption of normality is, as presently stated, incorrect.<p>(This abstract was borrowed from another version of this item.)'] ["Results published recently by Hendry (1979) for the limiting distribution of inconsistent instrumental variable estimators in misspecified dynamic systems are incorrect. In particular, Hendry's derivations involve the use of an appropriate control variate and lead to an expression for the covariance matrix of the limiting distribution which, in general, omits many additional terms. Correct formulae are given in the present paper and the accuracy of the asymptotic distribution in finite samples is investigated in a simple case using the know exact small sample distribution. On the basis of our exact results, we argue for caution in the use of response surface regressions of the type recommended by Hendry in Monte Carlo experiments; and we emphasize the need for qualifying statements concerning the parameter environments in which the adequacy of these regressions has been substantiated.<p>(This abstract was borrowed from another version of this item.)"] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['A local limit theorem for large deviations of o(n)1/2, where n is the sample size, is developed for multivariate statistics which are more general than standardised means, but which depend on n in much the same way. In particular, the cumulants of the statistic are of the same order in n-1/2 as those of a standardised mean. The theory is derived under conditions which correspond to those in earlier work by Richter on limit theorems for standardised means and by Chambers on the validity of Edgeworth expansions for multivariate statistics.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.']