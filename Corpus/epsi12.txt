 ['Drastic changes in central bank operations and monetary institutions in recent years have made previously standard approaches to explaining the determination of the price level obsolete. Recent expansions of central bank balance sheets and of the levels of rich-country sovereign debt, as well as the evolving political economy of the European Monetary Union, have made it clear that fiscal policy and monetary policy are intertwined. Our thinking and teaching about inflation, monetary policy, and fiscal policy should be based on models that recognize fiscal-monetary policy interactions. (JEL E31, E52, E58, E62, H63)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['The euro was created at a time when the conventional view was that a central bank could control inflation by controlling the money supply and that fiscal policy\xe2\x80\x99s interaction with monetary policy took the form of attempts to get the central bank to finance government debt. With a sufficiently firm and independent central bank, this view considered that financial markets would force discipline on fiscal policy. By creating a strong, independent central bank at the european level, facing multiple country-level fiscal authorities, the threat of political pressures for inflationary finance would be lower than with individual country central banks. We are learning that this formerly conventional view was largely mistaken. In particular, the euro as originally structured seemed to require the elimination of national-level lender of last resort functions for central banks, without creating as strong a replacement at the european level. Having discovered these gaps through experience, what options are there going forward for the euro area? A solution would be to fill in the institutional gaps in the original euro framework. At a minimum, this would require a new institution with at least some taxing power, able to issue debt and to buy, or not buy, the debt of euro area governments. Such an institution would of course have to be subject to democratic control.'] ["The inflation of the 1970s in the US is often discussed as if the only type of policy action that could have prevented the inflation were monetary policy actions and the only type of policy errors that might have induced the inflation were monetary policy errors. Yet fiscal policy underwent dramatic shifts in the 1970s and economic theory makes clear that in an environment of uncertainty about future fiscal policy, monetary policy instruments may lose potency or have perverse effects. This paper documents the vagaries of fiscal policy in this period and argues that people at the time must have been uncertain about fiscal policy's future course. It also lays out a theoretical framework for understanding the effects of fiscal uncertainties on monetary policy and shows that fiscal variables have predictive value in dynamic models, even if traditional monetary policy indicators are included in the system."] ['Several aspects of the difficulties of policy at the zero lower bound are discussed: The difficulty of credible commitment to higher future inflation, as most New Keynesian models imply is necessary; the need for fiscal and monetary policy coordination; and the pitfalls in the taking of quasi-fiscal actions by the central bank.'] ['The fact is, economics is not an experimental science and cannot be. "Natural" experiments and "quasi" experiments are not in fact experiments. They are rhetorical devices that are often invoked to avoid having to confront real econometric difficulties. Natural, quasi-, and computational experiments, as well as regression discontinuity design, can all, when well applied, be useful, but none are panaceas. The essay by Angrist and Pischke, in its enthusiasm for some real accomplishments in certain subfields of economics, makes overbroad claims for its favored methodologies. What the essay says about macroeconomics is mainly nonsense. Consequently, I devote the central part of my comment to describing the main developments that have helped take some of the con out of macroeconomics. Recent enthusiasm for single-equation, linear, instrumental variables approaches in applied microeconomics has led many in these fields to avoid undertaking research that would require them to think formally and carefully about the central issues of nonexperimental inference -- what I see and many see as the core of econometrics. Providing empirically grounded policy advice necessarily involves confronting these difficult central issues.'] ['As with many important theories, the long run value of Phillips curve theories may lie in the new flames that are emerging from its dying embers.'] ['Inference for multiple-equation Markov-chain models raises a number of difficulties that are unlikely to appear in smaller models. Our framework allows for many regimes in the transition matrix, without letting the number of free parameters grow as the square as the number of regimes, but also without losing a convenient form for the posterior distribution. Calculation of marginal data densities is difficult in these high-dimensional models. This paper gives methods to overcome these difficulties, and explains why existing methods are unreliable. It makes suggestions for maximizing posterior density and initiating MCMC simulations that provide robustness against the complex likelihood shape.'] ['I have written several papers for BPEA (2002; 1996; 1982) looking at the relation of multiple equation quantitative economic models to the process of monetary policy making. When the first of these papers was written, the impact of the rational expectations critique in undermining academic interest in quantitative modeling for monetary policy was apparent. Many, maybe most, economists took the Lucas critique to imply that the month-to-month business of choosing monetary policy actions in the light of current information was trivial or irrelevant. Economists were thought to have nothing useful to say about it. Economists were supposed to contemplate only the choice of policy \xe2\x80\x9crules\xe2\x80\x9d, which were modeled as functions mapping the state of the economy into policy actions.<p>(This abstract was borrowed from another version of this item.)'] ['We take a decision-theoretic view on the question of how to use instrumental variables and method of moments. Since prior beliefs play an inevitably strong role when instruments are possibly "weak", or when the number of instruments is large relative to the number of observations, it is important in these cases to report characteristics of the likelihood beyond the usual IV or ML estimates and their asymptotic (i.e. second-order local) approximate standard errors. IV and GMM appeal because of their legitimate claim to be convenient to compute in many cases, and a (spurious) claim that they can be justified with few "assumptions". We discuss some approaches to making such a claim more legitimately.'] ['No abstract is available for this item.'] ['The issue of uncovering the effects of monetary policy is far short of resolution. In the identified VAR literature, restrictions have been imposed to identify the effects of unpredictable monetary policy disturbances. We offer critical views on the unreasonable assumptions in the existing work and argue for careful economic argument about identifying assumptions. We display a structural stochastic equilibrium model in which our VAR identification would produce correct results while drawing attention to the serious lack of time series fit in most of the DSGE literature.<p>(This abstract was borrowed from another version of this item.)'] ['A multivariate regime-switching model for monetary policy is confronted with U.S. data. The best fit allows time variation in disturbance variances only. With coefficients allowed to change, the best fit is with change only in the monetary policy rule and there are three estimated regimes corresponding roughly to periods when most observers believe that monetary policy actually differed. But the differences among regimes are not large enough to account for the rise, then decline, in inflation of the 1970s and 1980s. Our estimates imply monetary targeting was central in the early 1980s, but also important sporadically in the 1970s.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['If macroeconomic models are to be useful in policy-making, where uncertainty is pervasive, the models must be treated as probability models, whether formally or informally. Use of explicit probability models allows us to learn systematically from past mistakes, to integrate model-based uncertainty with uncertain subjective judgment, and to bind data-bassed forecasting together with theory-based projection of policy effects. Yet in the last few decades policy models at central banks have steadily shed any claims to being believable probability models of the data to which they are fit. Here we describe the current state of policy modeling, suggest some reasons why we have reached this state, and assess some promising directions for future progress.<p>(This abstract was borrowed from another version of this item.)'] [' Progress, regress, and continuity in quantitative analysis for policy are discussed. We look at the present from the perspective of Tinbergen, Haavelmo, and Keynes. Probability modeling has been in retreat at central banks and elsewhere. New computational methods, though, are making Bayesian analysis of previously intractable problems possible, and at the same time appreciation of the clarity with which Bayesian data analyis integrates with decison-making is spreading.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['We discuss the results of fitting a 6-variable structural VAR in which we allow for certain types of parameter variation over time. Allowing structural equation variances to change over time is extremely important in improving fit. Allowing the coefficients that define the model\xe2\x80\x99s dynamics to change is less important to improving fit, though models with changing parameters are consistent with the data. We pay special attention to a version of the model that allows the monetary policy rule, but not other parts of the model, to show changing coefficients. Results from this model fit some aspects of conventional wisdom about changes in monetary policy over time, but imply that the changes in policy have been more subtle than dramatic. We construct counterfactual histories for the early 1980\xe2\x80\x99s, suppressing the \xe2\x80\x9cVolcker regime\xe2\x80\x9d in monetary policy. We find a steadier decline in inflation and a smaller recession earlier in the period, but slower growth later, than actually occurred.'] [' We describe methods for solving general linear rational expectations models in continuous or discrete timing with or without exogenous variables. The methods are based on matrix eigenvalue decompositions. Copyright 2002 by Kluwer Academic Publishers'] [' Dollarization implies a reduction in the menu of assets available to the government and to the private sector in managing risk. Whatever the gains from dollarization, the costs of reducing the asset menu need to be weighed against them. This paper presents models, one a simple generalization of a well-known model of tax smoothing by Barro, in which these costs are explicit. Along the way, it suggests that there is likely to be no reduction in interest costs to the government from dollarization.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ["This article reviews Monetary Policy Rules, edited by John Taylor. The book evaluates the Taylor rule, a policy rule that specifies changes in the central bank's interest rate according to what is happening to two variables, real output and inflation. Questions are raised about (a) how well the models fit the data; (b) the validity of the assumption that there has been clear improvement in monetary policy; and (c) the rule's microfoundations."] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [" We show how to correctly extend known methods for generating error bands in reduced form VAR's to overidentified models. We argue that the conventional pointwise bands common in the literature should be supplemented with measures of shape uncertainty, and we show how to generate such measures. We focus on bands that characterize the shape of the likelihood. Such bands are not classical confidence regions. We explain that classical confidence regions mix information about parameter location with information about model fit, and hence can be misleading as summaries of the implications of the data for the location of parameters."] [' If dynamic multivariate models are to be used to guide decisionmaking, it is important that probability assessments of forecasts or policy projections be provided. When identified Bayesian vector autoregression (VAR) models are presented with error bands in the existing literature, both conceptual and numerical problems have not been dealt with in an internally consistent way. In this paper, the authors develop methods to introduce prior information in both reduced-form and structural VAR models without introducing substantial new computational burdens. Their approach makes it feasible to use a single, large dynamic framework (for example, twenty-variable models) for tasks of policy projections. Copyright 1998 by Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['Probabilistic reasoning is essential to discourse in economics. This is true in any discipline in which, as in economics, data collection is constrained and beliefs about the phenomena being studied are crucial to decisions that cannot be delayed. Some economists have recently turned away from form probabilistic inference, in part because of legitimate discontent with the prescriptions of specialized econometricians. However, this turning away has gone in mutually inconsistent directions and is in the long run unsustainable. It should be more widely recognized that careful applied work in macroeconomics, using steadily advancing probabilistic modeling techniques, has been steadily increasing.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['In a world where time series show clear seasonal fluctuations, rational agents will take account of those fluctuations in planning their own behavior. Using seasonally adjusted data to model behavior of such agents throws away information and introduces possibly severe bias. Nonetheless it may be true fairly often that rational expectations modeling with seasonally adjusted data, treating the adjusted data as if it were actual data, gives approximately correct results; and naive extensions of standard modeling techniques to seasonally unadjusted data may give worse results than naive use of adjusted data. This paper justifies these claims with examples and detailed arguments.<p>(This abstract was borrowed from another version of this item.)'] ['Existing theory and evidence on the effects of monetary policy are reviewed. Substantial room for disagreement among economists remains. New evidence, based on multivariate time series studies of several countries, is presented. While certain patterns in the data consistent with effective monetary policy are strikingly similar across countries, others, particularly the tendency of interest rate increases to predict high inflation, are harder to reconcile with effective monetary policy.<p>(This abstract was borrowed from another version of this item.)'] [' For the first-order univariate autoregression without constant term, the joint density (corresponding to a flat prior) for the true coefficient and its least squares estimate is estimated by Monte Carlo and graphically displayed. The graphs show how a symmetric distribution for the coefficient conditional on the estimate coexists with an asymmetric distribution for the estimate conditional on the coefficient. Prior densities implicit in treating classical significance levels as if they were Bayesian posterior probabilities are calculated. They are shown to depend sensitively on the estimated coefficient and to put substantial probability on values of the coefficient above one. Copyright 1991 by The Econometric Society.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' Backsolving is a class of methods that generate simulated values for exogenous forcing processes in a stochastic equilibrium model from specified assumed distributions for Euler-equation disturbances. It can be thought of as a way to force the approximation error generated by inexact choice of decision rule or boundary condition into distortions of the distribution of the exogenous shocks in the simulations rather than into violations of the Euler equations as with standard approaches. Here it is applied to a one-sector neoclassical growth model with decision rule generated from a linear-quadratic approximation.'] [' This paper considers estimation and hypothesis testing in linear time series when some or all of the variables have (possibly multiple) unit roots. The motivating example is a vector autoregression with some unit roots in the companion matrix, which might include polynomials in time as regressors. Parameters that can be written as coefficients on mean zero, nonintegrated regressors have jointly normal asymptotic distribution, converging at the rate of T(superscript "one-half") In general, the other coefficients (including the coefficient on polynomials in time), and associated t and F test statistics, have nonstandard asymptotic distributions. Copyright 1990 by The Econometric Society.'] ['No abstract is available for this item.'] ['This paper examines several grounds for doubting the value of much of the special attention recently devoted to unit root econometrics. Unit root hypotheses are less well connected to economic theory than is often suggested or assumed; distribution theory for tests of other hypotheses in models containing unit roots are less often affected by the presence of unit roots than has been widely recognized; and the Bayesian inferential theory for dynamic models is largely unaffected by the presence of unit roots. The paper displays an example to show that when Bayesian probability statements and classical marginal significance levels diverge as they do for unit root models, the marginal significance levels are misleading. The paper shows how to carry out Bayesian inference when discrete weight is given to the unit root null hypothesis in a univariate model.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['In this article, Christopher A. Sims argues the answer to his title is yes. Sims explains that any decisionmaking model must incorporate some identifying assumptions to enable it to forecast the effects of alternative decisions. He argues that although all identifying assumptions in econometric policymaking models are of uncertain validity, those incorporated in vector autoregression (VAR) forecasting models have the advantage of allowing their uncertainty to be measured. Sims concludes by demonstrating a method for identifying a small macroeconomic VAR model so that it can be used to analyze monetary policy'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['When monthly data on production, prices, and the money stock are interpreted, via a vector autoregression, as generated by dynamic responses to "surprises" in each of the variables, a remarkable similarity in dynamics between interwar and postwar business cycles emerges, though the size of the "surprises" is much larger in the interwar period. Furthermore, the money stock emerges as firmly causally prior, in Granger\'s sense, in both periods and accounts for a substantial fraction of variance in production in both periods. When a short interest rate is added to the vector autoregression, the remarkable similarity in dynamics between periods persists, but the central role of the money stock surprises evaporates for the postwar period. While there are potential monetarist explanations for such an observation, none of them seem to fit comfortably the estimated dynamics. A non-monetarist explanation of the dynamics, based on the role of expectations in investment behavior, seems to fit the estimated dynamics better. That this explanation, which is consistent with a passive role for money, could account for so much of the observed postwar relation between money stock and income may raise doubts about the monetarist interpretation even of the interwar data.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.']