 ['Nonlinear time series models, especially those with regime-switching and/or conditionally heteroskedastic errors, have become increasingly popular in the economics and finance literature. However, much of the research has concentrated on the empirical applications of various models, with little theoretical or statistical analysis associated with the structure of the processes or the associated asymptotic theory. In this paper, we derive sufficient conditions for strict stationarity and ergodicity of three different specifications of the first-order smooth transition autoregressions with heteroskedastic errors. This is essential, among other reasons, to establish the conditions under which the traditional LM linearity tests based on Taylor expansions are valid. We also provide sufficient conditions for consistency and asymptotic normality of the Quasi-Maximum Likelihood Estimator for a general nonlinear conditional mean model with first-order GARCH errors..'] [' Macroeconomic forecasts are frequently produced, widely published, intensively discussed, and comprehensively used. The formal evaluation of such forecasts has a long research history. Recently, a new angle to the evaluation of forecasts has been addressed, and in this review we analyze some recent developments from that perspective. The literature on forecast evaluation predominantly assumes that macroeconomic forecasts are generated from econometric models. In practice, however, most macroeconomic forecasts, such as those from the IMF, World Bank, OECD, Federal Reserve Board, Federal Open Market Committee (FOMC), and the ECB, are typically based on econometric model forecasts jointly with human intuition. This seemingly inevitable combination renders most of these forecasts biased and, as such, their evaluation becomes nonstandard. In this review, we consider the evaluation of two forecasts in which: (i) the two forecasts are generated from two distinct econometric models; (ii) one forecast is generated from an econometric model and the other is obtained as a combination of a model and intuition; and (iii) the two forecasts are generated from two distinct (but unknown) combinations of different models and intuition. It is shown that alternative tools are needed to compare and evaluate the forecasts in each of these three situations. These alternative techniques are illustrated by comparing the forecasts from the (econometric) Staff of the Federal Reserve Board and the FOMC on inflation, unemployment, and real GDP growth. It is shown that the FOMC does not forecast significantly better than the Staff, and that the intuition of the FOMC does not add significantly in forecasting the actual values of the economic fundamentals. This would seem to belie the purported expertise of the FOMC.'] ['The three most popular univariate conditional volatility models are the generalized autoregressive conditional heteroskedasticity (GARCH) model of Engle (1982) and Bollerslev (1986), the GJR (or threshold GARCH) model of Glosten, Jagannathan and Runkle (1992), and the exponential GARCH (or EGARCH) model of Nelson (1990, 1991). The underlying stochastic specification to obtain GARCH was demonstrated by Tsay (1987), and that of EGARCH was shown recently in McAleer and Hafner (2014). These models are important in estimating and forecasting volatility, as well as in capturing asymmetry, which is the different effects on conditional volatility of positive and negative effects of equal magnitude, and purportedly in capturing leverage, which is the negative correlation between returns shocks and subsequent shocks to volatility. As there seems to be some confusion in the literature between asymmetry and leverage, as well as which asymmetric models are purported to be able to capture leverage, the purpose of the paper is three-fold, namely, (1) to derive the GJR model from a random coefficient autoregressive process, with appropriate regularity conditions; (2) to show that leverage is not possible in the GJR and EGARCH models; and (3) to present the interpretation of the parameters of the three popular univariate conditional volatility models in a unified manner.'] ['One of the most popular univariate asymmetric conditional volatility models is the exponential GARCH (or EGARCH) specification. In addition to asymmetry, which captures the different effects on conditional volatility of positive and negative effects of equal magnitude, EGARCH can also accommodate leverage, which is the negative correlation between returns shocks and subsequent shocks to volatility. However, the statistical properties of the (quasi-) maximum likelihood estimator of the EGARCH parameters are not available under general conditions, but rather only for special cases under highly restrictive and unverifiable conditions. It is often argued heuristically that the reason for the lack of general statistical properties arises from the presence in the model of an absolute value of a function of the parameters, which does not permit analytical derivatives, and hence does not permit (quasi-) maximum likelihood estimation. It is shown in this paper for the non-leverage case that: (1) the EGARCH model can be derived from a random coefficient complex nonlinear moving average (RCCNMA) process; and (2) the reason for the lack of statistical properties of the estimators of EGARCH under general conditions is that the stationarity and invertibility conditions for the RCCNMA process are not known.'] ['In this paper, we document that realized variation measures constructed from high-frequency returns reveal a large degree of volatility risk in stock and index returns, where we characterize volatility risk by the extent to which forecasting errors in realized volatility are substantive. Even though returns standardized by ex post quadratic variation measures are nearly Gaussian, this unpredictability brings considerably more uncertainty to the empirically relevant ex ante distribution of returns. Explicitly modeling this volatility risk is fundamental. We propose a dually asymmetric realized volatility model, which incorporates the fact that realized volatility series are systematically more volatile in high volatility periods. Returns in this framework display time varying volatility, skewness and kurtosis. We provide a detailed account of the empirical advantages of the model using data on the S&amp;P; 500 index and eight other indexes and stocks.'] ['The paper analyses academic journal quality and impact using quality weighted citations that are based on the widely-used Thomson Reuters ISI Web of Science citations database (ISI). A recently developed Index of Citations Quality (ICQ), based on quality weighted citations, is used to analyse the top 276 Economics and top 10 Econometrics journals in the ISI Economics category using alternative quantifiable Research Assessment Measures (RAMs). It is shown that ICQ is a useful additional measure to the 2-Year Impact Factor (2YIF) and other well known RAMs available in ISI for the purpose of evaluating journal impact and quality, as well as ranking, of Economics and Econometrics journals as it contains information that has very low correlations with the information contained in alternative well-known RAMs. Among other findings, the top Econometrics journals have some of the highest ICQ scores in the ISI category of Economics.'] ['Hausman (1978) developed a widely-used model specification test that has passed the test of time. In this paper, we show that the asymptotic variance of the difference of the two estimators can be a singular matrix. Three illustrative examples are used, namely an exogeneity test for the linear regression model, a test for the Box\xe2\x80\x93Cox transformation, and a test for sample selection bias.'] ['This paper investigates the stock returns and volatility size effects for firm performance in the Taiwan tourism industry, especially the impacts arising from the tourism policy reform that allowed mainland Chinese tourists to travel to Taiwan. Four conditional univariate GARCH models are used to estimate the volatility in the stock indexes for large and small firms in Taiwan. Daily data from 30 November 2001 to 27 February 2013 are used, which covers the period of Cross-Straits tension between China and Taiwan. The full sample period is divided into two subsamples, namely prior to and after the policy reform that encouraged Chinese tourists to Taiwan. The empirical findings confirm that there have been important changes in the volatility size effects for firm performance, regardless of firm size and estimation period. Furthermore, the risk premium reveals insignificant estimates in both time periods, while asymmetric effects are found to exist only for large firms after the policy reform. The empirical findings should be useful for financial managers and policy analysts as it provides insight into the magnitude of the volatility size effects for firm performance, how it can vary with firm size, the impacts arising from the industry policy reform, and how firm size is related to financial risk management strategy.'] ['No abstract is available for this item.'] ['The paper is concerned with ranking academic journal quality and research impact in Finance, based on the widely-used Thomson Reuters ISI (2013) Web of Science citations database (hereafter ISI). The paper analyses the 89 leading international journals in the ISI category of "Business\xe2\x80\x93Finance" using quantifiable Research Assessment Measures (RAMs). The analysis highlights the similarities and differences in various RAMs, all of which are based on alternative transformations of journal citations and impact. Alternative RAMs may be calculated annually or updated daily to determine the citations frequency of published papers that are cited in journals listed in ISI. The RAMs include the classic 2-year impact factor including journal self citations (2YIF), 2-year impact factor excluding journal self citations (2YIF*), 5-year impact factor including journal self citations (5YIF), Immediacy including journal self citations, Eigenfactor (or Journal Influence), Article Influence (AI), h-index, Papers Ignored-By Even The Authors (PI-BETA), Self-citation Threshold Approval Rating (STAR), 5YD2 (namely, 5YIF divided by 2YIF), Escalating Self Citations (ESC) and Index of Citation Quality (ICQ). The paper calculates the harmonic mean (HM) of the ranks of up to 16 RAMs. It is shown that emphasizing 2YIF to the exclusion of other informative RAMs can lead to a misleading evaluation of journal quality and impact relative to the HM of the ranks. The analysis of the 89 ISI journals in Finance makes it clear that there are three leading journals in Finance, namely Journal of Finance, Journal of Financial Economics and Review of Financial Studies, which form an exclusive club in terms of the RAMs that measure journal quality and impact based on alternative measures of journal citations. The next two journals in Finance in terms of overall quality and impact are Journal of Accounting and Economics and Journal of Monetary Economics. As Accounting does not have a separate classification in ISI, the tables of rankings given in the paper are also used to rank the top 3 journals in the sub-category of Accounting in the ISI category of "Business \xe2\x80\x93 Finance", namely Journal of Accounting and Economics, Accounting Review, and Journal of Accounting Research.'] ['The Journal of Risk and Financial Management was first published in 2008, and, since its inception, has published a number of theoretical and empirical papers on various topics in risk and financial management, in pursuit of its stated goal of advancing knowledge and understanding in the practice of risk and financial management through the publication of high quality papers that are relevant to practitioners in the field.[...]'] ['The Thomson Reuters ISI Web of Science citations database (hereafter ISI) category of Economics has one of the largest numbers of journals, at 304 (as of 2011) and 333 (as of 2013), of any ISI discipline, and hence has wide coverage. The paper analyses the leading international journals in the Economics sub-disciplines of Agricultural, Energy, Environmental and Resource Economics using quantifiable Research Assessment Measures (RAMs), and highlights the similarities and differences in alternative RAMs. The RAMs are based on alternative transformations of citations and influence taken from the ISI database. Alternative RAMs may be calculated annually or updated daily to answer the perennial questions as to When, Where and How (frequently) published papers are cited. The RAMs include the most widely used RAM, namely the classic 2-year impact factor including journal self citations (2YIF), 2-year impact factor excluding journal self citations (2YIF*), 5-year impact factor including journal self citations (5YIF), Immediacy (or zeroyear impact factor (0YIF)), Eigenfactor, Article Influence, C3PO (Citation Performance Per Paper Online), h-index, PIBETA (Papers Ignored - By Even The Authors), 2-year Self-citation Threshold Approval Ratings (2Y-STAR), Historical Self-citation Threshold Approval Ratings (H-STAR), Impact Factor Inflation (IFI), and Cited Article Influence (CAI). As data are not available for 5YIF, Article Influence and CAI for one of the 20 journals considered, 13 RAMs are analysed for 19 highly-cited journals in Agricultural, Energy, Environmental and Resource Economics in the ISI category of Economics. The harmonic mean of the ranks of the 13 RAMs for the 19 highly-cited journals are also presented. It is shown that emphasizing the 2-year impact factor of a journal, which partly answers the question as to When published papers are cited, to the exclusion of other informative RAMs, which answer Where and How (frequently) published papers are cited, can lead to a distorted evaluation of journal impact and influence relative to the harmonic mean of the ranks. The \xe2\x80\x9cage\xe2\x80\x9d effect of journals, that is, the number of years for which the journals have been included in ISI, on the RAMs is also examined to check whether the RAMs are being compared fairly.'] ['No abstract received.'] ['Several Multivariate GARCH (MGARCH) models have been proposed, and recently such MGARCH specifications have been examined in terms of their out-of-sample forecasting performance. An empirical comparison of alternative MGARCH models is provided, which focuses on the BEKK, DCC, Corrected DCC (cDCC), CCC, OGARCH models, Exponentially Weighted Moving Average, and covariance shrinking, all fitted to historical data for 89 US equities. Notably, a wide range of models, including the recent cDCC model and the covariance shrinking method, are used. Several tests and approaches for direct and indirect model comparison, including the Model Confidence Set, are considered. Furthermore, the robustness of model rankings to the cross-sectional dimension of the problem is analyzed.'] ['The purpose of the paper is to discuss ten things potential users should know about the limits of the Dynamic Conditional Correlation (DCC) representation for estimating and forecasting time-varying conditional correlations. The reasons given for caution about the use of DCC include the following: DCC represents the dynamic conditional covariances of the standardized residuals, and hence does not yield dynamic conditional correlations; DCC is stated rather than derived; DCC has no moments; DCC does not have testable regularity conditions; DCC yields inconsistent two step estimators; DCC has no asymptotic properties; DCC is not a special case of Generalized Autoregressive Conditional Correlation (GARCC), which has testable regularity conditions and standard asymptotic properties; DCC is not dynamic empirically as the effect of news is typically extremely small; DCC cannot be distinguished empirically from diagonal Baba, Engle, Kraft and Kroner (BEKK) in small systems; and DCC may be a useful filter or a diagnostic check, but it is not a model.'] ['Research papers in empirical finance and financial econometrics are among the most widely cited, downloaded and viewed articles in the discipline of Finance. The special issue presents several papers by leading scholars in the field on \xe2\x80\x9cRecent Developments in Financial Economics and Econometrics\xe2\x80\x9d. The breadth of coverage is substantial, and includes original research and comprehensive review papers on theoretical, empirical and numerical topics in Financial Economics and Econometrics by leading researchers in finance, financial economics, financial econometrics and financial statistics. The purpose of this special issue on \xe2\x80\x9cRecent Developments in Financial Economics and Econometrics\xe2\x80\x9d is to highlight several novel and significant developments in financial economics and financial econometrics, specifically dynamic price integration in the global gold market, a conditional single index model with local covariates for detecting and evaluating active management, whether the Basel Accord has improved risk management during the global financial crisis, the role of banking regulation in an economy under credit risk and liquidity shock, separating information maximum likelihood estimation of the integrated volatility and covariance with micro-market noise, stress testing correlation matrices for risk management, whether bank relationship matters for corporate risk taking, with evidence from listed firms in Taiwan, pricing options on stocks denominated in different currencies, with theory and illustrations, EVT and tail-risk modelling, with evidence from market indices and volatility series, the economics of data using simple model free volatility in a high frequency world, arbitrage-free implied volatility surfaces for options on single stock futures, the non-uniform pricing effect of employee stock options using quantile regression, nonlinear dynamics and recurrence plots for detecting financial crisis, how news sentiment impacts asset volatility, with evidence from long memory and regime-switching approaches, quantitative evaluation of contingent capital and its applications, high quantiles estimation with Quasi-PORT and DPOT, with an application to value-at-risk for financial variables, evaluating inflation targeting based on the distribution of inflation and inflation volatility, the size effects of volatility spillovers for firm performance and exchange rates in tourism, forecasting volatility with the realized range in the presence of noise and non-trading, using CARRX models to study factors affecting the volatilities of Asian equity markets, deciphering the Libor and Euribor spreads during the subprime crisis, information transmission between sovereign debt CDS and other financial factors for Latin America, time-varying mixture GARCH models and asymmetric volatility, and diagnostic checking for non-stationary ARMA models with an application to financial data.'] ['Financial economics and econometrics have advanced rapidly in recent years, in terms of coverage of topics, the creation of new data sources, the availability of existing high frequency and ultra-high frequency tick data, the growing importance of international financial analysis, the technicality of research topics, and the number of papers and journals publishing such theoretical and practical research. [...]'] ['Experts possess knowledge and information that are not publicly available. The paper is concerned with forecasting academic journal quality and research impact using a survey of international experts from a national project on ranking academic finance journals in Taiwan. A comparison is made with publicly available bibliometric data, namely the Thomson Reuters ISI Web of Science citations database (hereafter ISI) for the Business\xe2\x80\x93Finance (hereafter Finance) category. The paper analyses the leading international journals in Finance using expert scores and quantifiable Research Assessment Measures (RAMs), and highlights the similarities and differences in the expert scores and alternative RAMs, where the RAMs are based on alternative transformations of citations taken from the ISI database. Alternative RAMs may be calculated annually or updated daily to answer the perennial questions as to When, Where and How (frequently) published papers are cited (see Chang et al., 2011a,b,c). The RAMs include the most widely used RAM, namely the classic 2-year impact factor including journal self citations (2YIF), 2-year impact factor excluding journal self citations (2YIF*), 5-year impact factor including journal self citations (5YIF), Immediacy (or zero-year impact factor (0YIF)), Eigenfactor, Article Influence, C3PO (Citation Performance per Paper Online), h-index, PI-BETA (Papers Ignored \xe2\x80\x94 By even the Authors), 2-year Self-citation Threshold Approval Ratings (2Y-STAR), Historical Self-citation Threshold Approval Ratings (H-STAR), Impact Factor Inflation (IFI), and Cited Article Influence (CAI). As data are not available for 5YIF, Article Influence and CAI for 13 of the leading 34 journals considered, 10 RAMs are analysed for 21 highly-cited journals in Finance. The harmonic mean of the ranks of the 10 RAMs for the 34 highly-cited journals are also presented. It is shown that emphasizing the 2-year impact factor of a journal, which partly answers the question as to When published papers are cited, to the exclusion of other informative RAMs, which answer Where and How (frequently) published papers are cited, can lead to a distorted evaluation of journal impact and influence relative to the Harmonic Mean rankings. A linear regression model is used to forecast expert scores on the basis of RAMs that capture journal impact, journal policy, the number of high quality papers, and quantitative information about a journal. The robustness of the rankings is also analyzed.'] ['This paper features an analysis of the relationship between the S&amp;P; 500 Index and the VIX using daily data obtained from the CBOE website and SIRCA (The Securities Industry Research Centre of the Asia Pacific). We explore the relationship between the S&amp;P; 500 daily return series and a similar series for the VIX in terms of a long sample drawn from the CBOE from 1990 to mid 2011 and a set of returns from SIRCA\xe2\x80\x99s TRTH datasets from March 2005 to-date. This shorter sample, which captures the behavior of the new VIX, introduced in 2003, is divided into four sub-samples which permit the exploration of the impact of the Global Financial Crisis. We apply a series of non-parametric based tests utilizing entropy based metrics. These suggest that the PDFs and CDFs of these two return distributions change shape in various subsample periods. The entropy and MI statistics suggest that the degree of uncertainty attached to these distributions changes through time and using the S&amp;P; 500 return as the dependent variable, that the amount of information obtained from the VIX changes with time and reaches a relative maximum in the most recent period from 2011 to 2012. The entropy based non-parametric tests of the equivalence of the two distributions and their symmetry all strongly reject their respective nulls. The results suggest that parametric techniques do not adequately capture the complexities displayed in the behavior of these series. This has practical implications for hedging utilizing derivatives written on the VIX.'] ['No abstract received.'] ['A risk management strategy that is designed to be robust to the Global Financial Crisis (GFC), in the sense of selecting a Value-at-Risk (VaR) forecast that combines the forecasts of different VaR models, was proposed in McAleer et al. (2010c). The robust forecast is based on the median of the point VaR forecasts of a set of conditional volatility models. Such a risk management strategy is robust to the GFC in the sense that, while maintaining the same risk management strategy before, during and after a financial crisis, it will lead to comparatively low daily capital charges and violation penalties for the entire period. This paper presents evidence to support the claim that the median point forecast of VaR is generally GFC-robust. We investigate the performance of a variety of single and combined VaR forecasts in terms of daily capital requirements and violation penalties under the Basel II Accord, as well as other criteria. In the empirical analysis, we choose several major indexes, namely French CAC, German DAX, US Dow Jones, UK FTSE100, Hong Kong Hang Seng, Spanish Ibex35, Japanese Nikkei, Swiss SMI and US S&amp;P500.; The GARCH, EGARCH, GJR and Riskmetrics models, as well as several other strategies, are used in the comparison. Backtesting is performed on each of these indexes using the Basel II Accord regulations for 2008-10 to examine the performance of the Median strategy in terms of the number of violations and daily capital charges, among other criteria. The Median is shown to be a profitable and safe strategy for risk management, both in calm and turbulent periods, as it provides a reasonable number of violations and daily capital charges. The Median also performs well when both total losses and the asymmetric linear tick loss function are considered<p>(This abstract was borrowed from another version of this item.)'] ['This paper examines the size effects of volatility spillovers for firm performance and exchange rates with asymmetry in the Taiwan tourism industry. The analysis is based on two conditional multivariate models, BEKK\xe2\x80\x93AGARCH and VARMA\xe2\x80\x93AGARCH, in the volatility specification. Daily data from 1 July 2008 to 29 June 2012 for 999 firms are used, which covers the Global Financial Crisis. The empirical findings indicate that there are size effects on volatility spillovers from the exchange rate to firm performance. Specifically, the risk for firm size has different effects from the three leading tourism sources to Taiwan, namely USA, Japan, and China. Furthermore, all the return series reveal quite high volatility spillovers (at over 60%) with a one-period lag. The empirical results show a negative correlation between exchange rate returns and stock returns. However, the asymmetric effect of the shock is ambiguous, owing to conflicts in the significance and signs of the asymmetry effect in the two estimated multivariate GARCH models. The empirical findings provide financial managers with a better understanding of how firm size is related to financial performance, risk and portfolio management strategies that can be used in practice.'] [' This paper examines, within the context of globalization, the impact of the main channels of international trade on domestic innovation, namely outward direct investment (ODI), inward direct investment (IDI), cross-border mergers and acquisitions (M&amp;A;) by foreigners, R&amp;D; expenditure, exports, and imports. The number of approved Triadic patents serves as a proxy for innovation. The data set contains 37 countries that are considered to be highly competitive in world markets, covering the period 1994--2005. The empirical results show that increased exports and ODI are able to stimulate an increase in approved patents. In contrast, IDI exhibits a negative correlation with domestic patents. Imports are shown not to have a significant impact on international technology spillovers. The paper shows that the impact of IDI on domestic innovation is characterized by two forces, namely the cross-border M&amp;A; by foreigners and remaining IDI, both of which are found to be negative.'] ['In this paper, we develop a modified maximum likelihood (MML) estimator for the multiple linear regression model with underlying student t distribution. We obtain the closed form of the estimators, derive the asymptotic properties, and demonstrate that the MML estimator is more appropriate for estimating the parameters of the Capital Asset Pricing Model (CAPM) by comparing its performance with least squares estimators (LSE) on the monthly returns of US portfolios. The empirical results reveal that the MML estimators are more efficient than LSE in terms of the relative efficiency of one-step-ahead forecast mean square error in small samples.'] ['It is common practice to evaluate fixed-event forecast revisions in macroeconomics by regressing current forecast revisions on one-period lagged forecast revisions. Under weak-form (forecast) efficiency, the correlation between the current and one-period lagged revisions should be zero. The empirical findings in the literature suggest that this null hypothesis of zero correlation is rejected frequently, and the correlation can be either positive (which is widely interpreted in the literature as \xe2\x80\x9csmoothing\xe2\x80\x9d) or negative (which is widely interpreted as \xe2\x80\x9cover-reacting\xe2\x80\x9d). We propose a methodology for interpreting such non-zero correlations in a straightforward and clear manner. Our approach is based on the assumption that numerical forecasts can be decomposed into both an econometric model and random expert intuition. We show that the interpretation of the sign of the correlation between the current and one-period lagged revisions depends on the process governing intuition, and the current and lagged correlations between intuition and news (or shocks to the numerical forecasts). It follows that the estimated non-zero correlation cannot be given a direct interpretation in terms of either smoothing or over-reaction.'] ["The Basel II Accord requires that banks and other Authorized Deposit-taking Institutions (ADIs) communicate their daily risk forecasts to the appropriate monetary authorities at the beginning of each trading day, using one or more risk models to measure Value-at-Risk (VaR). The risk estimates of these models are used to determine capital requirements and associated capital costs of ADIs, depending in part on the number of previous violations, whereby realised losses exceed the estimated VaR. In this paper we define risk management in terms of choosing from a variety of risk models, and discuss the selection of optimal risk models. A new approach to model selection for predicting VaR is proposed, consisting of combining alternative risk models, and we compare conservative and aggressive strategies for choosing between VaR models. We then examine how different risk management strategies performed during the 2008\xe2\x80\x9309 global financial crisis. These issues are illustrated using Standard and Poor's 500 Composite Index."] ['Economists and financial analysts have begun to recognise the importance of the actions of other agents in the decision-making process. Herding is the deliberate mimicking of the decisions of other agents. Examples of mimicry range from the choice of restaurant, fashion and financial market participants, to academic research. Herding may conjure negative images of irrational agents sheepishly following the actions of others, but such actions can be rational under asymmetric information and uncertainty. This paper uses futures position data in nine different markets of the Commodity Futures Trading Commission (CFTC) to provide a direct test of herding behaviour, namely the extent to which small traders mimic the positions of large speculators. Evidence consistent with herding among small traders is found for the Canadian dollar, British pound, gold, S&amp;P; 500 and Nikkei 225 futures. Consistent with survey-based results on technical analysis, the positions are significantly correlated with both current and past market returns. Using various time-varying volatility models to accommodate conditional heteroskedasticity, the empirical results are found to be robust to alternative models and methods of estimation. When a test of causality-in-variance is used to analyse if volatility among small traders spills over into spot markets, it is found that spillovers occur only with Nikkei 225 futures. The policy implications of the findings are also discussed'] ['As the preponderance of journal rankings becomes increasingly more frequent and prominent in academic decision making, such rankings in broad discipline categories is taking on an increasingly important role. The paper focuses on the robustness of rankings of academic journal quality and research impact using on the widely-used Thomson Reuters ISI Web of Science citations database (ISI) for the Statistics &amp; Probability category. The paper analyses 110 ISI international journals in Statistics &amp; Probability using quantifiable Research Assessment Measures (RAMs), and highlights the similarities and differences in various RAMs, which are based on alternative transformations of citations and influence. Alternative RAMs may be calculated annually or updated daily to determine When, Where and How (frequently) published papers are cited (see Chang et al. (2011a, b, c), Chang et al. (2012)). The RAMs are grouped in four distinct classes that include impact factor, mean citations and non-citations, journal policy, number of high quality papers, and journal influence and article influence. These classes include the most widely used RAMs, namely the classic 2-year impact factor including journal self citations (2YIF), 2-year impact factor excluding journal self citations (2YIF*), 5-year impact factor including journal self citations (5YIF), Eigenfactor (or Journal Influence), Article Influence, h-index, PI-BETA (Papers Ignored - By Even The Authors), 5YD2 (= 5YIF/2YIF) as a measure of citations longevity, and Escalating Self Citations (ESC) as a measure of increasing journal self citations. The paper highlights robust rankings based on the harmonic mean of the ranks of RAMs across the 4 classes. It is shown that focusing solely on the 2-year impact factor (2YIF) of a journal, which partly answers the question as to When published papers are cited, to the exclusion of other informative RAMs, which answer Where and How (frequently) published papers are cited, can lead to a distor<p>(This abstract was borrowed from another version of this item.)'] ['This paper investigates the conditional correlations and volatility spillovers between the crude oil and financial markets, based on crude oil returns and stock index returns. Daily returns from 2 January 1998 to 4 November 2009 of the crude oil spot, forward and futures prices from the WTI and Brent markets, and the FTSE100, NYSE, Dow Jones and S&amp;P500; stock index returns, are analysed using the CCC model of Bollerslev (1990), VARMA-GARCH model of Ling and McAleer (2003), VARMA-AGARCH model of McAleer, Hoti, and Chan (2008), and DCC model of Engle (2002). Based on the CCC model, the estimates of conditional correlations for returns across markets are very low, and some are not statistically significant, which means the conditional shocks are correlated only in the same market and not across markets. However, the DCC estimates of the conditional correlations are always significant. This result makes it clear that the assumption of constant conditional correlations is not supported empirically. Surprisingly, the empirical results from the VARMA-GARCH and VARMA-AGARCH models provide little evidence of volatility spillovers between the crude oil and financial markets. The evidence of asymmetric effects of negative and positive shocks of equal magnitude on the conditional variances suggests that VARMA-AGARCH is superior to VARMA-GARCH and CCC.'] ['This paper examines risk transmission and migration among six US measures of credit and market risk during the full period 2004\xe2\x80\x932011 period and the 2009\xe2\x80\x932011 recovery subperiod, with a focus on four sectors related to the highly volatile oil price. There are more long-run equilibrium risk relationships and short-run causal relationships among the four oil-related Credit Default Swaps (CDS) indexes, the (expected equity volatility) VIX index and the (swaption expected volatility) SMOVE index for the full period than for the recovery subperiod. The auto sector CDS spread is the most error-correcting in the long run and also leads in the risk discovery process in the short run. On the other hand, the CDS spread of the highly regulated, natural monopoly utility sector does not error correct. The four oil-related CDS spread indexes are responsive to VIX in the short- and long-run, while no index is sensitive to SMOVE which, in turn, unilaterally assembles risk migration from VIX. The 2007\xe2\x80\x932008 Great Recession seems to have led to \xe2\x80\x9clocalization\xe2\x80\x9d and less migration of credit and market risk in the oil-related sectors.'] ['The paper focuses on the robustness of rankings of academic journal quality and research impact of 10 leading econometrics journals taken from the Thomson Reuters ISI Web of Science (ISI) Category of Economics, using citations data from ISI and the highly accessible Research Papers in Economics (RePEc) database that is widely used in economics, finance and related disciplines. The journals are ranked using quantifiable static and dynamic Research Assessment Measures (RAMs), with 15 RAMs from ISI and five RAMs from RePEc. The similarities and differences in various RAMs, which are based on alternative weighted and unweighted transformations of citations, are highlighted to show which RAMs are able to provide informational value relative to others. The RAMs include the impact factor, mean citations and non-citations, journal policy, number of high quality papers, and journal influence and article influence. The paper highlights robust rankings based on the harmonic mean of the ranks of 20 RAMs, which in some cases are closely related. It is shown that emphasizing the most widely-used RAM, the two-year impact factor of a journal, can lead to a distorted evaluation of journal quality, impact and influence relative to the harmonic mean of the ranks. Some suggestions regarding the use of the most informative RAMs are also given.'] ['In this paper we provide further evidence on the suitability of the median of the point VaR forecasts of a set of models as a GFC-robust strategy by using an additional set of new extreme value forecasting models and by extending the sample period for comparison. The median is not affected by extremes, unlike the mean. In periods of contagion, wherein the number and values of extremes are substantially greater, the use of the median would be expected to be even more robust than the mean. These extreme value models include DPOT and Conditional EVT. Such models might be expected to be useful in explaining financial data, especially in the presence of extreme shocks that arise during a GFC. Our empirical results confirm that the median remains GFC-robust even in the presence of these new extreme value models. This is illustrated by using the S&amp;P500; index before, during and after the 2008\xe2\x80\x932009 GFC. We investigate the performance of a variety of single and combined VaR forecasts in terms of daily capital requirements and violation penalties under the Basel II Accord, as well as other criteria, including several tests for independence of the violations. The strategy based on the median, or more generally, on combined forecasts of single models, is straightforward to incorporate into existing computer software packages that are used by banks and other financial institutions.'] ['This paper features the application of a novel and recently developed method of statistical and mathe- matical analysis to the assessment of financial risk: namely Regular Vine copulas. Dependence modelling using copulas is a popular tool in financial applications, but is usually applied to pairs of securities. Vine copulas offer greater flexibility and permit the modelling of complex dependency patterns using the rich variety of bivariate copulas which can be arranged and analysed in a tree structure to facilitate the anal- ysis of multiple dependencies. We apply Regular Vine copula analysis to a sample of stocks comprising the Dow Jones Index to assess their interdependencies and to assess how their correlations change in different economic circumstances using three different sample periods: pre-GFC (Jan 2005- July 2007), GFC (July 2007-Sep 2009), and post-GFC periods (Sep 2009 - Dec 2011). The empirical results suggest that the dependencies change in a complex manner, and there is evidence of greater reliance on the Student t copula in the copula choice within the tree structures for the GFC period, which is consistent with the existence of larger tails in the distributions of returns for this period. One of the attractions of this approach to risk modelling is the flexibility in the choice of distributions used to model co-dependencies.<p>(This abstract was borrowed from another version of this item.)'] ['It is well known that the Basel II Accord requires banks and other Authorized Deposit-taking Institutions (ADIs) to communicate their daily risk forecasts to the appropriate monetary authorities at the beginning of each trading day, using one or more risk models, whether individually or as combinations, to measure Value-at-Risk (VaR). The risk estimates of these models are used to determine capital requirements and associated capital costs of ADIs, depending in part on the number of previous violations, whereby realised losses exceed the estimated VaR. Previous papers proposed a new approach to model selection for predicting VaR, consisting of combining alternative risk models, and comparing conservative and aggressive strategies for choosing between VaR models. This paper, using Bayesian and non-Bayesian combinations of models addresses the question of risk management of risk, namely VaR of VIX futures prices, and extends the approaches given in previous papers to examine how different risk management strategies performed during the 2008\xe2\x80\x932009 global financial crisis (GFC). The use of time-varying weights using Bayesian methods, allows dynamic combinations of the different models to obtain a more accurate VaR forecasts than the estimates and forecasts that might be produced by a single model of risk. One of these dynamic combinations is endogenously determined by the pass performance in terms of daily capital charges of the individual models. This can improve the strategies to minimize daily capital charges, which is a central objective of ADIs. The empirical results suggest that an aggressive strategy of choosing the Supremum of single model forecasts, as compared with Bayesian and non-Bayesian combinations of models, is preferred to other alternatives, and is robust during the GFC.'] ['Many macroeconomic forecasts and forecast updates like those from IMF and OECD typically involve both a model component, which is replicable, as well as intuition, which is non-replicable. Intuition is expert knowledge possessed by a forecaster. If forecast updates are progressive, forecast updates should become more accurate, on average, as the actual value is approached. Otherwise, forecast updates would be neutral. The paper proposes a methodology to test whether macroeconomic forecast updates are progressive, where the interaction between model and intuition is explicitly taken into account. The data set for the empirical analysis is for Taiwan, where we have three decades of quarterly data available of forecasts and their updates of the inflation rate and real GDP growth rate. Our empirical results suggest that the forecast updates for Taiwan are progressive, and that progress can be explained predominantly by improved intuition.'] ['A risk management strategy is proposed as being robust to the Global Financial Crisis (GFC) by selecting a Value-at-Risk (VaR) forecast that combines the forecasts of different VaR models. The robust forecast is based on the median of the point VaR forecasts of a set of conditional volatility models. This risk management strategy is GFC-robust in the sense that maintaining the same risk management strategies before, during and after a financial crisis would lead to comparatively low daily capital charges and violation penalties. The new method is illustrated by using the S&amp;P500; index before, during and after the 2008\xe2\x80\x9309 global financial crisis. We investigate the performance of a variety of single and combined VaR forecasts in terms of daily capital requirements and violation penalties under the Basel II Accord, as well as other criteria. The median VaR risk management strategy is GFC-robust as it provides stable results across different periods relative to other VaR forecasting models. The new strategy based on combined forecasts of single models is straightforward to incorporate into existing computer software packages that are used by banks and other financial institutions.'] ['Modelling, monitoring and forecasting volatility are indispensible to sensible portfolio risk management. The volatility of an asset of composite index can be traded by using volatility derivatives, such as volatility and variance swaps, options and futures. The most popular volatility index is VIX, which is a key measure of market expectations of volatility, and hence also an important barometer of investor sentiment and market volatility. Investors interpret the VIX cash index as a \xe2\x80\x9cfear\xe2\x80\x9d index, and of VIX options and VIX futures as derivatives of the \xe2\x80\x9cfear\xe2\x80\x9d index. VIX is based on S&amp;P500; call and put options over a wide range of strike prices, and hence is not model based. Speculators can trade on volatility risk with VIX derivatives, with views on whether volatility will increase or decrease in the future, while hedgers can use volatility derivatives to avoid exposure to volatility risk. VIX and its options and futures derivatives has been widely analysed in recent years. An alternative volatility derivative to VIX is the S&amp;P500; variance futures, which is an expectation of the variance of the S&amp;P500; cash index. Variance futures are futures contracts written on realized variance, or standardized variance swaps. The S&amp;P500; variance futures are not model based, so the assumptions underlying the index do not seem to have been clearly understood. As variance futures are typically thinly traded, their returns and volatility are not easy to model accurately using a variety of volatility model specifications. This paper analyses the volatility in S&amp;P500; 3-month and 12-month variance futures Before, During and After the GFC, as well as for the full data period, for each of three alternative conditional volatility models and three densities, in order to determine whether exposure to risk can be incorporated into a financial portfolio without taking positions on the S&amp;P500; index itself.'] ['This paper examines the issue of coercive journal self citations and the practical usefulness of two recent journal performance metrics, namely the Eigenfactor score, which may be interpreted as measuring \xe2\x80\x9cJournal Influence\xe2\x80\x9d, and the Article Influence score, using the Thomson Reuters ISI Web of Science (hereafter ISI) data for 2009 for the 200 most highly cited journals in each of the Sciences and Social Sciences. The paper also compares the two new bibliometric measures with two existing ISI metrics, namely Total Citations and the 5-Year Impact Factor (5YIF) (including journal self citations) of a journal. It is shown that the Sciences and Social Sciences are different in terms of the strength of the relationship of journal performance metrics, although the actual relationships are very similar. Moreover, the Journal Influence and Article Influence journal performance metrics are shown to be closely related empirically to the two existing ISI metrics, and hence add little in practical usefulness to what is already known, except for eliminating the pressure arising from coercive journal self citations. These empirical results are compared with existing results in the bibliometrics literature.'] ["This paper examines whether there is evidence of spillovers of volatility from the Chinese stock market to its neighbours and trading partners, including Australia, Hong Kong, Singapore, Japan and USA. China's increasing integration into the global market may have important consequences for investors in related markets. In order to capture these potential effects, we explore these issues using an Autoregressive Moving Average (ARMA) return equation. A univariate GARCH model is then adopted to test for the persistence of volatility in stock market returns, as represented by stock market indices. Finally, univariate GARCH, multivariate VARMA\xe2\x80\x93GARCH, and multivariate VARMA\xe2\x80\x93AGARCH models are used to test for constant conditional correlations and volatility spillover effects across these markets. Each model is used to calculate the conditional volatility between both the Shenzhen and Shanghai Chinese markets and several other markets around the Pacific Basin Area, including Australia, Hong Kong, Japan, Taiwan and Singapore, during four distinct periods, beginning 27 August 1991 and ending 17 November 2010. The empirical results show some evidence of volatility spillovers across these markets in the pre-GFC periods, but there is little evidence of spillover effects from China to related markets during the GFC. We undertook some additional analysis for this period featuring an exploration of whether there was any spillover effect in the mean equations as well as in the variance equations. We used a bimean equation to model the conditional mean in the individual markets plus an ARMA model to capture volatility spillovers from China to the five markets considered. This augmented model showed much greater evidence of spillovers. We also suspected that the correlations were not constant and applied a moving window of 120 days of daily observations to explore time-varying conditional and fitted correlations. There was evidence of non-constant correlations and even a period of negative correlations between the US and China at the height of the GFC. This is presumably because the GFC was initially a US phenomenon, before spreading to developed markets around the globe and it was not a Chinese phenomenon."] ['Risk management is crucial for optimal portfolio management. One of the fastest growing areas in empirical finance is the expansion of financial derivatives. The purpose of this special issue on \xe2\x80\x9cRisk Management and Financial Derivatives\xe2\x80\x9d is to highlight some areas in which novel econometric, financial econometric and empirical finance methods have contributed significantly to the analysis of risk management, with an emphasis on financial derivatives, specifically conditional correlations and volatility spillovers between crude oil and stock index returns, pricing exotic options using the Wang transform, the rise and fall of S&amp;P500; variance futures, predicting volatility using Markov switching multifractal model: evidence from S&amp;P100; index and equity options, the performance of commodity trading advisors: a mean-variance-ratio test approach, forecasting volatility via stock return, range, trading volume and spillover effects: the case of Brazil, estimating and simulating Weibull models of risk or price durations: an application to ACD models, valuation of double trigger catastrophe options with counterparty risk, day of the week effect on the VIX \xe2\x80\x93 a parsimonious representation, equity and CDS sector indices: dynamic models and risk hedging, the probability of default in collateralized credit operations, risk premia in multi-national enterprises, solving claims replication problems in a complete market by orthogonal series expansion, downside risk management and VaR-based optimal portfolios for precious metals, oil and stocks, and implied Sharpe ratios of portfolios with options: application to Nikkei futures and listed options.'] ['Several methods have recently been proposed in the ultra-high frequency financial literature to remove the effects of microstructure noise and to obtain consistent estimates of the integrated volatility (IV) as a measure of ex post daily volatility. Even bias-corrected and consistent realized volatility (RV) estimates of IV can contain residual microstructure noise and other measurement errors. Such noise is called "realized volatility error". As such errors are ignored, we need to take account of them in estimating and forecasting IV. This paper investigates through Monte Carlo simulations the effects of RV errors on estimating and forecasting IV with RV data. It is found that: (i) neglecting RV errors can lead to serious bias in estimators; (ii) the effects of RV errors on one-step-ahead forecasts are minor when consistent estimators are used and when the number of intraday observations is large; (iii) even the partially corrected R2 recently proposed in the literature should be fully corrected for evaluating forecasts. This paper proposes a full correction of R2. An empirical example for S&amp;P; 500 data is used to demonstrate the techniques developed in this paper.'] ['This paper analyses the constant elasticity of volatility (CEV) model suggested by Chan et al. [K.C. Chan, G.A. Karolyi, F.A. Longstaff, A.B. Sanders, An empirical comparison of alternative models of the short-term interest rate, Journal of Finance 47 (1992) 1209\xe2\x80\x931227]. The CEV model without mean reversion is shown to be the inverse Box\xe2\x80\x93Cox transformation of integrated processes asymptotically. It is demonstrated that the maximum likelihood estimator of the power parameter has a nonstandard asymptotic distribution, which is expressed as an integral of Brownian motions, when the data generating process is not mean reverting. However, it is shown that the t-ratio follows a standard normal distribution asymptotically, so that the use of the conventional t-test in analyzing the power parameter of the CEV model is justified even if there is no mean reversion, as is often the case in empirical research. The model may applied to ultra high frequency data.'] ['Tourism is a major source of service receipts for many countries, including Taiwan. The two leading tourism countries for Taiwan are Japan and USA, which are sources of short and long haul tourism, respectively. As a strong domestic currency can have adverse effects on international tourist arrivals through the price effect, daily data from 1 January 1990 to 31 December 2008 are used to model the world price, exchange rates, and tourist arrivals from the world, USA and Japan to Taiwan, and their associated volatility. Inclusion of the exchange rate and its volatility captures approximate daily and weekly price and price volatility effects on world, US and Japanese tourist arrivals to Taiwan. The Heterogeneous Autoregressive (HAR) model is used to approximate the slowly decaying correlations associated with the long memory properties in daily and weekly exchange rates and international tourist arrivals, to test whether alternative short and long run estimates of conditional volatility are sensitive to the long memory in the conditional mean, to examine asymmetry and leverage in volatility, and to examine the effects of temporal and spatial aggregation. The approximate price and price volatility effects tend to be different, with the exchange rate typically having the expected negative impact on tourist arrivals to Taiwan, whereas exchange rate volatility can have positive or negative effects on tourist arrivals to Taiwan. For policy purposes, the empirical results suggest that an arbitrary choice of data frequency or spatial aggregation will not lead to robust findings as they are generally not independent of the level of aggregation used.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ["This paper examines the long- and short-run asymmetric adjustments and pairs trades for nine pairs of spot and futures prices, itemized as three own pairs for three different bio-fuel ethanol types, three own pairs for three related agricultural products, namely corn, soybeans and sugar, and three cross pairs that included hybrids of the spot price of each of the agricultural products and an ethanol futures price. Most of the spreads' asymmetric adjustments generally occur during narrowing. The three ethanol pairs that contain the eCBOT futures with each of Chicago spot, New York Harbor spot and Western European (Rotterdam) spot show different long-run adjustments, arbitrage profitable opportunities and price risk hedging capabilities. The asymmetric spread adjustments for the three grains are also different, with corn spread showing the strongest long-run widening adjustment, and sugar showing the weakest narrowing adjustment. Among others, the empirical analysis indicates the importance of potentially hedging the spot prices of agricultural commodities with ethanol futures contracts, which sends an important message that the ethanol futures market is capable of hedging price risk in agricultural commodity markets. The short-run asymmetric adjustments for individual prices in the nine pairs, with the exception of the corn own pair, underscore the importance of futures prices in the price discovery and hedging potential, particularly for ethanol futures."] ['Some novel nonlinear threshold conditional autoregressive VaR (CAViaR) models are proposed that incorporate intra-day price ranges. Model estimation is performed using a Bayesian approach via the link with the Skewed\xe2\x80\x93Laplace distribution. The performances of a range of risk models during the 2008\xe2\x80\x9309 financial crisis are examined, including an evaluation of the way in which the crisis affected the performance of VaR forecasting. An empirical analysis is conducted on five Asia-Pacific Economic Cooperation stock market indices and two exchange rate series. Standard back-testing criteria are used to measure and assess the forecast performances of a variety of risk models. The proposed threshold CAViaR model, incorporating range information, is shown to forecast VaR more effectively and more accurately than other models, across the series considered.'] ['Macroeconomic forecasts are often based on the interaction between econometric models and experts. A forecast that is based only on an econometric model is replicable and may be unbiased, whereas a forecast that is not based only on an econometric model, but also incorporates expert intuition, is non-replicable and is typically biased. In this paper we propose a methodology to analyze the qualities of individual and alternative means of non-replicable forecasts. One part of the methodology seeks to retrieve a replicable component from the non-replicable forecasts, and compares this component against the actual data. A second part modifies the estimation routine due to the assumption that the difference between a replicable and a non-replicable forecast involves measurement error. An empirical example to forecast economic fundamentals for Taiwan shows the relevance of the methodological approach using both individuals and alternative mean forecasts.'] ['The management and monitoring of very large portfolios of financial assets are routine for many individuals and organizations. The two most widely used models of conditional covariances and correlations in the class of multivariate GARCH models are BEKK and DCC. It is well known that BEKK suffers from the archetypal \xe2\x80\x9ccurse of dimensionality\xe2\x80\x9d, whereas DCC does not. It is argued in this paper that this is a misleading interpretation of the suitability of the two models for use in practice. The primary purpose of this paper is to analyze the similarities and dissimilarities between BEKK and DCC, both with and without targeting, on the basis of the structural derivation of the models, the availability of analytical forms for the sufficient conditions for existence of moments, sufficient conditions for consistency and asymptotic normality of the appropriate estimators, and computational tractability for ultra large numbers of financial assets. Based on theoretical considerations, the paper sheds light on how to discriminate between BEKK and DCC in practical applications.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['This paper analyzes two indexes in order to capture the volatility inherent in El Ni\xc3\xb1os Southern Oscillations (ENSO), develops the relationship between the strength of ENSO and greenhouse gas emissions, which increase as the economy grows, with carbon dioxide being the major greenhouse gas, and examines how these gases affect the frequency and strength of El Ni\xc3\xb1o on the global economy. The empirical results show that both the ARMA(1,1)- GARCH(1,1) and ARMA(3,2)-GJR(1,1) models are suitable for modelling ENSO volatility accurately, and that 1998 is a turning point, which indicates that the ENSO strength has increased since 1998. Moreover, the increasing ENSO strength is due to the increase in greenhouse gas emissions. The ENSO strengths for Sea Surface Temperature (SST) are predicted for the year 2030 to increase from 29.62% to 81.5% if global CO2 emissions increase by 40% to 110%, respectively. This indicates that we will be faced with even stronger El Ni\xc3\xb1o or La Ni\xc3\xb1a effects in the future if global greenhouse gas emissions continue to increase unabated'] ['This paper examines the roles of futures prices of crude oil, gasoline, ethanol, corn, soybeans and sugar in the energy\xe2\x80\x93grain nexus. It also investigates the own- and cross-market impacts for the lagged grain trading volume and the open interest in the energy and grain markets. According to the results, the conventional view, for which the impacts are from oil to gasoline to ethanol to grains in the energy\xe2\x80\x93grain nexus, does not hold well in the long run because the oil price is influenced by gasoline, soybeans and oil. Moreover, gasoline is preceded by only the oil price, and ethanol is not foreshadowed by any of the prices. However, in the short run, a two-way feedback in both directions exists in all markets. The grain trading volume effect across oil and gasoline is more pronounced in the short-run than in the long-run, satisfying both the overconfidence/disposition and the new information hypotheses across markets. The results for the ethanol open interest show that money flows out of this market in both the short- and long-run, but no results suggest across market inflows or outflows to the other grain markets.'] ['The main purpose of this paper is to evaluate the effect of crude oil price on global fertilizer prices in both the mean and volatility. The endogenous structural breakpoint unit root test, ARDL model, and alternative volatility models, including GARCH, EGARCH, and GJR models, are used to investigate the relationship between crude oil price and six global fertilizer prices. The empirical results from ARDL show that most fertilizer prices are significantly affected by the crude oil price while the volatility of global fertilizer prices and crude oil price from March to December 2008 are higher than in other periods.'] ['This paper estimates a long memory volatility model for 16 agricultural commodity futures returns from different futures markets, namely corn, oats, soybeans, soybean meal, soybean oil, wheat, live cattle, cattle feeder, pork, cocoa, coffee, cotton, orange juice, Kansas City wheat, rubber, and palm oil. The class of fractional GARCH models, namely the FIGARCH model of Baillie et al. (1996), FIEGARCH model of Bollerslev and Mikkelsen (1996), and FIAPARCH model of and FIAPARCH model of Tse (1998), are modelled and compared with the GARCH model of Bollerslev (1986), EGARCH model of Nelson (1991), and APARCH model of Ding et al. (1993). The estimated d parameters, indicating long-term dependence, suggest that fractional integration is found in most of agricultural commodity futures returns series. In addition, the FIGARCH (1, d, 1) and FIEGARCH (1, d, 1) models are found to outperform their GARCH (1, 1) and EGARCH (1, 1) counterparts.'] [' In this paper, we propose a long memory asymmetric volatility model, which captures more flexible asymmetric patterns as compared with several existing models. We extend the new specification to realized volatility (RV) by taking account of measurement errors and use the Efficient Importance Sampling technique to estimate the model. We apply the model to the RV of S&amp;P500.; Overall, the results of the out-of-sample forecasts show the adequacy of the new asymmetric and long memory volatility model for the period including the global financial crisis. Copyright The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com., Oxford University Press.'] ['The paper examines the performance of several multivariate volatility models, namely CCC, VARMA-GARCH, DCC, BEKK and diagonal BEKK, for the crude oil spot and futures returns of two major benchmark international crude oil markets, Brent and WTI, to calculate optimal portfolio weights and optimal hedge ratios, and to suggest a crude oil hedge strategy. The empirical results show that the optimal portfolio weights of all multivariate volatility models for Brent suggest holding futures in larger proportions than spot. For WTI, however, DCC, BEKK and diagonal BEKK suggest holding crude oil futures to spot, but CCC and VARMA-GARCH suggest holding crude oil spot to futures. In addition, the calculated optimal hedge ratios (OHRs) from each multivariate conditional volatility model give the time-varying hedge ratios, and recommend to short in crude oil futures with a high proportion of one dollar long in crude oil spot. Finally, the hedging effectiveness indicates that diagonal BEKK (BEKK) is the best (worst) model for OHR calculation in terms of reducing the variance of the portfolio.'] ['Purpose \xe2\x80\x93 The Basel II Accord requires that banks and other authorized deposit-taking institutions (ADIs) communicate their daily risk forecasts to the appropriate monetary authorities at the beginning of each trading day, using one or more risk models to measure value-at-risk (VaR). The risk estimates of these models are used to determine capital requirements and associated capital costs of ADIs, depending in part on the number of previous violations, whereby realized losses exceed the estimated VaR. The purpose of this paper is to address the question of risk management of risk, namely VaR of VIX futures prices. Design/methodology/approach \xe2\x80\x93 The authors examine how different risk management strategies performed before, during and after the 2008-2009 global financial crisis (GFC). Findings \xe2\x80\x93 The authors find that an aggressive strategy of choosing the supremum of the univariate model forecasts is preferred to the other alternatives, and is robust during the GFC. Originality/value \xe2\x80\x93 The paper examines how different risk management strategies performed before, during and after the 2008-2009 GFC, and finds that an aggressive strategy of choosing the supremum of the univariate model forecasts is preferred to the other alternatives, and is robust during the GFC.'] ["Purpose \xe2\x80\x93 The purpose of this paper is to propose a new method for estimating continuous-time stochastic volatility (SV) models for the S&amp;P; 500 stock index process using intraday high-frequency observations of both the S&amp;P; 500 index and the Chicago Board Options Exchange (CBOE) implied (or expected) volatility index (VIX). Design/methodology/approach \xe2\x80\x93 A primary purpose of the paper is to provide a framework for using intraday high-frequency data of both the indices' estimates, in particular, for improving the estimation accuracy of the leverage parameter, that is, the correlation between the two Brownian motions driving the diffusive components of the price process and its spot variance process, respectively. Findings \xe2\x80\x93 Finite sample simulation results show that the proposed estimator delivers more accurate estimates of the leverage parameter than do existing methods. Research limitations/implications \xe2\x80\x93 The focus of the paper is on the Heston and non-Heston leverage parameters. Practical implications \xe2\x80\x93 Finite sample simulation results show that the proposed estimator delivers more accurate estimates of the leverage parameter than do existing methods. Social implications \xe2\x80\x93 The research findings are important for the analysis of ultra high-frequency financial data. Originality/value \xe2\x80\x93 The paper provides a framework for using intraday high-frequency data of both indices' estimates, in particular, for improving the estimation accuracy of the leverage parameter, that is, the correlation between the two Brownian motions driving the diffusive components of the price process and its spot variance process, respectively."] ["Asia is presently the most important market for the production and consumption of natural rubber. World prices of rubber are subject to not only to changes in demand, but also speculation regarding future markets. Japan and Singapore are the major future markets for rubber, while Thailand is one of the world's largest producers of rubber. As rubber prices are influenced by external markets, it is important to analyse the relationship between the relevant markets in Thailand, Japan and Singapore. The analysis is conducted using several alternative multivariate GARCH models. The empirical results indicate that the constant conditional correlations arising from the CCC model lie in the low to medium range. The results from the VARMA-GARCH model and the VARMA-AGARCH model suggest the presence of volatility spillovers and asymmetric effects of positive and negative return shocks on conditional volatility. Finally, the DCC model suggests that the conditional correlations can vary dramatically over time. In general, the dynamic conditional correlations in rubber spot and futures returns shocks can be independent or interdependent."] ['In this paper we use a structural VAR model with block exogeneity to investigate if external shocks originating from the USA played a dominant role in influencing the macroeconomic fluctuations in East Asia during the period 1978\xe2\x80\x932007. The empirical results show a dynamic effect of external shocks, implying that, even though regional integration appears to be deepening and accelerating, especially after the recent global financial crisis, the influence of US shocks on real output fluctuations in the East Asian region is still very strong. The effects of Chinese shocks show an increasing trend over time, but the impacts are still small and not comparable with those of US shocks. The world oil price shock has become increasingly important in influencing the stability of real output growth in the region. The results from variance decomposition and impulse response analysis confirm the findings. Even though Japanese firms have established production networks in East Asia through trade and investment, and China has also grown rapidly and become a key regional country, the results suggest that US influence in the region is still asymmetric and strong. Therefore, it is difficult to conclude that shocks to the East Asian economies have become more regionally oriented.'] [' The stochastic volatility model usually incorporates asymmetric effects by introducing the negative correlation between the innovations in returns and volatility. In this paper, we propose a new asymmetric stochastic volatility model, based on the leverage and size effects. The model is a generalization of the exponential GARCH (EGARCH) model of Nelson (1991). We consider categories for asymmetric effects, which describes the difference among the asymmetric effect of the EGARCH model, the threshold effects indicator function of Glosten et al. (1992), and the negative correlation between the innovations in returns and volatility. The new model is estimated by the efficient importance sampling method of Liesenfeld and Richard (2003), and the finite sample properties of the estimator are investigated using numerical simulations. Four financial time series are used to estimate the alternative asymmetric stochastic volatility (SV) models, with empirical asymmetric effects found to be statistically significant in each case. The empirical results for S&amp;P; 500 and Yen/USD returns indicate that the leverage and size effects are significant, supporting the general model. For Tokyo stock price index (TOPIX) and USD/AUD returns, the size effect is insignificant, favoring the negative correlation between the innovations in returns and volatility. We also consider standardized t distribution for capturing the tail behavior. The results for Yen/USD returns show that the model is correctly specified, while the results for three other data sets suggest there is scope for improvement.'] ['Prices in the hog industry in Taiwan are determined according to an auction system. There are significant differences in hog prices before, during and after joining the World Trade Organization (WTO). The paper models growth rates and volatility in daily hog prices in Taiwan from 23 March 1999 to 30 June 2007, which enables an analysis of the effects of joining the WTO. The empirical results have significant implications for risk management and policy in the agricultural industry. The three sub-samples for the periods before, during and after joining the WTO display significantly different volatility persistence of symmetry, asymmetry and leverage, respectively.'] ['This paper examines volatility and correlation dynamics in price returns of gold, silver, platinum and palladium, and explores the corresponding risk management implications for market risk and hedging. Value-at-Risk (VaR) is used to analyze the downside market risk associated with investments in precious metals, and to design optimal risk management strategies. We compute the VaR for major precious metals using the calibrated RiskMetrics, different GARCH models, and the semi-parametric Filtered Historical Simulation approach. The best approach for estimating VaR based on conditional and unconditional statistical tests is documented. The economic importance of the results is highlighted by assessing the daily capital charges from the estimated VaRs.'] ["The country risk literature argues that country risk ratings have a direct impact on the cost of borrowings as they reflect the probability of debt default by a country. An improvement in country risk ratings, or country creditworthiness, will lower a country's cost of borrowing and debt servicing obligations, and vice versa. In this context, it is useful to analyse country risk ratings data, much like financial data, in terms of the time series patterns, as such an analysis would provide policy makers and the industry stakeholders with a more accurate method of forecasting future changes in the risks and returns of country risk ratings. This paper considered an extension of the Value-at-Risk (VaR) framework where both the upper and lower thresholds are considered. The purpose of the paper was to forecast the conditional variance and Country Risk Bounds (CRBs) for the rate of change of risk ratings for 10 countries. The conditional variance of composite risk returns for the 10 countries were forecasted using the Single Index (SI) and Portfolio Methods (PM) of McAleer and da Veiga [10,11]. The results suggested that the country risk ratings of Switzerland, Japan and Australia are much mode likely to remain close to current levels than the country risk ratings of Argentina, Brazil and Mexico. This type of analysis would be useful to lenders/investors evaluating the attractiveness of lending/investing in alternative countries."] ["A government's ability to forecast key economic fundamentals accurately can affect business confidence, consumer sentiment, and foreign direct investment, among others. A government forecast based on an econometric model is replicable, whereas one that is not fully based on an econometric model is non-replicable. Governments typically provide non-replicable forecasts (or expert forecasts) of economic fundamentals, such as the inflation rate and real GDP growth rate. In this paper, we develop a methodology for evaluating non-replicable forecasts. We argue that in order to do so, one needs to retrieve from the non-replicable forecast its replicable component, and that it is the difference in accuracy between these two that matters. An empirical example to forecast economic fundamentals for Taiwan shows the relevance of the proposed methodological approach. Our main finding is that the undocumented knowledge of the Taiwanese government reduces forecast errors substantially."] ['Time series data affect many aspects of our lives. This paper highlights ten things we should all know about time series, namely: a good working knowledge of econometrics and statistics, an awareness of measurement errors, testing for zero frequency, seasonal and periodic unit roots, analysing fractionally integrated and long memory processes, estimating VARFIMA models, using and interpreting cointegrating models carefully, choosing sensibly among univariate conditional, stochastic and realized volatility models, not confusing thresholds, asymmetry and leverage, not underestimating the complexity of multivariate volatility models, and thinking carefully about forecasting models and expertise.<p>(This abstract was borrowed from another version of this item.)'] ['In this paper we consider a nonlinear model based on neural networks as well as linear models to forecast the daily volatility of the S&amp;P; 500 and FTSE 100 futures. As a proxy for daily volatility, we consider a consistent and unbiased estimator of the integrated volatility that is computed from high frequency intra-day returns. We also consider a simple algorithm based on bagging (bootstrap aggregation) in order to specify the models analyzed.<p>(This abstract was borrowed from another version of this item.)'] [' The paper analyzes the leading journals in neurosciences using quantifiable research assessment measures (RAM), highlights the similarities and differences in alternative RAM, shows that several RAM capture similar performance characteristics of highly cited journals, and shows that some other RAM have low correlations with each other, and hence add significant informational value. Alternative RAM are discussed for the Thomson Reuters ISI Web of Science database (hereafter ISI). The RAM that are calculated annually or updated daily include the classic 2-year impact factor (2YIF), 5-year impact factor, immediacy (or zero-year impact factor), Eigenfactor score, article influence score, C3PO (citation performance per paper online), h-index, Zinfluence, PI-BETA (papers ignored by even the authors), 2-year and historical self-citation threshold approval ratings, impact factor inflation, and cited article influence (CAI). The RAM are analyzed for 26 highly cited journals in the ISI category of neurosciences. The paper finds that the Eigenfactor score and PI-BETA are not highly correlated with the other RAM scores, so that they convey additional information regarding journal rankings, that article influence is highly correlated with some existing RAM, so that it has little informative incremental value, and that CAI has additional informational value to that of article influence. Harmonic mean rankings of the 13 RAM criteria for the 26 highly cited journals are also presented. Emphasizing the 2YIF of a journal to the exclusion of other informative RAM criteria is shown to lead to a distorted evaluation of journal performance and influence, especially given the informative value of several other RAM.'] ['Nonlinear regression models have been widely used in practice for a variety of time series and cross-section datasets. For purposes of analyzing univariate and multivariate time series data, in particular, smooth transition regression (STR) models have been shown to be very useful for representing and capturing asymmetric behavior. Most STR models have been applied to univariate processes, and have made a variety of assumptions, including stationary or cointegrated processes, uncorrelated, homoskedastic or conditionally heteroskedastic errors, and weakly exogenous regressors. Under the assumption of exogeneity, the standard method of estimation is nonlinear least squares. The primary purpose of this paper is to relax the assumption of weakly exogenous regressors and to discuss moment-based methods for estimating STR models. The paper analyzes the properties of the STR model with endogenous variables by providing a diagnostic test of linearity of the underlying process under endogeneity, developing an estimation procedure and a misspecification test for the STR model, presenting the results of Monte Carlo simulations to show the usefulness of the model and estimation method, and providing an empirical application for inflation rate targeting in Brazil. We show that STR models with endogenous variables can be specified and estimated by a straightforward application of existing results in the literature.'] [' The article discusses alternative Research Assessment Measures (RAM), with an emphasis on the Thomson Reuters ISI Web of Science database (hereafter ISI). Some analysis and comparisons are also made with data from the SciVerse Scopus database. The various RAM that are calculated annually or updated daily are defined and analyzed, including the classic 2-year impact factor (2YIF), 2YIF without journal self-citations (2YIF*), 5-year impact factor (5YIF), Immediacy (or zero-year impact factor (0YIF)), Impact Factor Inflation (IFI), Self-citation Threshold Approval Rating (STAR), Eigenfactor score, Article Influence, C3PO (Citation Performance Per Paper Online), h-index, Zinfluence, and PI-BETA (Papers Ignored - By Even The Authors). The RAM are analyzed for 10 leading econometrics journals and 4 leading statistics journals. The application to econometrics can be used as a template for other areas in economics, for other scientific disciplines, and as a benchmark for newer journals in a range of disciplines. In addition to evaluating high quality research in leading econometrics journals, the paper also compares econometrics and statistics, alternative RAM, highlights the similarities and differences of the alternative RAM, finds that several RAM capture similar performance characteristics for the leading econometrics and statistics journals, while the new PI-BETA criterion is not highly correlated with any of the other RAM, and hence conveys additional information regarding RAM, highlights major research areas in leading journals in econometrics, and discusses some likely future uses of RAM, and shows that the harmonic mean of 13 RAM provides more robust journal rankings than relying solely on 2YIF.'] ['This paper develops a new test, the trinomial test, for pairwise ordinal data samples to improve the power of the sign test by modifying its treatment of zero differences between observations, thereby increasing the use of sample information. Simulations demonstrate the power superiority of the proposed trinomial test statistic over the sign test in small samples in the presence of tie observations. We also show that the proposed trinomial test has substantially higher power than the sign test in large samples and also in the presence of tie observations, as the sign test ignores information from observations resulting in ties.'] ['The paper is concerned with analysing what makes a great journal great in economics, based on quantifiable measures. Alternative Research Assessment Measures (RAM) are discussed, with an emphasis on the Thomson Reuters ISI Web of Science database (hereafter ISI). The various ISI RAM that are calculated annually or updated daily are defined and analysed, including the classic 2-year impact factor (2YIF), 5-year impact factor (5YIF), Immediacy (or zero-year impact factor (0YIF)), Eigenfactor score, Article Influence, C3PO (Citation Performance Per Paper Online), h-index, Zinfluence, PI-BETA (Papers Ignored - By Even The Authors), and two new RAM measure, the Self-citation Threshold Approval Rating (STAR) score and the Impact Factor Inflation (IFI) score. The ISI RAM data are analysed for the most highly cited journals in the ISI categories of Economics, Management, Business, and Business - Finance. The journals are chosen on the basis of 2YIF (including self citations by both author and journal). The application to these four ISI categories could be used as a template for other ISI categories in both the Social Sciences and the Sciences, and as a benchmark for newer journals in a range of ISI disciplines. In addition to evaluating high quality research in the most highly cited Economics journals, the paper also compares the most highly cited journals in Management, Business, and Business - Finance, alternative RAM, highlights the similarities and differences in alternative RAM criteria, finds that several ISI RAM capture similar performance characteristics for the most highly cited Economics, Management, Business and Business - Finance journals, determines that the Immediacy and PI-BETA scores are not highly correlated with the other ISI RAM, and hence conveys additional information regarding ISI RAM criteria. Harmonic mean rankings of the 12 RAM criteria for the most highly cited journals in the four categories are also presented. It was shown that emphasizing THE im<p>(This abstract was borrowed from another version of this item.)'] ['DAMGARCH is a new model that extends the VARMA-GARCH model of Ling and McAleer (2003) by introducing multiple thresholds and time-dependent structure in the asymmetry of the conditional variances. Analytical expressions for the news impact surface implied by the new model are also presented. DAMGARCH models the shocks affecting the conditional variances on the basis of an underlying multivariate distribution. It is possible to model explicitly asset-specific shocks and common innovations by partitioning the multivariate density support. This paper presents the model structure, describes the implementation issues, and provides the conditions for the existence of a unique stationary solution, and for consistency and asymptotic normality of the quasi-maximum likelihood estimators. The paper also presents an empirical example to highlight the usefulness of the new model.<p>(This abstract was borrowed from another version of this item.)'] ['What are the advances introduced by realized volatility models in pricing options? In this short paper we analyze a simple option pricing framework based on the dually asymmetric realized volatility model, which emphasizes extended leverage effects and empirical regularity of high volatility risk during high volatility periods. We conduct a brief empirical analysis of the pricing performance of this approach against some benchmark models using data from the S&amp;P; 500 options in the 2001\xe2\x80\x932004 period. The results indicate that as expected the superior forecasting accuracy of realized volatility translates into significantly smaller pricing errors when compared to models of the GARCH family. Most importantly, our results indicate that the presence of leverage effects and a high volatility risk are essential for understanding common option pricing anomalies.'] [' This paper develops a general asymptotic theory for the estimation of strictly stationary and ergodic time series models. Under simple conditions that are straightforward to check, we establish the strong consistency, the rate of strong convergence and the asymptotic normality of a general class of estimators that includes LSE, MLE, and some M-type estimators. As an application, we verify the assumptions for the long-memory fractional ARIMA model. Other examples include the GARCH(1,1) model, random coefficient AR(1) model and the threshold MA(1) model.<p>(This abstract was borrowed from another version of this item.)'] ['This paper examines the market efficiency of oil spot and futures prices by using both mean-variance (MV) and stochastic dominance (SD) approaches. Based on the West Texas Intermediate crude oil data for the sample period 1989-2008, we find no evidence of any MV and SD relationships between oil spot and futures indices. This infers that there is no arbitrage opportunity between these two markets, spot and futures do not dominate one another, investors are indifferent to investing spot or futures, and the spot and futures oil markets are efficient and rational. The empirical findings are robust to each sub-period before and after the crises for different crises, and also to portfolio diversification.'] ['This study examines the conditional volatility and correlation dependency and interdependency for the four major precious metals (i.e., gold, silver, platinum and palladium), while accounting for geopolitics within a multivariate system. The implications of the estimated results for portfolio designs and hedging strategies are also analyzed. The results for the four metals system show significant short-run and long-run dependencies and interdependencies to news and past volatility. Furthermore, these results become more pervasive when the exchange rate and federal funds rate are included. Monetary policy also has a differential impact on the precious metals and the exchange rate volatilities. Finally, the applications of the results show the optimal weights in a two-asset portfolio and the hedging ratios for long positions.'] ["In 2003, the Chicago Board Options Exchange (CBOE) made two key enhancements to the volatility index (VIX) methodology based on S&amp;P; options. The new VIX methodology seems to be based on a complicated formula to calculate expected volatility. In this paper, with the use of Thailand's SET50 Index Options data, we modify the VIX formula to a very simple relationship, which has a higher negative correlation between the VIX for Thailand (TVIX) and SET50 index options. We show that TVIX provides more accurate forecasts of option prices than the simple expected volatility (SEV) index, but the SEV index outperforms TVIX in forecasting expected volatility. Therefore, the SEV index would seem to be a superior tool as a hedging diversification tool because of the high negative correlation with the volatility index."] ['Crude oil price volatility has been analyzed extensively for organized spot, forward and futures markets for well over a decade, and is crucial for forecasting volatility and Value-at-Risk (VaR). There are four major benchmarks in the international oil market, namely West Texas Intermediate (USA), Brent (North Sea), Dubai/Oman (Middle East), and Tapis (Asia-Pacific), which are likely to be highly correlated. This paper analyses the volatility spillover and asymmetric effects across and within the four markets, using three multivariate GARCH models, namely the constant conditional correlation (CCC), vector ARMA-GARCH (VARMA-GARCH) and vector ARMA-asymmetric GARCH (VARMA-AGARCH) models. A rolling window approach is used to forecast the 1-day ahead conditional correlations. The paper presents evidence of volatility spillovers and asymmetric effects on the conditional variances for most pairs of series. In addition, the forecast conditional correlations between pairs of crude oil returns have both positive and negative trends. Moreover, the optimal hedge ratios and optimal portfolio weights of crude oil across different assets and market portfolios are evaluated in order to provide important policy implications for risk management in crude oil markets.'] [' The benefits of investing internationally depend on three conditions, namely, cross-country correlations, market volatilities and future changes in currency risks (Odier and Solnik, 1993). This article investigates these conditions for several countries. Many papers have modelled both domestic interactions across asset markets and international interactions in individual asset markets in isolation, but rarely have they examined international interactions across asset markets. The article fills this gap by modelling the international interactions across stock, bond and foreign exchange markets. Two models that meet these purposes are the VARMA-AGARCH model of Hoti et al. (2002) and the VARMA-GARCH model of Ling and McAleer (2003). The countries that will be modelled in this article are Australia, Japan, Singapore, New Zealand and USA.'] [' Just as friendly arguments based on an ignorance of facts eventually led to the creation of the definitive Guinness Book of World Records, any argument about university rankings has seemingly been a problem without a solution. To state the obvious, alternative rankings methodologies can and do lead to different rankings. This article evaluates the robustness of rankings of Australian and New Zealand economics teaching departments for 1988 to 2002 and 1996 to 2002 using alternative rankings methodologies, and compares the results with the rankings obtained by Macri and Sinha (2006). In the overall mean rankings for both 1988 to 2006 and 1996 to 2002, the University of Melbourne is ranked first, followed by UWA and ANU.'] [' Stress and distress are unavoidable aspects of dealing with the vagaries of financial markets and financial advisers. The purpose of this paper is to try to reduce the discomfort in dealing with investment advisers, and to make the journey up and down the financial mountain a little less stressful and more satisfying. The commandments deal with defining investment policies precisely, diversifying asset classes, choosing a consistent benchmark for investment policies, structuring precisely the asset allocation process, defining risk and risk management procedures, monitoring the portfolio carefully, matching the allocation and investment horizons, being active or passive according to investment policies, being agnostic about model forecasts and being aware that, while buy low and sell high is a truism, investors and financial advisers are only human and therefore make mistakes. Copyright \xef\xbf\xbd 2009 Blackwell Publishing Ltd.'] [' Modeling volatility, or predictable changes over time and space in a variable, is crucial in the natural and social sciences. Life can be volatile, and anything that matters, and which changes over time and space, involves volatility. Without volatility, many temporal and spatial variables would simply be constants. Our purpose is to propose a scientific classification of the alternative volatility models and approaches that are available in the literature, following the Linnaean taxonomy. This scientific classification is used because the literature has evolved as a living organism, with the birth of numerous new species of models. Copyright \xef\xbf\xbd 2009 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] ['This paper presents a different approach to tourism research at the regional level. Financial econometric techniques are applied to international tourist arrivals, as well as their volatilities, in the five main tourist regions in Spain, using monthly international tourist arrivals during 1997\xe2\x80\x932007. Univariate time series models are estimated for the conditional means of monthly international tourist arrivals and their volatilities. The estimated conditional volatility models are GARCH(1,1), GJR(1,1) and EGARCH(1,1). Both the second moment and log-moment conditions are calculated to provide diagnostic checks of the estimated models. The conditional mean estimates are generally statistically adequate, and the inferences are valid.'] ['This paper shows that in the almost four decades from January 1965 through to December 2003, US stock prices closely followed the 4-year Presidential Election Cycle. In general, stock prices fell during the first half of a Presidency, reached a trough in the second year, rose during the second half of a Presidency, and reached a peak in the third or fourth year. This cyclical trend is found to hold for the greater part of the last ten administrations, starting from President Lyndon Johnson to the administration of President George W. Bush, particularly when the incumbent is a Republican. The empirical results suggest that the Republican Party may have greater cause to engage in active policy manipulation to win re-election than their Democratic counterparts. There is irony in that bullish runs in the stock market have tended to coincide with sub-periods under Democratic administrations. The existence of the Presidential Election Cycle shown in the paper may constitute an anomaly in the US stock market, which could be useful for investors.'] ['The volatility in agricultural prices, such as for broiler and color broiler chickens in Taiwan, is similar in various aspects to financial volatility as it relates to the risk and returns associated with agricultural production. However, as the characteristics of agricultural markets may be different from financial markets, the results arising from empirical risk analysis need to be investigated. The broiler and color broiler industries are the second and third largest livestock industries in Taiwan. When Taiwan applied to join the World Trade Organization (WTO) in the 1990s, these two industries faced the threat of deregulation of chicken meat imports. However, developments in these two industries have not been the same under deregulation, with the level of competition in the broiler and color broiler industries being markedly different. The purpose of the paper is to model the prices, growth rates and their respective volatilities in weekly broiler and color broiler chicken prices in Taiwan from January 1995 to June 2007. The empirical results show that the time series of broiler and color broiler prices, their logarithms and their growth rates are stationary, and that the estimated symmetric and asymmetric conditional volatility models all fit the data extremely well. The empirical second moment and log-moment conditions also support the statistical adequacy of the estimated volatility models. The empirical results have significant implications for risk management and policy considerations in the agricultural production industry in Taiwan.'] ['Expert opinion is an opinion given by an expert, and it can have significant value in forecasting key policy variables in economics and finance. Expert forecasts can either be expert opinions, or forecasts based on an econometric model. An expert forecast that is based on an econometric model is replicable, and can be defined as a replicable expert forecast (REF), whereas an expert opinion that is not based on an econometric model can be defined as a non-replicable expert forecast (Non-REF). Both replicable and non-replicable expert forecasts may be made available by an expert regarding a policy variable of interest. In this paper we develop a model to generate replicable expert forecasts, and compare REF with Non-REF. A method is presented to compare REF and Non-REF using efficient estimation methods, and a direct test of expertise on expert opinion is given. The latter serves the purpose of investigating whether expert adjustment improves the model-based forecasts. Illustrations for forecasting pharmaceutical SKUs, where the econometric model is of (variations of) the ARIMA type, show the relevance of the new methodology proposed in the paper. In particular, experts possess significant expertise, and expert forecasts are significant in explaining actual sales.<p>(This abstract was borrowed from another version of this item.)'] ["The major objectives of this study are twofold. The first objective is to examine the dynamic volatility and volatility transmission in a multivariate setting using the VAR(1)-GARCH(1,1) model for three major sectors, namely, Service, Banking and Industrial/or Insurance, in four Gulf Cooperation Council (GCC)'s economies (Kuwait, Qatar, Saudi Arabia and UAE). The second is to use the models' results to compute and analyze the optimal weights and hedge ratios for two-sector portfolio holdings, comprised of the three sectors for each country. The results suggest that past own volatilities matter more than past shocks and there are moderate volatility spillovers between the sectors within the individual countries, with the exception of Qatar. Moreover, the values for ratios of hedging long positions with short positions in the GCC sectors are smaller than those for the US equity sectors. The optimal portfolio weights favor the Banking/financial sector for Qatar, Saudi Arabia and UAE and the Industrial sector for Kuwait."] ['No abstract is available for this item.'] ['This paper examines behaviors of returns and volatility of ASEAN emerging stock markets (Indonesia, Malaysia, Philippines, Thailand and Vietnam), incorporating with the effects from the international gold market. The estimates of GARCH(1,1) and GJR(1,1) for these stock markets indicate that the GJR(1,1) model is preferred to GARCH(1,1), except Vietnam. However, under the exogenous effects from international gold market such as the 1 day lagged returns and the 1 day lagged volatility of gold, the GARCH(1,1)-X model captures better stock market volatility behavior than GJR(1,1)-X, except Indonesia. Interestingly, gold could be a substitute commodity for stocks in Vietnam and the Philippines, while it could be a complement for stocks in Indonesia, Thailand and Malaysia.'] ["Adopting both linear and nonlinear Granger causality tests, we find consumer attitude indices of the University of Michigan's surveys are very useful in predicting consumption movements of the United States."] [' As U.S. Treasury securities carry the full faith and credit of the U.S. government, they are free of default risk. Thus, their yields are risk-free rates of return, which allows the most recently issued U.S. Treasury securities to be used as a benchmark to price other fixed-income instruments. This article analyzes the time series properties of interest rates on U.S. Treasury benchmarks and related debt instruments by modelling the conditional mean and conditional volatility for weekly yields on 12 Treasury Bills and other debt instruments for the period January 8, 1982 to August 20, 2004. The conditional correlations between all pairs of debt instruments are also calculated. These estimates are of interest as they enable an assessment of the implications of modelling conditional volatility on forecasting performance. The estimated conditional correlation coefficients indicate whether there is specialization, diversification, or independence in the debt instrument shocks. Constant conditional correlation estimates of the standardized shocks indicate that the shocks to the first differences in the debt instrument yields are generally high and always positively correlated. In general, the primary purpose in holding a portfolio of Treasury Bills and other debt instruments should be to specialize on instruments that provide the largest returns. Tests for Stochastic Dominance are generally consistent with these findings, but find somewhat surprising rankings between debt instruments, with implications for portfolio composition. Thirty year treasuries, Aaa bonds, and mortgages tend to dominate the other instruments, at least to the second order.'] ['In this paper a number of alternative autoregressive conditional duration (ACD) models are compared using a sample of data for three major companies traded on the Australian Stock Exchange. The comparison is performed by employing the methodology for evaluating density and interval forecasts, developed by Diebold et al. [F. Diebold, A. Gunther, S. Tay, Evaluating density forecasts with applications to financial risk management, International Economic Review 39 (1998) 863\xe2\x80\x93883] and Christoffersen [P. Christoffersen, Evaluating interval forecasts, International Economic Review 39 (1998) 841\xe2\x80\x93862], respectively. Our main finding is that the generalized gamma and log-normal distributions for the error terms have similar performance and perform better that the exponential and Weibull distributions. Additionally, there seems to be no substantial difference between the standard ACD specification of Engle and Russel [R. Engle, J. Russell, Autoregressive conditional duration: a new model for irregularly-spaced transaction data, Econometrica 66 (1998) 1127\xe2\x80\x931162] and the log-ACD specification of Bauwens and Giot [L. Bauwens, P. Giot, The logarithmic ACD model: an application to the bid-ask quote process of three NYSE stocks, Annales d\xe2\x80\x99Economie et de Statistique 60 (2000) 117\xe2\x80\x93150].'] [" Alternative multivariate stochastic\xe2\x80\x89 volatility (MSV)\xe2\x80\x89 models with leverage have been proposed in the literature. However, the existing MSV with leverage models are unclear about the definition of leverage, specifically the timing of the relationship between the innovations in financial returns and the associated shocks to volatility, as well as their connection to partial correlations. This paper proposes a new MSV with leverage (MSVL) model in which leverage is defined clearly in terms of the innovations in both financial returns and volatility, such that the leverage effect associated with one financial return is not related to the leverage effect of another. News impact surfaces are developed for MSV models with leverage based on both log-volatility and volatility and are compared with the special case of news impact functions for their univariate counterparts. In order to capture heavy tails in each return distribution, we incorporate an additional factor for the volatility of each return. An empirical example based on bivariate data for Standard and Poor's 500 Composite Index and the Nikkei 225 Index is presented to illustrate the usefulness of the new MSVL model and the associated news impact surfaces. Likelihood ratio (LR) tests are considered for model selection. The LR tests show that the two-factor MSVL model is supported, indicating that the restrictions considered in the paper are empirically adequate under heavy-tailed return distributions. Copyright \xc2\xa9 2009 The Author(s). Journal compilation \xc2\xa9 Royal Economic Society 2009"] [' Credit risk is the most important type of risk in terms of monetary value. Another key risk measure is market risk, which is concerned with stocks and bonds, and related financial derivatives, as well as exchange rates and interest rates. This paper is concerned with market risk management and monitoring under the Basel II Accord, and presents Ten Commandments for optimizing value-at-risk (VaR) and daily capital charges, based on choosing wisely from (1) conditional, stochastic and realized volatility; (2) symmetry, asymmetry and leverage; (3) dynamic correlations and dynamic covariances; (4) single index and portfolio models; (5) parametric, semi-parametric and non-parametric models; (6) estimation, simulation and calibration of parameters; (7) assumptions, regularity conditions and statistical properties; (8) accuracy in calculating moments and forecasts; (9) optimizing threshold violations and economic benefits; and (10) optimizing private and public benefits of risk management. For practical purposes, it is found that the Basel II Accord would seem to encourage excessive risk taking at the expense of providing accurate measures and forecasts of risk and VaR. Copyright \xef\xbf\xbd 2009 Blackwell Publishing Ltd.'] ['The paper forecasts conditional correlations between three classes of international financial assets, namely stock, bond and foreign exchange. Two countries are considered, namely Australia and New Zealand. Forecasting will be conducted using three multivariate GARCH models, namely the CCC model [T. Bollerslev, Modelling the coherence in short-run nominal exchange rates: a multivariate generalized ARCH model, Rev. Econ. Stat. 72 (1990) 498\xe2\x80\x93505], VARMA-GARCH model [S. Ling, M. McAleer, Asymptotic theory for a vector ARMA-GARCH model, Econometric Theory 19 (2003) 280\xe2\x80\x93310], and VARMA-AGARCH model [M. McAleer, S. Hoti, F. Chan, Structure and asymptotic theory for multivariate asymmetric volatility, Econometric Rev., in press]. A rolling window technique is used to forecast 1-day ahead conditional correlations. To evaluate the impact of model specification on conditional correlations forecasts, this paper calculates and compares the correlations between conditional correlations forecasts resulted from the three models. The paper finds the evidence of volatility spillovers and asymmetric effect of negative and positive shock on the conditional variance in most pairs of series. However, it suggests that incorporating volatility spillovers and asymmetric do not contribute to better conditional correlations forecasts.'] [' Under the Basel II Accord, banks and other authorized deposit-taking institutions are required to communicate their daily market risk estimates to the relevant national monetary authority at the beginning of each trading day, using one of a variety of value-at-risk (VaR) models to measure risk. The purpose of this paper is to provide a simple explanation and a set of prescriptions for managing VaR under the Basel II Accord. The commandments deal with understanding the Basel II colours, understanding the risk model before choosing, varying the choice of risk model, avoiding the green zone and being willing to violate, incurring large violations, stopping before the red zone, avoiding frequent violations, avoiding the estimation of large portfolios, aggregating portfolios into a single index and interpreting commandments sensibly as guidelines. Copyright \xef\xbf\xbd 2009 Blackwell Publishing Ltd.'] ['Box\xe2\x80\x93Jenkins (1970) models are often used to capture the autoregressive moving average of past observations of tourist arrivals from Japan to Taiwan and New Zealand. However, other explanatory variables, such as real income in the origin country, have also affected the demand for international travel. The purpose of this paper is to use the ARMAX model to investigate the dynamic relationship between tourism demand and real income of Japan, and to compare the findings with the single-equation model. Unit root tests and diagnostics are performed before estimating the income elasticity of travel demand by Japan for New Zealand and Taiwan based on seasonally unadjusted quarterly data for 1980(1) to 2004(2). The empirical results of the ARMAX model support the economic theory that the demand for international travel is positively related to income of the origin country.'] ['This paper proposes two types of stochastic correlation structures for Multivariate Stochastic Volatility (MSV) models, namely the constant correlation (CC) MSV and dynamic correlation (DC) MSV models, from which the stochastic covariance structures can easily be obtained. Both structures can be used for purposes of determining optimal portfolio and risk management strategies through the use of correlation matrices, and for calculating Value-at-Risk (VaR) forecasts and optimal capital charges under the Basel Accord through the use of covariance matrices. A technique is developed to estimate the DC MSV model using the Markov Chain Monte Carlo (MCMC) procedure, and simulated data show that the estimation method works well. Various multivariate conditional volatility and MSV models are compared via simulation, including an evaluation of alternative VaR estimators. The DC MSV model is also estimated using three sets of empirical data, namely Nikkei 225 Index, Hang Seng Index and Straits Times Index returns, and significant dynamic correlations are found. The Dynamic Conditional Correlation (DCC) model is also estimated, and is found to be far less sensitive to the covariation in the shocks to the indexes. The correlation process for the DCC model also appears to have a unit root, and hence constant conditional correlations in the long run. In contrast, the estimates arising from the DC MSV model indicate that the dynamic correlation process is stationary.'] [' Various univariate and multivariate models of volatility have been used to evaluate market risk, asymmetric shocks, thresholds, leverage effects, and Value-at-Risk in economics and finance. This article is concerned with market risk, and develops a constant conditional correlation vector ARMA-asymmetric GARCH (VARMA-AGARCH) model, as an extension of the widely used univariate asymmetric (or threshold) GJR model of Glosten et al. (1992), and establishes its underlying structure, including the unique, strictly stationary, and ergodic solution of the model, its causal expansion, and convenient sufficient conditions for the existence of moments. Alternative empirically verifiable sufficient conditions for the consistency and asymptotic normality of the quasi-maximum likelihood estimator are established under non-normality of the standardized shocks.'] ['This paper concerns the properties of the Quasi Maximum Likelihood Estimator (QMLE) of the Logarithmic Autoregressive Conditional Duration (Log-ACD) model. Proofs of consistency and asymptotic normality of QMLE for the Log-ACD model with log-normal density are presented. This is an important issue as the Log-ACD is used widely for testing various market microstructure models and effects. Knowledge of the distribution of the QMLE is crucial for purposes of valid inference and diagnostic checking. The theoretical results developed in the paper are evaluated using Monte Carlo experiments. The experimental results also provide insights into the finite sample properties of the Log-ACD model under different distributional assumptions. Finally, this paper presents two extensions to the Log-ACD model to accommodate asymmetric effects. The usefulness of these novel models will be evaluated empirically using data from Australian stocks.'] ['This paper gives an overview about the sixteen papers included in this special issue. The papers in this special issue cover a wide range of topics. Such topics include discussing a class of tests for correlation, estimation of realized volatility, modeling time series and continuous-time models with long-range dependence, estimation and specification testing of time series models, estimation in a factor model with high-dimensional problems, finite-sample examination of quasi-maximum likelihood estimation in an autoregressive conditional duration model, and estimation in a dynamic additive quantile model.'] ['This paper analyses the time-varying conditional correlations between Chinese A and B share returns using the Dynamic Conditional Correlation (DCC) model of Engle [Engle, R.F. (2002), "Dynamic Conditional Correlation: A Simple Class of Multivariate Generalized Autoregressive Conditional Heteroskedasticity Models", Journal of Business and Economic Statistics, 20, 339-350.]. The results show that the conditional correlations increased substantially following the B share market reform, whereby Chinese investors were permitted to purchase B shares. However, this increase in correlations was found to have begun well before the B share market reform. This result has significant implication relating to the structure of the information flow between the markets for the two classes of shares. Value-at-Risk (VaR) threshold forecasts are used to analyse the importance of accommodating dynamic conditional correlations between Chinese A and B shares, and thus reflects the impact of the changes in information flow on the risk evaluation of a diversified portfolio. The competing VaR forecasts are analysed using the Unconditional Coverage, Serial Independence and Conditional Coverage tests of Christoffersen [Christoffersen (1998), "Evaluating Interval Forecasts", International Economic Review, 39, 841-862], and the Time Until First Failure Test of Kupiec [Kupiec, P.H., (1995), "Techniques for Verifying the Accuracy of Risk Measurements Models", Journal of Derivatives, 73-84]. The results offer mild support for the DCC model over its constant conditional correlation counterpart.'] ['There exist several important benchmark indexes in environmental finance, some computed by well-known financial index providers such as the Dow Jones group and others by independent agencies specializing in environmentally and socially responsible investing in finance. The construction of these sustainability indexes relies on two distinct screening methods, positive and negative, which aim to include or exclude candidate companies according to sustainable economic, environmental, social and ethical criteria. We investigate the presence and the importance of multivariate effects in conditional volatility in two major financial time-series indexes, namely the Dow Jones Sustainability Index (DJSI) World and the Ethibel Sustainability Index (ESI) Global, as a way to analyse their relative inherent risk. We further investigate empirically the existence of risk spillovers across these four indexes as a mean to assess the impact of the different screening criteria. Finally, the trends and volatility of two prominent financial indexes, the DJIA and S&amp;P500;, are analysed in the same manner to provide a comparison of the performance of the two types of indexes.'] [' The paper derives the scalar special case of the well-known BEKK multivariate GARCH model using a multivariate extension of the random coefficient autoregressive (RCA) model. This representation establishes the relevant structural and asymptotic properties of the scalar BEKK model using the theoretical results available in the literature for general multivariate GARCH. Sufficient conditions for the (direct) DCC model to be consistent with a scalar BEKK representation are established. Moreover, an indirect DCC model that is consistent with the scalar BEKK representation is obtained, and is compared with the direct DCC model using an empirical example. The paper shows, within an asset allocation and risk measurement framework, that the two models are similar in terms of providing parameter estimates and forecasting value-at-risk thresholds for equally weighted and minimum variance portfolios. Copyright \xc2\xa9 2008 John Wiley &amp; Sons, Ltd.'] ['Maldives and Seychelles in the Indian Ocean are small island tourism economies (SITEs), both of which have relatively small populations, territorial sizes, land area and narrow productive bases. The two SITEs are surrounded by vast ocean and have an overwhelming reliance on international tourism for economic development. Variations in international tourist arrivals to these two SITEs have been affected by unanticipated oil shocks, natural disasters, crime and global terrorism, among others. An accurate assessment of the variations in international tourist arrivals, particularly the conditional volatility, is essential for policy and marketing purposes. The conditional mean and conditional variance of the weekly international tourist arrivals to Maldives and Seychelles from 1 January 1994 to 31 December 2003 for the five main tourist source countries are modelled. Multivariate models of uncertainty are estimated and tested. An assessment and interpretation of the estimates are made for policy makers and tour operators to reach optimal decisions on the basis of a portfolio approach to international tourism demand. The paper assesses four sets of country spillover effects between Maldives and Seychelles, namely (i) the own country effects for Maldives and Seychelles; (ii) the country spillover effects from the remaining four countries within each of Maldives and Seychelles; (iii) the own country spillover effects between Maldives and Seychelles; and (iv) the cross-country spillover effects between Maldives and Seychelles. The empirical results for both Maldives and Seychelles are discussed in terms of each of these components.'] ['In this paper we provide an alternative approach to analyze the demand for international tourism in the Balearic Islands, Spain, by using a neural network model that incorporates time-varying conditional volatility. We consider daily air passenger arrivals to Palma de Mallorca, Ibiza and Mahon, which are located in the islands of Mallorca, Ibiza and Menorca, respectively, as a proxy for international tourism demand for the Balearic Islands. Spain is a world leader in terms of total international tourist arrivals and receipts, and Mallorca is one of the most popular destinations in Spain. For tourism management and marketing, it is essential to forecast high frequency international tourist demand accurately. As it is important to provide sensible international tourism demand forecast intervals, it is also necessary to model their variances accurately. Moreover, time-varying variances provide useful information regarding the risks associated with variations in international tourist arrivals.'] ['The paper develops the structure of parsimonious portfolio single index (PSI) multivariate conditional and stochastic constant correlation volatility models, and methods for estimating the underlying parameters. These multivariate estimates of volatility can be used for more accurate portfolio risk management, to enable efficient forecasting of value-at-risk (VaR) thresholds, and to determine optimal Basel Accord capital charges. A parsimonious portfolio single index approach for modelling the conditional and stochastic covariance matrices of a portfolio of assets is developed, and estimation methods for the conditional and stochastic volatility models are discussed.'] [' The challenge of modeling, estimating, testing, and forecasting financial volatility is both intellectually worthwhile and also central to the successful analysis of financial returns and optimal investment strategies. In each of the three primary areas of volatility modeling, namely, conditional (or generalized autoregressive conditional heteroskedasticity) volatility, stochastic volatility and realized volatility (RV), numerous univariate volatility models of individual financial assets and multivariate volatility models of portfolios of assets have been established. This special issue has eleven innovative articles, eight of which are focused directly on RV and three on long memory, while two are concerned with both RV and long memory.'] ['Within the industrial metals industry, there has been a great deal of interest surrounding trends in metals market volatility over time. This paper uses a rolling AR(1)-GARCH(1,1) model to estimate and forecast the volatility processes for daily returns on the futures prices of two important non-ferrous metals, namely aluminium and copper. The rolling models are used to examine how the processes driving aluminium and copper returns volatility have evolved over a long sample. The variation over time seen in the volatility processes, as modelled by GARCH, suggest that, while volatility in returns has not necessarily increased, the conditional volatility process in metals markets is itself time-varying when analysed over a long horizon.'] ['In this paper we consider estimation of demand systems with flexible functional forms, allowing an error term with a general conditional heteroskedasticity function that depends on observed covariates, such as demographic variables. We propose a general model that can be estimated either by quasi-maximum likelihood (in the case of exogenous regressors) or generalized method of moments (GMM) if the covariates are endogenous. The specification proposed in the paper nests several demand functions in the literature and the results can be applied to the recently proposed Exact Affine Stone Index (EASI) demand system of [Lewbel, A., Pendakur, K., 2008. Tricks with Hicks: The EASI implicit Marshallian demand system for unobserved heterogeneity and flexible Engel curves. American Economic Review (in press)]. Furthermore, flexible nonlinear expenditure elasticities can be estimated.'] [' This article reviews the exciting and rapidly expanding literature on realized volatility. After presenting a general univariate framework for estimating realized volatilities, a simple discrete time model is presented in order to motivate the main results. A continuous time specification provides the theoretical foundation for the main results in this literature. Cases with and without microstructure noise are considered, and it is shown how microstructure noise can cause severe problems in terms of consistent estimation of the daily realized volatility. Independent and dependent noise processes are examined. The most important methods for providing consistent estimators are presented, and a critical exposition of different techniques is given. The finite sample properties are discussed in comparison with their asymptotic properties. A multivariate model is presented to discuss estimation of the realized covariances. Various issues relating to modelling and forecasting realized volatilities are considered. The main empirical findings using univariate and multivariate methods are summarized.'] ["This paper develops a generalized autoregressive conditional correlation (GARCC) model when the standardized residuals follow a random coefficient vector autoregressive process. As a multivariate generalization of the Tsay (1987, Journal of the American Statistical Association 82, 590\xe2\x80\x93604) random coefficient autoregressive (RCA) model, the GARCC model provides a motivation for the conditional correlations to be time varying. GARCC is also more general than the Engle (2002, Journal of Business &amp; Economic Statistics 20, 339\xe2\x80\x93350) dynamic conditional correlation (DCC) and the Tse and Tsui (2002, Journal of Business &amp; Economic Statistics 20, 351\xe2\x80\x93362) varying conditional correlation (VCC) models and does not impose unduly restrictive conditions on the parameters of the DCC model. The structural properties of the GARCC model, specifically, the analytical forms of the regularity conditions, are derived, and the asymptotic theory is established. The Baba, Engle, Kraft, and Kroner (BEKK) model of Engle and Kroner (1995, Econometric Theory 11, 122\xe2\x80\x93150) is demonstrated to be a special case of a multivariate RCA process. A likelihood ratio test is proposed for several special cases of GARCC. The empirical usefulness of GARCC and the practicality of the likelihood ratio test are demonstrated for the daily returns of the Standard and Poor's 500, Nikkei, and Hang Seng indexes."] ['With the rapid flow of knowledge and capital from Hong Kong and Taiwan to Mainland China, a dynamic economy of \xe2\x80\x9cGreater China\xe2\x80\x9d has emerged, making the Chinese trio increasingly interdependent on trade and investment. In this paper we develop a three-variable VAR model to assess empirically the feasibility of forming a currency union in the Greater China area. The empirical results suggest that, from an economic perspective, it is feasible for the Chinese trio to move toward a currency union because of the increasing symmetry of shocks, the dynamic economic integration among the Greater China economies, and the speed of adjustment to shocks.'] ['No abstract is available for this item.'] ['The aim of this paper is to investigate the effect of the Chinese B share market reform on the conditional correlation and information transmission between A and B Shares issued in the Shanghai and Shenzen stock exchanges. Daily returns for the Shanghai A share index (SHA), Shanghai B share index (SHB), Shenzen A share index (SZA) and Shenzen B share index (SZB) are used for the period 6 October 1992 to 8 February 2005. The impact of the reform on the volatility spillovers and volatility transmission were found to be significant. The results also suggest that all pairs of conditional correlations increase dramatically over the period analysed, but such increases began well before the reforms to the B share market. The importance of accommodating such an increase in conditional correlations and changes in the information transmission mechanism when estimating value-at-risk (VaR) thresholds is analysed. The results suggest that accommodating the B share market reform may not be particularly important in empirical analyses of volatility transmission.'] ['In this paper we propose a flexible model to describe nonlinearities and long-range dependence in time series dynamics. The new model is a multiple regime smooth transition extension of the Heterogeneous Autoregressive (HAR) model, which is specifically designed to model the behavior of the volatility inherent in financial time series. The model is able to simultaneously approximate long memory behavior, as well as describe sign and size asymmetries. A sequence of tests is developed to determine the number of regimes, and an estimation and testing procedure is presented. Monte Carlo simulations evaluate the finite-sample properties of the proposed tests and estimation procedures. We apply the model to several Dow Jones Industrial Average index stocks using transaction level data from the Trades and Quotes database that covers ten years of data. We find strong support for long memory and both sign and size asymmetries. Furthermore, the new model, when combined with the linear HAR model, is viable and flexible for purposes of forecasting volatility.'] [' Accurate modelling of volatility (or risk) is important in finance, particularly as it relates to the modelling and forecasting of value-at-risk (VaR) thresholds. As financial applications typically deal with a portfolio of assets and risk, there are several multivariate GARCH models which specify the risk of one asset as depending on its own past as well as the past behaviour of other assets. Multivariate effects, whereby the risk of a given asset depends on the previous risk of any other asset, are termed spillover effects. In this paper we analyse the importance of considering spillover effects when forecasting financial volatility. The forecasting performance of the VARMA-GARCH model of Ling and McAleer (2003), which includes spillover effects from all assets, the CCC model of Bollerslev (1990), which includes no spillovers, and a new Portfolio Spillover GARCH (PS-GARCH) model, which accommodates aggregate spillovers parsimoniously and hence avoids the so-called curse of dimensionality, are compared using a VaR example for a portfolio containing four international stock market indices. The empirical results suggest that spillover effects are statistically significant. However, the VaR threshold forecasts are generally found to be insensitive to the inclusion of spillover effects in any of the multivariate models considered. Copyright \xc2\xa9 2008 John Wiley &amp; Sons, Ltd.'] [' The variance of a portfolio can be forecast using a single index model or the covariance matrix of the portfolio. Using univariate and multivariate conditional volatility models, this paper evaluates the performance of the single index and portfolio models in forecasting value-at-risk (VaR) thresholds of a portfolio. Likelihood ratio tests of unconditional coverage, independence and conditional coverage of the VaR forecasts suggest that the single-index model leads to excessive and often serially dependent violations, while the portfolio model leads to too few violations. The single-index model also leads to lower daily Basel Accord capital charges. The univariate models which display correct conditional coverage lead to higher capital charges than models which lead to too many violations. Overall, the Basel Accord penalties appear to be too lenient and favour models which have too many violations. Copyright \xc2\xa9 2008 John Wiley &amp; Sons, Ltd.'] ['As creations of the mind, intellectual property includes industrial property and copyrights. This paper presents an aggregate production function of the generalized Fechner-Thurstone (GFT) form to analyze the impact of an important component of intellectual industrial property, namely patent activity, on technical change in the USA for the period 1947-1981. Patents should alter isoquant maps, and measuring their elasticities is both intuitively and empirically appealing. We define a technology-changer as a variable that has an impact on the elasticity of the marginal rate of technical substitution (MRTS) between inputs of the GFT production function over time. Various types of US patent grant activity, specifically total, domestic, foreign, successful and unsuccessful patent applications, are used as instruments for the technology-changer. Using the GFT specification, the impacts of various technology-changers on the elasticity of the mrts between inputs are estimated directly. It is found that granted (or successful) patents, patents granted to foreign companies and individuals, total patent applications, and even unsuccessful patent applications, have significant impacts on the rates at which inputs are substituted for each other over time in production.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] [' It is well known that non-trading days (or holidays) can have significant effects on the returns in financial series. In this paper, we analyze three models of non-trading day effects in stochastic volatility models with leverage effects, namely (i) the approach based on the dummy variable in conditional volatility models; (ii) the approach based on a discrete time approximation of a continuous time stochastic volatility model and (iii) the twin non-trading day stochastic volatility model which nests the above two models. The three models are also estimated and tested within the asymmetric and exponential conditional volatility frameworks. All the models within the stochastic, asymmetric conditional and exponential conditional volatility frameworks are estimated and compared using a selection of financial returns series. Copyright Royal Economic Society 2007'] [' Environmental sustainability indices, such as the Dow Jones Sustainability Indexes and the Ethibel Sustainability Index, quantify the development and promotion of sustainable social, ethical and environmental values in the community. Moreover, such indices provide a benchmark for managing sustainability portfolios, and developing financial products and services that are linked to sustainable economic, environmental, social and ethical criteria. This paper reviews the existing data and risk indices in environmental finance. The main purpose of the paper is to analyse existing sustainability and ethical indices in environmental finance, and evaluate empirical environmental risk by estimating conditional volatility clustering that is inherent in these indices. Financial volatility models are estimated to analyse the underlying conditional volatility or time-varying risk that is inherent in alternative environmental sustainability indices. Volatility clustering is observed for most series, but some extreme observations are also evident. The log- and second-moment conditions suggest that valid inferences can be drawn for purposes of sensible empirical analysis. Copyright 2007 The Authors. Journal compilation \xef\xbf\xbd 2007 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] [' This article develops the dynamic asymmetric GARCH (or DAGARCH) model that generalizes asymmetric GARCH models such as that of Glosten, Jagannathan, and Runkle (GJR), introduces multiple thresholds, and makes the asymmetric effect time dependent. We provide the stationarity conditions for the DAGARCH model and show how GJR can be obtained as a special case. Furthermore, we derive the news impact curve implied by the DAGARCH model and demonstrate its flexibility. An application to daily stock market indices is presented to demonstrate the practical usefulness of the new model. Copyright 2006, Oxford University Press.'] [' This paper proposes and analyses two types of asymmetric multivariate stochastic volatility (SV) models, namely, (i) the SV with leverage (SV-L) model, which is based on the negative correlation between the innovations in the returns and volatility, and (ii) the SV with leverage and size effect (SV-LSE) model, which is based on the signs and magnitude of the returns. The paper derives the state space form for the logarithm of the squared returns, which follow the multivariate SV-L model, and develops estimation methods for the multivariate SV-L and SV-LSE models based on the Monte Carlo likelihood (MCL) approach. The empirical results show that the multivariate SV-LSE model fits the bivariate and trivariate returns of the S&amp;P; 500, the Nikkei 225, and the Hang Seng indexes with respect to AIC and BIC more accurately than does the multivariate SV-L model. Moreover, the empirical results suggest that the univariate models should be rejected in favor of their bivariate and trivariate counterparts.'] ['This paper estimates the dynamic conditional correlations in the returns on WTI oil one-month forward prices, and one-, three-, six-, and twelve-month futures prices, using recently developed multivariate conditional volatility models. The dynamic correlations enable a determination of whether the forward and various futures returns are substitutes or complements, which are crucial for deciding whether or not to hedge against unforeseen circumstances. The models are estimated using daily data on WTI oil forward and futures prices, and their associated returns, from 3 January 1985 to 16 January 2004. At the univariate level, the estimates are statistically significant, with the occasional asymmetric effect in which negative shocks have a greater impact on volatility than positive shocks. In all cases, both the short- and long-run persistence of shocks are statistically significant. Among the five returns, there are ten conditional correlations, with the highest estimate of constant conditional correlation being 0.975 between the volatilities of the three-month and six-month futures returns, and the lowest being 0.656 between the volatilities of the forward and twelve-month futures returns. The dynamic conditional correlations can vary dramatically, being negative in four of ten cases and being close to zero in another five cases. Only in the case of the dynamic volatilities of the three-month and six-month futures returns is the range of variation relatively narrow, namely (0.832, 0.996). Thus, in general, the dynamic volatilities in the returns in the WTI oil forward and future prices can be either independent or interdependent over time.<p>(This abstract was borrowed from another version of this item.)'] [' Brand names or trademarks carry incredible economic power and prestige. There is increasing recognition by world bodies that intellectual property (IP), whether manifested in patents, trademarks, copyrights or trade secrets, is highly valuable and must be protected through robust IP enforcement. The USA is an interesting natural laboratory as patent, trademark and copyright litigation battles have been raging domestically for some time. The paper discusses the four main forms of IP assets, the legal remedies that are available to enforce the property rights inherent in each type of IP asset, the basic damages theory relating to each form of IP, and how damages may be calculated when each type of asset is presumed to be infringed. The increased recognition of the value of IP has led to stronger enforcement of IP protection, an increase in IP litigation, and growing policy actions that are focused on how that protection should be manifested. An empirical analysis of how the IP litigation activity in the USA has changed over time is also presented. Copyright 2006 The Authors Journal compilation \xef\xbf\xbd 2006 Blackwell Publishing Ltd.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [" Innovation can occur at the national level under a wide range of settings. However, the leading innovative countries internationally have several common traits, including economic, financial and political stability, which are reflected in various measures of country risk. The purpose of the paper is to examine, for the first time, the relationship between the economic, financial and political country risk ratings, on the one hand, and innovation, as measured by a country's registered patents, on the other. The relationships between various monthly country risk ratings and registered patents are analyzed for the leading 12 foreign patenting countries in the USA from 1975 to 1997. The empirical results show that economic, financial and political risk ratings have a considerable impact on the innovative activities of the 12 countries. Total US patent applications are also influential in inducing innovation in the 12 countries. Such issues have not previously been addressed in the literature on country risk and innovation. Copyright 2006 The Authors Journal compilation \xef\xbf\xbd 2006 Blackwell Publishing Ltd."] [' The London Metal Exchange (LME) is the most important centre for spot and futures trading in the main industrially-used non-ferrous metals. In this study, data on 3-month futures contracts for aluminium, aluminium alloy, copper, lead, nickel, tin, and zinc are analysed. The risk premium hypothesis and the cost-of-carry model are the standard theoretical models for pricing futures contracts, but these two models have rarely been estimated within a unified framework for metals futures. Single equation versions of the risk premium hypothesis and the cost-of-carry model are nested within a more general model. If the spot price, futures price, interest rate, and stock level variables contain stochastic trends, long run versions of the general model can be estimated within a cointegration framework. Various long run pricing models are estimated using daily LME price data for the period 1 February 1986 to 30 September 1998. Likelihood ratio tests are used to test restrictions on the general model to examine the validity of alternative nested specifications.'] [' The literature on multivariate stochastic volatility (MSV) models has developed significantly over the last few years. This paper reviews the substantial literature on specification, estimation, and evaluation of MSV models. A wide range of MSV models is presented according to various categories, namely, (i) asymmetric models, (ii) factor models, (iii) time-varying correlation models, and (iv) alternative MSV specifications, including models based on the matrix exponential transformation, the Cholesky decomposition, and the Wishart autoregressive process. Alternative methods of estimation, including quasi-maximum likelihood, simulated maximum likelihood, and Markov chain Monte Carlo methods, are discussed and compared. Various methods of diagnostic checking and model comparison are also reviewed.'] [' This paper estimates the dynamic conditional correlations in the returns on Tapis oil spot and one-month forward prices for the period 2 June 1992 to 16 January 2004, using recently developed multivariate conditional volatility models, namely the Constant Conditional Correlation Multivariate GARCH (CCC-MGARCH) model of Bollerslev (1990), Vector Autoregressive Moving Average-GARCH (VARMA-GARCH) model of Ling and McAleer (2003), VARMA-Asymmetric GARCH (VARMA-AGARCH) model of Hoti et al. (2002), and the Dynamic Conditional Correlation (DCC) model of Engle (2002). The dynamic correlations are extremely useful in determining whether the spot and forward returns are substitutes or complements, which can be used to hedge against contingencies. Both the univariate ARCH and GARCH estimates are significant for spot and forward returns, whereas the estimates of the asymmetric effect at the univariate level are not statistically significant for either spot or forward returns. Standard diagnostic tests show that the AR(1)-GARCH(1, 1) and AR(1)-GJR(1, 1) specifications are statistically adequate for both the conditional mean and the conditional variance. The multivariate estimates for the VAR(1)-GARCH(1, 1) and VAR(1)-AGARCH(1, 1) models show that the ARCH and GARCH effects for spot (forward) returns are significant in the conditional volatility model for spot (forward) returns. Moreover, there are significant interdependences in the conditional volatilities between the spot and forward markets. The multivariate asymmetric effects are significant for both spot and forward returns. Overall the multivariate VAR(1)-AGARCH(1, 1) dominates its symmetric counterpart. The calculated constant conditional correlations between the conditional volatilities of spot and forward returns using CCC-GARCH(1, 1), VAR(1)-GARCH(1, 1) and VAR(1)-AGARCH(1, 1) are very close to 0.93. Virtually identical results are obtained when the three constant conditional correlation models are extended to include two lags in both the ARCH and GARCH components. Finally, the estimates of the two DCC parameters are statistically significant, which makes it clear that the assumption of constant conditional correlation is not supported empirically. This is highlighted by the dynamic conditional correlations between spot and forward returns, for which its sample mean is virtually identical to the computed constant conditional correlation, regardless of whether a DCC-GARCH(1, 1) or a DCC-GARCH(2, 2) is used. For these models, the dynamic conditional correlations are in the range (0.417, 0.993) and (0.446, 0.993), signifying medium to extreme interdependence. Therefore, the dynamic volatilities in the returns in Tapis oil spot and forward markets are generally interdependent over time. These findings suggest that a sensible hedging strategy would consider spot and forward markets as being characterized by different degrees of substitutability.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ["Fast and steady economic growth in China during the 1990s attracted much international attention. Given the scarcity of resources, it is important for economic growth to depend on production efficiency improvement to achieve sustainability. As China is the world's second largest foreign capital recipient, foreign capital plays an important role in investment. If economic growth is fuelled by investment, an exodus or a shortage of foreign capital will render growth unsustainable. However, if growth is propelled by improvements in production efficiency, it is more likely to be sustained and to withstand reduction in production input. This paper estimates production efficiency in the agricultural sector in China with a panel data set comprising 30 provinces for the 7-year period, 1991\xe2\x80\x931997. A panel data model based on the Cobb\xe2\x80\x93Douglas production function is used to represent the production frontier and to compute technical efficiency at the provincial level. Individual effects are tested to determine if pooled estimation is preferred to unpooled (panel) estimation. The test confirms significant differences between the provinces, and hence warrants panel data estimation. Both fixed and random effects models are estimated, with provincial technical inefficiency specified as province-specific intercept terms for the former, and regression disturbances for the latter. Although the random effects model is rejected in favour of the fixed effects model, the latter did not produce estimates with correct signs, and is rejected on economic grounds. Using the random effects model, production efficiency has increased for most provinces, but the gap between the affluent coastal region and the hinterland in the west has increased."] [' In the class of stochastic volatility (SV) models, leverage effects are typically specified through the direct correlation between the innovations in both returns and volatility, resulting in the dynamic leverage (DL) model. Recently, two asymmetric SV models based on threshold effects have been proposed in the literature. As such models consider only the sign of the previous return and neglect its magnitude, this paper proposes a dynamic asymmetric leverage (DAL) model that accommodates the direct correlation as well as the sign and magnitude of the threshold effects. A special case of the DAL model with zero direct correlation between the innovations is the asymmetric leverage (AL) model. The dynamic asymmetric leverage models are estimated by the Monte Carlo likelihood (MCL) method. Monte Carlo experiments are presented to examine the finite sample properties of the estimator. For a sample size of T\xef\xbf\xbd=\xef\xbf\xbd2000 with 500 replications, the sample means, standard deviations, and root mean squared errors of the MCL estimators indicate only a small finite sample bias. The empirical estimates for S&amp;P; 500 and TOPIX financial returns, and USD/AUD and YEN/USD exchange rates, indicate that the DAL class, including the DL and AL models, is generally superior to threshold SV models with respect to AIC and BIC, with AL typically providing the best fit to the data.'] ['Atmospheric carbon dioxide concentrations (ACDC) are critical to the global temperature control system and climate change, with ACDC levels having increased rapidly since the start of the industrial revolution in the late 1700s, and the climate having become quite unstable with significant temperature changes. For this reason, a critical evaluation of ACDC levels is crucial for determining their impact on the global climate. The purpose of this paper is to analyse the trends and volatility in ACDC levels using daily data from 1 January 1991 to 31 December 2002 collected at two observatory stations, namely Ryori, Japan and Mauna Loa, USA. The conditional variance of ACDC levels is analysed using three multivariate generalised autoregressive conditional heteroscedasticity (GARCH) models, namely CCC, VARMA-GARCH and VARMA-AGARCH. These models are able to capture the dynamics in the conditional variance and the spillover effects in the volatility of ACDC levels across the two observatory stations.'] ['The Asian financial crisis in 1997 brought to the attention of member countries of the Association of South East Asian Countries (ASEAN-5) (comprising Indonesia, Malaysia, the Philippines, Singapore and Thailand) the need for closer monetary co-operation. Central to the OCA literature is the nature and symmetry of underlying economic disturbances. If the economic disturbances are similar across the countries in a region, then the costs of establishing a common currency area are likely to be small. As the presence of contagion necessarily means there is an increase in the correlation of shocks experienced within a region, this paper examines the suitability of establishing a common currency area for ASEAN-5 from the perspective of contagion. In order to select the breakpoints for contagion endogenously, a modified sequential dummy variable method is developed. The empirical results show that contagion is present between all country pairs in ASEAN-5, which indicates that the degree of correlation among the ASEAN-5 economies has increased during the Asian financial crisis.'] ['No abstract is available for this item.'] ['In the context of flexible exchange rates, Milton Friedman proposed that speculation must exert a stabilising influence on prices to remain profitable. This generated a substantial amount of predominantly theoretical research into the behaviour of speculators, for which the results seem to depend critically upon the assumptions. Such theoretical models need to be tested against empirical evidence to determine whether speculators behave in a destabilising manner. Using recent theoretical developments in the literature on modelling financial volatility, this paper tests the significance of speculators and their contributions to describing weekly volatilities across a series of currency, metals and commodity markets. As the time-varying conditional volatility GARCH model and its variants have been criticised for lacking economic content, incorporating speculators into such models contributes to an accommodation of this criticism. The economic implications from establishing the importance of speculators are far-reaching. Policymakers often discuss the imposition of a Tobin tax to curb speculation, so it must be established that speculators behave in economically destructive ways. The inclusion of speculators is also likely to yield superior forecasting models of volatility, and hence more efficient pricing of derivative instruments.'] ['Over the past decade, numerous studies have debated the usefulness of insider trading. One particularly important study relates to the informational role that insiders\xe2\x80\x99 transaction volumes have on trading activity in the equity market. In our paper, we examine whether insiders\xe2\x80\x99 purchases (sales) indicate positive (negative) earnings announcements. We argue that if insiders have early access to publicly announced information, then the issuance of good (bad) news should be preceded by insider buying (selling) activities. The results reveal that insiders\xe2\x80\x99 trading volume play an important role in the dissemination of private information to the investing public. In particular, insiders\xe2\x80\x99 purchases (sales) are found to be a good indication of good (bad) news. The information content in insiders\xe2\x80\x99 trades may be exploited, provided investors are able to realize returns within one, and at most two months, after the announcement date.'] ['Related commodity markets have two characteristics: (i) they may be expected to follow similar volatility processes; (ii) such markets are frequently represented by a market aggregate or index. Indices are used to represent the performance and aggregate time series properties of a group of markets. An important issue regarding the time series properties of an index is how the index reflects the corresponding properties of its components, particularly with regard to volatility and risk. This paper investigates the volatility of a market index relative to the volatility of its underlying assets by analysing correlation matrices derived from rolling AR(1)-generalised autoregressive conditional heteroskedasticity (GARCH)(1,1) model estimates. The second moment properties of a linear aggregate of ARMA processes with GARCH errors are analysed and compared with the properties of the individual returns series. Empirical application is made to the markets for non-ferrous metals on the London Metal Exchange (LME). The volatility of the LME Base Metals Index (LMEX) is modelled and compared with the volatility of the 3-month futures contracts for aluminium, copper, lead, nickel, tin, and zinc.'] ['Although the generalised autoregressive conditional heteroskedasticity (GARCH) model has been quite successful in capturing important empirical aspects of financial data, particularly for the symmetric effects of volatility, it has had far less success in capturing the effects of extreme observations, outliers and skewness in returns. This paper examines the GARCH model under various non-normal error distributions in order to evaluate skewness and leptokurtosis. The empirical results show that GARCH models estimated using asymmetric leptokurtic distributions are superior to their counterparts estimated under normality, in terms of: (i) capturing skewness and leptokurtosis; (ii) the maximized log-likelihood values; and (iii) isolating the ARCH and GARCH parameter estimates from the adverse effects of outliers. Overall, the flexible asymmetric Student\xe2\x80\x99s t-distribution performs best in capturing the non-normal aspects of the data.'] ['No abstract is available for this item.'] ['Since the 1970s, electronics and associated electrical equipment (henceforth \xe2\x80\x9celectronics\xe2\x80\x9d) has been one of the most dominant industries in the developed countries, with its geographical centre firmly rooted in the USA. The overall presence of electronics patents in the USA is considerable, with the share of electronics reaching 31% of all US patents in 1996 and total electronics patents reaching close to 170,000 in 1997. For the empirical analysis, the time-varying nature of volatility in the electronics patent share, namely the ratio of US electronics patents to total US patents, is examined using monthly data from January 1975 to December 1997. As negative and positive movements in the patent share may have different impacts on innovative activity, and hence on volatility, both symmetric and asymmetric models of volatility are estimated. The estimated models are the symmetric AR(1)-GARCH(1, 1), the asymmetric AR(1)-GJR(1, 1), and asymmetric AR(1)-EGARCH(1, 1). Of these, the asymmetric AR(1)-GJR(1, 1) model is found to be suitable for modelling the electronics patent share in the USA.'] ['This paper examines volatility models of currency futures contracts for three developed markets and two emerging markets. For each contract, standard models of the Unbiased Expectations Hypothesis (UEH) and Cost-of-Carry hypothesis (COC) are extended to derive volatility models corresponding to each of the two standard approaches. Each volatility model is formulated as a system of individual equations for the conditional variances of futures returns, spot returns and the domestic risk-free interest rate. The empirical results suggest that the conditional volatility of futures returns for emerging markets is significant in explaining the conditional volatility of returns in the underlying spot market. For developed markets, however, the conditional volatility of the spot returns is significant in explaining the conditional volatility of futures returns. Moreover, it is found that the domestic risk-free interest rate has little impact on the conditional variances of the futures, spot and domestic risk-free interest rates.'] ['The fast and steady economic growth in China during the 1990s has attracted much international attention. Using the three most recent Chinese input\xe2\x80\x93output tables, this paper investigates industry structure and inter-industry relationships and the relationship of both to economic growth. The input\xe2\x80\x93output tables contain intermediate demand and final demand for six broad industries, namely, Agriculture, Industry, Construction, Transportation, Post and Telecommunications, Services, and Others, for 1992, 1995 and 1997, which enables computing of input\xe2\x80\x93output coefficients for three time periods. As direct and indirect input\xe2\x80\x93output coefficients characterise industry structure during a particular time period, changes over time reflect the patterns in industry structure evolvement. Furthermore, output growth in a particular industry can be analysed from two different sources, namely the changes in input\xe2\x80\x93output coefficients that reflect technological change, and the change in final demand. This paper sheds light on four different issues over the five-year period from 1992 to 1997: (1) Was growth driven by technological changes or final demand increases? (2) As a result of the interdependence of industries, how did an increase in final demand in one industry affect growth in another? (3) How has the bottleneck of an insufficient capability in the transportation, post and telecommunications sectors to cope with demands from other sectors been affected during this period? (4) Has the industry structure of the economy been shifting in conformity with traditional growth theory, namely, with a decline in the agricultural sector and a rise in the modern industrial sector?'] [" With the globalization of financial and commodity markets, it is becoming increasingly important to recognize price linkages between markets beyond national boundaries. Models of futures pricing that incorporate such price linkages into the information set can be expected to be superior empirically. Test results obtained in the paper support this proposition strongly in the case of Brent crude oil futures contracts traded in a mutual offset system between the Singapore International Monetary Exchange (SIMEX) and the International Petroleum Exchange (IPE). Augmented models of SIMEX Brent futures contracts are obtained by incorporating the previous day's IPE Brent futures price into the equation system for the unbiased expectations and the cost-of-carry hypotheses, whereas augmented models of IPE Brent futures contracts are obtained by incorporating the same day's SIMEX Brent futures price in the system for the two hypotheses. On the basis of tests of zero restrictions, the system for the augmented unbiased expectations hypothesis is found to be superior empirically to the system for the standard Unbiased Expectations hypothesis, and the augmented cost-of-carry system is also found to be superior empirically to the standard cost-of-carry system for both SIMEX Brent futures and IPE Brent futures contracts."] ['This paper examines whether forming an optimum currency area (OCA) is viable for the East Asian region by testing the symmetry of underlying structural shocks. A structural vector autoregression (VAR) method is used to identify the underlying shocks and to examine the correlation in shocks for specified sample periods. Decomposition of the variance of shocks and impulse response analysis are used to examine the size and the speed of adjustments to shocks. The results imply that some sub-regions are potential candidates for forming OCAs, as their shocks are correlated and small, and the economies adjust rapidly to such shocks.'] ['No abstract is available for this item.'] [' This study analyses the patent trends and volatilities for the top 12 foreign patenting countries in the US market from 1975 to 1997. Japan is ranked first in terms of foreign patents registered in the USA, followed by Germany. Patent registrations from each of these countries have increased steadily over time, but at different rates. Using monthly time series data for 1975-1997, the time-varying volatility of Australian, Japanese and German patents registered in the USA is examined in detail. The asymmetric AR(1)-GJR(1,1) model is found to be suitable for Australia and Japan, while the best fitting model for Germany is the symmetric AR(1)-GARCH(1,1) model.'] [' The empirical suitability of the East Asian economies for potential monetary integration is assessed. The structural vector autoregression (VAR) method is employed to identify the underlying shocks using a three-variable VAR model across the East Asian economies. The estimates of the EEC are used as a benchmark to compare the size of the underlying shocks and the speed of adjustment to shocks in both regions to determine the feasibility of forming an optimum currency area (OCA) in East Asia. The empirical results do not display strong support for forming an OCA in the East Asian region. The results do imply, however, that some small subregions are potential candidates for OCAs, since their disturbances are correlated and small and these economies adjust rapidly to shocks.'] [" Country risk has become a topic of major concern for the international financial community over the last two decades. The importance of country ratings is underscored by the existence of several major country risk rating agencies, namely the Economist Intelligence Unit, Euromoney, Institutional Investor, International Country Risk Guide, Moody's, Political Risk Services, and Standard and Poor's. These risk rating agencies employ different methods to determine country risk ratings, combining a range of qualitative and quantitative information regarding alternative measures of economic, financial and political risk into associated composite risk ratings. However, the accuracy of any risk rating agency with regard to any or all of these measures is open to question. For this reason, it is necessary to review the literature relating to empirical country risk models according to established statistical and econometric criteria used in estimation, evaluation and forecasting. Such an evaluation permits a critical assessment of the relevance and practicality of the country risk literature. The paper also provides an international comparison of risk ratings for twelve countries from six geographic regions. These ratings are compiled by the International Country Risk Guide, which is the only rating agency to provide detailed and consistent monthly data over an extended period for a large number of countries. The time series data permit a comparative assessment of the international country risk ratings, and highlight the importance of economic, financial and political risk ratings as components of a composite risk rating. Copyright Blackwell Publishers Ltd, 2004."] [' This article evaluates the significance of the empirical models and the distributional properties of prices in non-ferrous metal spots and futures markets published in leading refereed economics and finance journals between 1980 and 2002. The survey focuses on econometric analyses of pricing and return models applied to exchange-based spot and futures markets for the main industrially used non-ferrous metals, namely aluminium, copper, lead, nickel, tin and zinc. Published empirical research is evaluated in the light of the type of contract examined, frequency of data used, choice of both dependent and explanatory variables, use of proxy variables, type of model chosen, economic hypotheses tested, methods of estimation and calculation of SEs for inference, reported descriptive statistics, use of diagnostic tests of auxiliary assumptions, use of nested and non-nested tests, use of information criteria and empirical implications for non-ferrous metals. Copyright Blackwell Publishers Ltd, 2004.'] ['This paper investigates regression quantiles (RQ) for unstable autoregressive models. The uniform Bahadur representation of the RQ process is obtained. The joint asymptotic distribution of the RQ process is derived in a unified manner for all types of characteristic roots on or outside the unit circle. It involves stochastic integrals in terms of a sequence of independent and identically distributed multivariate Brownian motions with correlated components. The related L-estimator is also discussed. The asymptotic distributions of the RQ and the L-estimator corresponding to the nonstationary componentwise arguments can be transformed into a function of a normal random variable and a sequence of i.i.d. univariate Brownian motions. This is different from the analysis based on the LSE in the literature. As an auxiliary theorem, a weak convergence of a randomly weighted residual empirical process to the stochastic integral of a Kiefer process is established. The results obtained in this paper provide an asymptotic theory for nonstationary time series processes, which can be used to construct robust unit root tests.'] ['No abstract is available for this item.'] [' The increasing diversity of average growth rates and income levels across countries has generated a large literature on testing the income convergence hypothesis. Most countries in South-East Asia, particularly the five founding ASEAN member countries (ASEAN-5), have experienced substantial economic growth, with the pace of growth having varied substantially across countries. Recent empirical studies have found evidence of several convergence clubs, in which per capita incomes have converged for selected groupings of countries and regions. This paper applies different time series tests of convergence to determine if there is a convergence club for ASEAN-5, as well as ASEAN-5 and the USA. The catching up hypothesis states that the lagging country, with low initial income and productivity levels, will tend to grow more rapidly by copying the technology of the leader country, without having to bear the associated costs of research and development. Given the important effects of technological change on growth, this paper also examines whether ASEAN-5 is catching up technologically with the USA.'] [' Least squares (LS) and maximum likelihood (ML) estimation are considered for unit root processes with GARCH (1, 1) errors. The asymptotic distributions of LS and ML estimators are derived under the condition \xce\xb1\xc2\xa0+\xc2\xa0\xce\xb2\xc2\xa0&lt;\xc2\xa01. The former has the usual unit root distribution and the latter is a functional of a bivariate Brownian motion, as in Ling and Li [Ling, S., Li, W. K. (1998). Limiting distributions of maximum likelihood estimators for unstable autoregressive moving-average time series with GARCH errors. Ann. Statist.26:84-125]. Several unit root tests based on LS estimators, ML estimators, and mixing LS and ML estimators, are constructed. Simulation results show that tests based on mixing LS and ML estimators perform better than Dickey-Fuller tests which are based on LS estimators, and that tests based on the ML estimators perform better than the mixed estimators.'] ['In this paper we examine the asymptotic properties of the estimator of the long-run coefficient (LRC) in a dynamic regression model with integrated regressors and serially correlated errors. We show that the OLS estimators of the regression coefficients are inconsistent but the OLS-based estimator of the LRC is superconsistent. Furthermore, we propose an alternative consistent estimator of the LRC, compare the two estimators through a Monte Carlo experiment, and find that the proposed estimator is MSE-superior to the OLS-based estimator.<p>(This abstract was borrowed from another version of this item.)'] [' The paper investigates several empirical issues regarding quasi-maximum likelihood estimation of smooth transition autoregressive (STAR) models with GARCH errors (STAR-GARCH) and STAR models with smooth transition GARCH errors (STAR-STGARCH). Empirical evidence is provided to show that different algorithms produce substantially different estimates for the same model. Consequently, the interpretation of the model can differ according to the choice of algorithm. Convergence, the choice of different algorithms for maximizing the likelihood function, and the sensitivity of the estimates to outliers and extreme observations, are examined using daily data for S&amp;P; 500, Hang Seng and Nikkei 225 for the period January 1986 to April 2000.'] ['This paper investigates the asymptotic theory for a vector ARMA-GARCH model. The conditions for the strict stationarity, ergodicity, and the higherorder moments of the model are established. Consistency of the quasi- maximum likelihood estimator (QMLE) is proved under only the second-order moment condition. This consistency result is new, even for the univariate ARCH and GARCH models. Moreover, the asymptotic normality of the QMLE for the vector ARCH model is obtained under only the second-order moment of the unconditional errors, and the finite fourth-order moment of the conditional errors. Under additional moment conditions, the asymptotic normality of the QMLE is also obtained for the vector ARMA-ARCH and ARMA-GARCH models, as well as a consistent estimator of the asymptotic covariance.<p>(This abstract was borrowed from another version of this item.)'] [" It is now 20 years since the publication of Engle's (1982) seminal paper, which introduced ARCH to the world. The ARCH paper had an enormous influence on both theoretical and applied econometrics, and was influential in the establishment of the discipline of Financial Econometrics. In this paper we provide an introduction to the special issue on modelling and forecasting financial volatility, which commemorates the Twentieth Anniversary of the publication of ARCH. Financial econometrics has become a mature discipline over the last two decades, and one of its major research objects is the modelling and forecasting of volatility. This special issue presents ten papers, all of which focus on volatility and risk. The papers examine issues such as the new frontiers of volatility, the selection of models for observed and unobserved volatility, the potential long-memory property of volatility, and the measurement of volatility. The commonality of papers is that they do not examine the extant literature, which has been reviewed elsewhere, but rather outline a number of important issues that are not only of current interest, but are likely to remain so for many years to come. Copyright \xc2\xa9 2002 John Wiley &amp; Sons, Ltd."] ['The London Metal Exchange (LME) is a centre for spot and futures trading in the main industrially-used non-ferrous metals. In this paper, the market for 3-month LME copper futures contracts is analysed. The risk premium hypothesis and the cost-of-carry (COC) model are the standard theoretical models for pricing futures contracts, but these two models have rarely been estimated within a unified framework for metals futures. Single equation versions of the risk premium hypothesis and the COC model are nested within a general model. If the spot price, futures price, interest rate and stock level variables contain stochastic trends, long-run versions of the general model can be estimated within the cointegration framework. The long-run pricing models are estimated using daily LME copper price data over the period 3 January 1989 to 30 September 1998. Likelihood ratio tests are used to test restrictions on the general model.'] ['The high growth performance of Singapore can be attributed largely to the rapid inflows of foreign direct investment (FDI). It is generally accepted that FDI brings not only additional capital to the host country, but also the transfer of advanced technology and management skills. The catching up hypothesis states that the lagging country, with low initial income and productivity levels, will tend to grow more rapidly by copying the technology from the leader country, without having to bear the associated costs of research and development. Given the important effects of technological change on growth, this paper examines whether Singapore is catching up technologically to the technology leader (USA). The paper applies two different time series tests of technological catching up, namely the Dickey\xe2\x80\x93Fuller-type unit root test and a test based on the Verspagen model. The empirical evidence suggests technological catching up by Singapore to the USA.'] [' This paper provides a review of some recent theoretical results for time series models with GARCH errors, and is directed towards practitioners. Starting with the simple ARCH model and proceeding to the GARCH model, some results for stationary and nonstationary ARMA-GARCH are summarized. Various new ARCH-type models, including double threshold ARCH and GARCH, ARFIMA-GARCH, CHARMA and vector ARMA-GARCH, are also reviewed. Copyright 2002 by Blackwell Publishers Ltd'] ['No abstract is available for this item.'] ['This paper investigates the use of a flexible forecasting method based on non-linear Markov modelling and canonical variate analysis, and the use of a prediction algorithm to forecast conditional volatility. We assess the dynamic behaviour of the model by forecasting volatility of a stock index. It is found that the non-linear non-parametric model based on canonical variate analysis forecasts stock index volatility significantly better than the GJR-GARCH(1,1)-t model due to the flexibility in accommodating multiple dynamic patterns in volatility which are not captured by its parametric counterpart.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['This paper investigates some structural properties of a family of GARCH processes. A simple sufficient condition for the existence of the alpha delta-order stationary solution of the processes is derived, where alpha belongs to (0,1] and delta &gt; 0. The solution is strictly stationary and ergodic, and the causal expansion of the family of GARCH processes is also established. Furthermore, the necessary and sufficient condition for the existence of the moments is obtained. The technique used in this paper for the moment conditions is different to that used in He and Terasvirta (1999a), and avoids the assumption that the process started at some finite value infinitely many periods ago. Moreover, the conditions for the strict stationarity of the model and the existence of its moments are simple to check and should prove useful in practice.<p>(This abstract was borrowed from another version of this item.)'] ['This paper investigates the long-run relationship between the demand for international travel to Australia from Malaysia and a group of leading macroeconomic variables, including Malaysian income, tourism prices in Australia, transportation costs between Malaysia and Australia, and the exchange rate between the two countries. The Augmented Dickey\xe2\x80\x93Fuller (ADF) procedure is used to test for unit roots, while Johansen\xe2\x80\x99s maximum likelihood procedure is used to test for cointegration and to estimate the number of cointegrating vectors. A single cointegrating relationship is found among the set of non-stationary macroeconomic variables, and is compared with the ordinary least squares estimates. It is found that lagged changes in real airfares, and the extent to which the system is out of equilibrium, are statistically significant. Surprisingly, real income does not seem to have a significant effect on tourism demand from Malaysia to Australia when the cointegration technique is used. However, real income (as measured by the logarithm of real private consumption expenditures per capita) is significant when ordinary least squares estimation is used.'] [" Theoretical and practical interest in non-linear time series models, particularly regime switching models, have increased substantially in recent years. Given the abundant research activity in analysing time-varying volatility through Generalized Autoregressive Conditional Heteroscedasticity (GARCH) processes (see Engle, 1982; Bollerslev, 1986), it is important to analyse regime switching models with GARCH errors. A popular specification in this class is the (stationary) Smooth Transition Autoregressive-GARCH (STAR-GARCH) model. Little is presently known about the structure of the model, or the consistency, asymptotic normality and finite sample properties of the estimators. The paper develops the structural and statistical properties of the STAR-GARCH model, and investigates the finite sample properties of maximum likelihood estimation (MLE) of STAR and STAR-GARCH models through numerical simulation. The effects of fixing the threshold value and|or the transition rate for the STAR model, misspecification of the conditional mean and the transition function of the STAR-GARCH model, and the finite sample properties of the MLE for the STAR-GARCH model, are also examined. These numerical results are used as a guide in empirical research, with an application to Standard and Poor's Composite 500 Index returns for alternative STAR-GARCH models. Copyright \xc2\xa9 2002 John Wiley &amp; Sons, Ltd."] ["Although econometricians have been using Bollerslev's (1986) GARCH (r, s) model for over a decade, the higher-order moment structure of the model remains unresolved. The sufficient condition for the existence of the higherorder moments of the GARCH (r, s) model was given by Ling (1999a). This paper shows that Ling's condition is also necessary. As an extension, the necessary and sufficient moment conditions are established for Ding, Granger and Engle's (1993) asymmetric power GARCH (r, s) model.<p>(This abstract was borrowed from another version of this item.)"] [' An efficient systems approach is used to estimate and test two alternative models regarding the pricing of Australian dollar futures contracts traded on the International Monetary Market of the Chicago Mercantile Exchange. Cointegrating relationships among the Australian dollar spot and futures prices, and the US and Australian risk-free rates of interest, suggest alternative error-correction representations for the cost-of-carry model which, with appropriate zero restrictions, yields the unbiased expectations hypothesis. A structural break in the futures price series permits estimation of appropriate models for the full sample in the presence of the break, for the full sample without explicitly modelling the break, and for two separate sub-samples created by the structural break. The restricted and unrestricted cost-of-carry formulations are estimated for all sample sets, the models obtained are found to be statistically adequate, and the qualitative results are reasonably robust across different sample sets for both models. On the basis of the tests of zero restrictions, the cost-of-carry model is found to be empirically superior to the unbiased expectations hypothesis for the four sample sets considered, regardless of the number of cointegrating relations. Copyright 2001 by The Economic Society of Australia.'] [" Hong Kong and Singapore are two of the most important and fastest growing markets for tourists to Australia. The purpose of this paper is to investigate movements in the long-run demand for tourist travel by these two origin countries for Australia. Some of the leading macroeconomic variables examined to explain tourism demand are incomes in Hong Kong and Singapore, tourism prices in Australia, and transportation costs and exchange rates between the two countries and Australia. Seasonally unadjusted quarterly data are used for Hong Kong for the period 1975(1)-1996(4), and for 1980(4)-1996(4) for Singapore. Several proxy variables are used for the incomes of tourists from Hong Kong and Singapore to explain quarterly tourist arrivals to Australia. The augmented Dickey-Fuller test for unit roots is examined in the univariate framework, and Johansen's maximum likelihood procedure is used to test for cointegration and to estimate the number of cointegrating vectors. Error correction models are estimated to explain quarterly tourism demand by Hong Kong and Singapore for Australia."] ['No abstract is available for this item.'] [' The t-test of an individual coefficient is used widely in models of qualitative choice. However, it is well known that the t-test can yield misleading results when the sample size is small. This paper provides some experimental evidence on the finite sample properties of the t-test in models with sample selection biases, through a comparison of the t-test with the likelihood ratio and Lagrange multiplier tests, which are asymptotically equivalent to the squared t-test. The finite sample problems with the t-test are shown to be alarming, and much more serious than in models such as binary choice models. An empirical example is also presented to highlight the differences in the calculated test statistics.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' Rapid economic growth in South-East and East Asia has seen a surge in tourist arrivals from this region to Australia in the 1990s, prior to the currency crisis in late 1997. The purpose of the paper is to use Autoregressive Integrated Moving Average (ARIMA) models to explain the nonstationary seasonally unadjusted quarterly tourist arrivals from Hong Kong and Singapore to Australia from 1975(1) to 1996(4). As the tourist arrivals series display strong seasonal patterns, deterministic and stochastic seasonality are examined as possible explanations for variations in the international tourist arrivals series. The Hylleberg et al. (Journal of Econometrics, 99, pp. 215-38, 1990) test for seasonal unit roots is used to examine stochastic seasonality in the various series.'] [' Previous tests of the long-run neutrality hypothesis have generally relied on annual time series data. This paper analyses the long-run neutrality of money in Australia using different sources of intra-year data, which permits an examination of the effects of seasonality and the robustness of previous empirical results. A reduced form ARIMA model is used with both quarterly seasonally unadjusted and adjusted Australian real GDP and nominal money supply to test the neutrality hypothesis. Using two measures of money stock, namely M1 and M3, it is shown that the hypothesis is supported using M1 as the measure of money supply, while it is rejected using M3. Recent trends and developments in the money and credit markets in Australia provide a possible explanation of the sensitivity of the outcome to the measure of money stock employed in the analysis.'] [' There has long been substantial interest in understanding the relative pricing of forward and futures contracts. This has led to the development of two standard theories of forward and futures pricing, namely, the Cost-of-Carry and the Risk Premium (or Unbiased Expectations) hypotheses. These studies have modelled the relationship between spot and forward/futures prices either through a no-arbitrage condition or a general equilibrium setting. Relatively few studies in this area have considered the impact of stochastic trends in the data. With the emergence of non-stationarity and cointegration in recent years, more sophisticated models of futures/forward prices have been specified. This paper surveys the significant contributions made to the literature on the pricing of forward/futures contracts, and examines recent empirical studies pertaining to z the estimation and testing of univariate and systems models of futures pricing. Copyright 2000 by Blackwell Publishers Ltd'] [' Brent crude oil futures contracts are traded on both the Singapore International Monetary Exchange (SIMEX) and the International Petroleum Exchange (IPE). Through a mutual offset system between SIMEX and IPE, Brent crude oil futures contracts can be traded up to nineteen hours each day. The inter-relationship between the two futures contracts, the spot price of Brent crude oil and the riskfree interest rate, suggest the existence of cointegration among SIMEX Brent crude oil futures prices, lagged IPE Brent crude oil futures prices, Brent spot prices and the London Inter-bank Offer Rate (LIBOR). Error-correction representations of two standard futures pricing models, namely the unbiased expectations and cost-of-carry hypotheses, are formulated for SIMEX Brent crude oil futures contracts. These formulations are augmented by including the lagged IPE futures price in the mispricing error. The resulting Augmented Unbiased Expectations Hypothesis (AUEH) and the Augmented Cost-of-Carry (ACOC) models are estimated and tested against each other, and also against the standard unbiased expectations and cost-of-carry models, using nested and non-nested testing procedures. Forecasting comparisons are also made among the various models and the autoregressive integrated moving average models fitted to SIMEX Brent crude oil futures prices. Results from the nonnested tests and the forecasting criteria show clearly that the augmented models outperform their standard (non-augmented) counterparts.'] [' The Risk Premium and Cost-of-Carry hypotheses regarding the pricing of futures contracts are tested using nested and non-nested procedures. Cointegrating relationships among the Australian dollar spot and futures prices, and US and Australian risk-free rates of interest, suggest an error-correction representation for the Risk Premium model, and two alternative error-correction formulations for the Cost of-Carry hypothesis. Two significant structural breaks in the futures price series permit a testing of appropriate models for the full sample in the presence of these breaks, for the full sample without explicitly modelling the breaks, and for various subsamples created by these structural breaks. Unit root and cointegration tests yield alternative non-nested formulations of the Cost-of-Carry model for three different subsamples, thereby leading to the use of nested and non-nested tests. The outcomes of these tests provide substantial support for the Cost-of-Carry hypothesis in the pricing of Australian dollar futures contracts.'] ['No abstract is available for this item.'] ['Real non-durable consumption expenditure for many countries typically exhibits substantial seasonal fluctuations. In this paper, two seasonal models that are consistent with an extension of the rational expectations life-cycle permanent income hypothesis are evaluated using quarterly seasonally unadjusted Swedish consumption expenditure. One model is a first-order periodically integrated autoregressive model. Formal procedures for periodic integration are used to test this hypothesis. The second model captures seasonal habit persistence in the form of a periodic seasonal ARIMA model. It is found that both models fail to capture adequately the dynamics in Swedish consumption expenditure, which suggests a rejection of the rational expectations life-cycle permanent income hypothesis.'] ['No abstract is available for this item.'] ['Strong economic growth and rapidly rising incomes in Malaysia have led to a surge in Malaysian tourist arrivals to Australia in the 1990s, prior to the currency crisis in mid-1997. The purpose of the paper is to use autoregressive integrated moving average (ARIMA) models to explain the non-stationary seasonally unadjusted quarterly tourist arrivals from Malaysia to Australia from 1975(1) to 1996(4). As the tourist arrivals series display strong seasonal patterns, deterministic and stochastic seasonality are examined as possible explanations for variations in the international tourist arrivals series. The Hylleberg, Engle, Granger and Yoo (HEGY) S. Hylleberg, R.F. Engle, C.W.J. Granges, B.S. Yoo, Seasonal integration and cointegration, J. Econometrics 99 (1990) 215\xe2\x80\x93238 test for seasonal unit roots is used to examine stochastic seasonality in the various series associated with Malaysian tourist arrivals to Australia.'] ['The Risk Premium and Cost-of-Carry models regarding the pricing of Australian dollar futures contracts traded on the International Monetary Market of the Chicago Mercantile Exchange are estimated and compared. Cointegrating relationships among the Australian dollar spot and futures prices, and US and Australian risk-free rates of interest, suggest an error-correction representation for the Risk Premium model, and two alternative error-correction formulations for the Cost-of-Carry model. Two significant structural breaks in the futures price series permit estimation of appropriate models for the full sample in the presence of these breaks, for the full sample without explicitly modelling the breaks, and for various sub-samples created by these structural breaks. The Risk Premium and Cost-of-Carry formulations are estimated for all sample sets, the models obtained are found to be statistically adequate, and the qualitative results are reasonably robust across different sample sets for both models.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [" A simultaneous equation system presumes that endogenous explanatory variables are correlated with equation-specific structural disturbances. The authors' paper proposes estimation methods and tests for switching orthogonality of a subset of the endogenous variables over a sample subset when the switching point is presumed known. Dividing the full sample period into two subperiods, the null hypothesis of switching orthogonality/endogeneity is that the subset of endogenous variables is correlated with the disturbance in one of the two periods only, whereas the alternative hypothesis of endogeneity is that the subset of variables is correlated with the disturbance in both periods. Copyright 1998 by Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association."] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' This paper reviews various recent approaches to cointegration analysis of seasonal time series. In addition to the usual decisions concerning data transformations and univariate time series properties, it is necessary to decide how seasonal variation is included in the multivariate model and how standard cointegration methods should accordingly be modified. Seasonal cointegration and periodic cointegration methods are discussed, as are some of their recent refinements. An overview of further research topics is also provided. Copyright 1998 by Blackwell Publishers Ltd'] ['No abstract is available for this item.'] ['Periodically integrated time series require a periodic differencing filter to remove the stochastic trend. A non-periodic integrated time series needs the first-difference filter for similar reasons. When the changing seasonal fluctuations for the non-periodic integrated series can be described by seasonal dummy variables for which the corresponding parameters are not constant within the sample, such a series may not be easily distinguished from a periodically integrated time series. In this paper, testing procedures developed by Franses and McAleer [4] are used to distinguish between these two alternative stochastic and non-stochastic seasonal processes when there is a single known structural break in the seasonal dummy parameters. Two empirical examples, namely, the logarithms of quarterly real GNP series for Austria and Germany, are used to illustrate the approach.'] ["The success of the economic reforms in rural China has raised the living standards of rural households. This is reflected in households' consuming goods and services that were not previously part of their consumption pattern. However, because of differences in economic and demographic characteristics, not every household has been able to increase consumption. Consequently, it will be useful to investigate how the likelihood of consuming such goods and services is affected by economic and demographic factors. In this paper, the probit model is used to compute the marginal and mean probabilities of consumption of five such goods and services, namely, Food away from home, Recreation, Medical Care, Transport, and Postage. The empirical results show that the estimated probabilities of consuming the first three goods are more sensitive to changes in the underlying economic and demographic factors, while the probabilities of consuming the latter two goods are more sensitive to changes in the model structure."] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['In this paper four versions of differential demand systems are compared empirically: namely, the Rotterdam system, a version of the Almost Ideal Demand (AID) system, the Central Bureau of Statistics (CBS) system, and the NBR system. These systems share common right-hand sides but differ in the non-linear data transformations of the endogenous variable. The variable addition testing method of McAleer (1983) for single equations is extended to vectors of equations in which the dependent variables of competing systems are subject to non-linear data transformations. An appealing feature of the variable addition testing procedure is that it accommodates the adding-up condition in a straight-forward manner. Annual data over the period 1921-1981 for The Netherlands for four major groups of consumer expenditure are used in the empirical application. It is found that no single system is dominant in explaining the data. Relatively speaking, the CBS system performs the best and the NBR system the worst, with the other two systems occupying intermediate positions. The specification of the price coefficients of the Rotterdam system appears to be empirically superior to that of the AID system. Dans ce papier, quatre versions de syst\xc3\xa8mes de demande diff\xc3\xa9rentiels sont compar\xc3\xa9s sur le plan empirique : le syst\xc3\xa8me de Rotterdam, une version du syst\xc3\xa8me de demande quasi id\xc3\xa9al (Almost Ideal Demand), le syst\xc3\xa8me du Bureau Central des Statistiques (CBS) et le syst\xc3\xa8me NBR. Ces syst\xc3\xa8mes poss\xc3\xa8dent des points en commun au niveau des variables explicatives, mais diff\xc3\xa8rent sur le plan de la transformation non lin\xc3\xa9aire de la variable endog\xc3\xa8ne. La m\xc3\xa9thode de McAleer (1983) du test par addition de variables dans le cas d\xe2\x80\x99une \xc3\xa9quation est cette fois appliqu\xc3\xa9e \xc3\xa0 des vecteurs d\xe2\x80\x99\xc3\xa9quations dans lesquelles les variables d\xc3\xa9pendantes du syst\xc3\xa8me sont sujettes \xc3\xa0 des transformations non lin\xc3\xa9aires.'] ['No abstract is available for this item.'] ['This paper is concerned with the practical problems associated with understanding and defining the concept of simplicity. Different attempts that have been made to define simplicity and, in particular, definitions based on counting parameters, are discussed and analyzed. The limitations of these attempts, especially as applied to economics, are illustrated by means of several econometric examples, including single-equation models, systems of equations, alternative functional forms, and probability distributions.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' This paper analyses and extends alternative procedures for converting qualitative expectations responses to quantitative expectations. A number of conversion procedures is investigated, including the probability model, the time-varying parameter probability model, and the regression approach. The informational content of the survey expectations is compared with simple time series models. It is found that the expectations models are superior for many series, both in terms of producing lower forecast root mean square error (RMSE) values and in detecting turning points in the actual data. Survey expectations are also tested for rational expectations in aggregate using the orthogonality test. Copyright 1995 by John Wiley &amp; Sons, Ltd.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['The paper examines how empirical models can be constructed to describe the dependence of the error in fitting data to parametric models of probability distributions on the type of distribution, sample size, parent parameter values and percentiles of interest. Such models are important in evaluating the goodness-of-fit of some distributional forms to air pollution data and, once calibrated, require only simple calculations. The procedure and results are described for the three-parameter gamma distribution, although they can also be readily applied to other distributions such as the Weibull and lognormal. Monte Carlo simulations are used to infer the true errors used as dependent variables to calibrate the parameters of the empirical model, and a variety of model selection criteria are used to examine the performance of the model. The use of such models can dramatically improve the efficiency of assessment procedures in air quality management.'] [" Two issues are discussed in this paper. The first is whether a formal definition and justification of simplicity (parsimony) in scientific inference can be found, and whether an optimal level of simplicity is obtainable. A definition of simplicity is possible, as are the optimum conditions for the desired degree of simplicity. The model of inference used here relates Bayesian inference to algorithmic information theory. Simplicity is examined in the light of induction, the Duhem-Quine thesis, and bounded rationality. The second issue relates to the role that simplicity might play in econometric modeling. This is elucidated with some remarks on the 'general to specific' approach to modeling and discussions on the purpose of a model. Copyright 1995 by Royal Economic Society."] ['No abstract is available for this item.'] [" This paper considers the consistency and efficiency of two-step estimators of a structural equation when the auxiliary equation is misspecified. Underspecification generally leads to the two-step estimator and the estimator of the error variance being inconsistent. When the errors of the structural and auxiliary equations are uncorrelated, a two-step estimator based on an overspecified auxiliary model will generally lead to a loss of efficiency compared with the two-step estimator based on a correctly specified auxiliary model. The impact of underspecifying and overspecifying the auxiliary equation used to generate initial parameter estimates for Heckman's two-step estimator of models with sample selection is analyzed. Copyright 1994 by Blackwell Publishing Ltd"] ['No abstract is available for this item.'] [' The paper critically reviews the literature on the econometric issues raised by the use of generated regressors (GR) in empirical models. The economic rationale for the use of GR is considered, with examples being drawn from several macroeconomic examples, including New Classical Macroeconomic (NCM) models which postulate monetary neutrality. Various estimation methods are discussed for models which include "surprise" or "unexpected" terms and the strengths and weaknesses of each approach are investigated. Drawing upon the work of McAleer and McKenzie (1991), situations where the typically inefficient two-step estimation (2SE) method will be efficient are highlighted. Problems of model misspecification and measurement errors are also investigated. An empirical section highlights some of the dangers of using uncorrected 2SE estimation results through a careful consideration of many recent attempts to test the NCM monetary neutrality hypothesis. Copyright 1993 by Blackwell Publishers Ltd'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' This paper emphasizes the practicability and accessibility of the necessary and sufficient condition for ordinary least squares to yield best linear unbiased estimators in several problems that are available in econometrics. Two convenient equivalent alternative forms of the condition are presented. It is shown that the condition is useful for analyzing different problems and is especially relevant for pedagogical purposes. Several practical economic examples are presented. Copyright 1992 by The Economic Society of Australia.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' Several Keynesian and New Classical models of unemployment for the United States are reevaluated. The models are examined for adequacy by testing the cross-equation restrictions (where appropriate) and using diagnostic and nonnested tests that explicitly recognize the problem introduced by generated regressors. The best New Classical model for the 1946-73 period is found to be adequate when it is estimated over the 1946-85 period, whereas the Keynesian model is not. Existing results of tests obtained at the single-equation level ignoring generated regressors are not always supported when the test statistics are calculated using the correct covariance matrix or maximum likelihood. Copyright 1991 by Royal Economic Society.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] [' Extreme bounds analysis attempts to measure the effects of the uncertainty in the specification of the explanatory variables in a regression model on the estimated coefficients of interest. Standard errors for the stochastic extreme bounds are computed using the bootstrap technique. State-by-state cross section data are used to study the deterrent effect of capital punishment in the United States in 1950. The bootstrap standard errors are sufficiently large for some bounds to suggest caution in the interpretation of the empirical results regarding the fragility of inferences for the deterrent effect of capital punishment. Copyright 1989 by MIT Press.'] ['This paper compares the asymptotic local power properties of some tests of a null model against a single nonnested alternative and against multiple nonnested alternatives, denoted hereafter as paired and joint tests, respectively. It is demonstrated that the ranking of tests on the basis of asymptotic local powers depends on the choice of local hypothesis. When a local null hypothesis is employed, it is not possible to rank the Wald and Cox-type paired or joint tests. However, when the local hypothesis is specified with reference to one of the alternative models under consideration, a ranking of different test procedures becomes possible. Under a local alternative hypothesis, it is shown that the paired Wald test will never have greater asymptotic local power than a paired Cox-type test.'] [' The purpose of this paper is to examine the properties of various tests of linear and logarithmic (or log-linear) regression models. The test procedures may be categorized as follows: (1) tests that exploit the fact that the two models are intrinsically non-nested; (2) tests based on the Box-Cox data transformation; and (3) diagnostic tests of functional form misspecification against an unspecified alternative. The small-sample properties of several tests are investigated through a Monte Carlo experiment, as is their robustness to non-normality of the errors. Copyright 1988 by MIT Press.'] [" A Monte Carlo experiment compares the small-sample properties of the Cox test, some linearized Cox tests, and an approximate point optimal test for AR(1) against MA(1) disturbances, as well as a Lagrange multiplier test of AR(1) against ARMA (1,1) disturbances. The true sizes of the asymptotic non-nested tests can differ considerably from their nominal sizes; t he Lagrange multipliers test's sizes are reasonably accurate; and the point optimal test is generally more powerful when appropriate criti cal values are used. When sizes are controlled at an arbitrary value of the AR(1) parameter, the relative power of the Cox test is increas ed. Copyright 1987 by The Review of Economic Studies Limited."] ['In this note we establish finite sample relations among some exact and asymptotic tests of non-nested linear regression models.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['The paper begins with the question of whether Leamer\'s Extreme Bounds Analysis (EBA) really does "Take the Con Out of Econometrics" By analytically demonstrating that the extreme bounds are simply functions of the F-statistic for the deletion of variables from a regression, we conclude that the information provided by EBA represents no advance over that available from traditional methods. Furthermore, there is a degree of arbitrariness in EBA which exactly parallels the selective reporting of regressions it was designed to supplant. The last part of the paper attempts a positive response to its title. By following a well defined series of modelling steps, we maintain that Cooley and Le Roy\'s EBA-derived conclusions concerning the interest elasticity of money demand owe more to a faulty methodology than to the data.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['Within the framework of linear regression, errors arising from artificial inclusion or exclusion of variables are considered with augmentations or restrictions on a given maintained hypothesis. This permits exploitation of relations between tests based on Wald and Lagrange Multiplier Principles. It is demonstrated that the standard F test, though based on biased estimators, is nevertheless valid. The traditional analysis of misspecification is applied to the linear specialization of tests for separate families of hypotheses. An empirical example is provided examining the effect of labour legislation on the growth of Canadian trade union membership, using annual data for 1925-72.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['This paper demonstrates that the extended linear expenditure system with durables (DELES) satisfies first-order conditions for local unidentifiability, and discuss alternative methods that might be used to achieve identifiability, as well as their implications. Estimates are presented using seasonally adjusted, quarterly Australian data from 1959Q4 to 1976Q2. This exercise compares the effects of allowing for first-order autocorrelation. We fix the decay rate for durables to secure identifiability, however, the estimates of the remaining parameters are insensitive to the value chosen. This suggests a major difficulty in interpreting DELES and leads us to reconsider its limiting properties.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['This paper attempts to synthesize various procedures for testing non-nested hypotheses within the framework of artificial nesting, and establishes the result that different tests correspond to different treatments of its identification problem. Numerical and a priori identification methods are distinguished. We derive two modified likelihood ratio tests that are asymptotically equivalent to the Cox-test and explain the relationship between them. The tests are consistent.<p>(This abstract was borrowed from another version of this item.)'] ['No abstract is available for this item.'] ['No abstract is available for this item.'] ['No abstract is available for this item.']